{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a98030af-fcd1-4d63-a36e-38ba053498fa",
   "metadata": {},
   "source": [
    "# A full business solution\n",
    "\n",
    "## Now we will take our project from Day 1 to the next level\n",
    "\n",
    "### BUSINESS CHALLENGE:\n",
    "\n",
    "Create a product that builds a Brochure for a company to be used for prospective clients, investors and potential recruits.\n",
    "\n",
    "We will be provided a company name and their primary website.\n",
    "\n",
    "See the end of this notebook for examples of real-world business applications.\n",
    "\n",
    "And remember: I'm always available if you have problems or ideas! Please do reach out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5b08506-dc8b-4443-9201-5f1848161363",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "# If these fail, please check you're running from an 'activated' environment with (llms) in the command prompt\n",
    "\n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "from typing import List\n",
    "from dotenv import load_dotenv\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display, update_display\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc5d8880-f2ee-4c06-af16-ecbc0262af61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key looks good so far\n"
     ]
    }
   ],
   "source": [
    "# Initialize and constants\n",
    "\n",
    "load_dotenv(override=True)\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "if api_key and api_key.startswith('sk-proj-') and len(api_key)>10:\n",
    "    print(\"API key looks good so far\")\n",
    "else:\n",
    "    print(\"There might be a problem with your API key? Please visit the troubleshooting notebook!\")\n",
    "    \n",
    "MODEL = 'gpt-4o-mini'\n",
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b96004-6822-4d09-8909-0410d18f0415",
   "metadata": {},
   "outputs": [],
   "source": [
    "ì´ ì½”ë“œëŠ” OpenAI APIë¥¼ ì“°ê¸° ìœ„í•´ í™˜ê²½ì„¤ì •ê³¼ í‚¤ ì ê²€ì„ í•˜ëŠ” ì´ˆê¸°í™” ë¶€ë¶„ì´ì—ìš”.\n",
    "ë‹¨ê³„ë³„ë¡œ í’€ë©´ ì´ë ‡ê²Œ ë©ë‹ˆë‹¤.\n",
    "\n",
    "í™˜ê²½ë³€ìˆ˜ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "\n",
    "python\n",
    "ì½”ë“œ ë³µì‚¬\n",
    "load_dotenv(override=True)\n",
    ".env íŒŒì¼ì— ì €ì¥ëœ í™˜ê²½ë³€ìˆ˜ë¥¼ íŒŒì´ì¬ìœ¼ë¡œ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.\n",
    "\n",
    "override=TrueëŠ” ê¸°ì¡´ í™˜ê²½ë³€ìˆ˜ê°€ ìˆì–´ë„ ë®ì–´ì“´ë‹¤ëŠ” ì˜ë¯¸ì˜ˆìš”.\n",
    "\n",
    "API í‚¤ ê°€ì ¸ì˜¤ê¸°\n",
    "\n",
    "python\n",
    "ì½”ë“œ ë³µì‚¬\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "ë¶ˆëŸ¬ì˜¨ í™˜ê²½ë³€ìˆ˜ ì¤‘ì—ì„œ OPENAI_API_KEY ê°’ì„ ì½ì–´ì˜µë‹ˆë‹¤.\n",
    "\n",
    "ì´ ê°’ì´ OpenAI APIë¥¼ í˜¸ì¶œí•  ë•Œ í•„ìš”í•œ ë¹„ë°€ë²ˆí˜¸ ê°™ì€ ê±°ì˜ˆìš”.\n",
    "\n",
    "API í‚¤ ìœ íš¨ì„± ì ê²€\n",
    "\n",
    "python\n",
    "ì½”ë“œ ë³µì‚¬\n",
    "if api_key and api_key.startswith('sk-proj-') and len(api_key) > 10:\n",
    "    print(\"API key looks good so far\")\n",
    "else:\n",
    "    print(\"There might be a problem with your API key? Please visit the troubleshooting notebook!\")\n",
    "API í‚¤ê°€ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸ (api_key)\n",
    "\n",
    "í‚¤ê°€ 'sk-proj-'ë¡œ ì‹œì‘í•˜ëŠ”ì§€ í™•ì¸ (OpenAI í”„ë¡œì íŠ¸ í‚¤ í˜•ì‹)\n",
    "\n",
    "ê¸¸ì´ê°€ 10ìë³´ë‹¤ ê¸´ì§€ í™•ì¸ (ë„ˆë¬´ ì§§ìœ¼ë©´ ì˜ëª»ëœ í‚¤ì¼ ê°€ëŠ¥ì„±)\n",
    "\n",
    "ì¡°ê±´ì´ ë§ìœ¼ë©´ \"API key looks good so far\" ì¶œë ¥,\n",
    "ì•„ë‹ˆë©´ \"There might be a problem...\" ê²½ê³  ë©”ì‹œì§€ ì¶œë ¥.\n",
    "\n",
    "ëª¨ë¸ ì´ë¦„ ì„¤ì •\n",
    "\n",
    "python\n",
    "ì½”ë“œ ë³µì‚¬\n",
    "MODEL = 'gpt-4o-mini'\n",
    "ì‚¬ìš©í•  OpenAI ëª¨ë¸ì„ ì§€ì •í•©ë‹ˆë‹¤.\n",
    "\n",
    "ì—¬ê¸°ì„  'gpt-4o-mini'ë¥¼ ì„ íƒí–ˆë„¤ìš”.\n",
    "\n",
    "OpenAI ê°ì²´ ìƒì„±\n",
    "\n",
    "python\n",
    "ì½”ë“œ ë³µì‚¬\n",
    "openai = OpenAI()\n",
    "OpenAI API í˜¸ì¶œì„ ë„ì™€ì£¼ëŠ” ê°ì²´ë¥¼ ë§Œë“­ë‹ˆë‹¤.\n",
    "\n",
    "ì´í›„ openai.chat.completions.create(...) ê°™ì€ ë©”ì„œë“œë¡œ ìš”ì²­ì„ ë³´ë‚¼ ìˆ˜ ìˆì–´ìš”.\n",
    "\n",
    "ğŸ’¡ ì‰½ê²Œ ë¹„ìœ \n",
    "ì´ê±´ ë§ˆì¹˜\n",
    "\n",
    ".envì—ì„œ ë¹„ë°€ë²ˆí˜¸ ì°¾ì•„ì˜¤ê¸°\n",
    "\n",
    "ê·¸ ë¹„ë°€ë²ˆí˜¸ê°€ ë§ëŠ”ì§€ ëŒ€ì¶© ê²€ì‚¬í•˜ê¸°\n",
    "\n",
    "ì‚¬ìš©í•  ëª¨ë¸ ì •í•˜ê¸°\n",
    "\n",
    "OpenAIì— ì—°ê²° ì¤€ë¹„ ì™„ë£Œ!\n",
    "â€¦ ì´ëŸ° ì¤€ë¹„ ë‹¨ê³„ì…ë‹ˆë‹¤.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "106dd65e-90af-4ca8-86b6-23a41840645b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A class to represent a Webpage\n",
    "\n",
    "# Some websites need you to use proper headers when fetching them:\n",
    "headers = {\n",
    " \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "class Website:\n",
    "    \"\"\"\n",
    "    A utility class to represent a Website that we have scraped, now with links\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, url):\n",
    "        self.url = url\n",
    "        response = requests.get(url, headers=headers)\n",
    "        self.body = response.content\n",
    "        soup = BeautifulSoup(self.body, 'html.parser')\n",
    "        self.title = soup.title.string if soup.title else \"No title found\"\n",
    "        if soup.body:\n",
    "            for irrelevant in soup.body([\"script\", \"style\", \"img\", \"input\"]):\n",
    "                irrelevant.decompose()\n",
    "            self.text = soup.body.get_text(separator=\"\\n\", strip=True)\n",
    "        else:\n",
    "            self.text = \"\"\n",
    "        links = [link.get('href') for link in soup.find_all('a')]\n",
    "        self.links = [link for link in links if link]\n",
    "\n",
    "    def get_contents(self):\n",
    "        return f\"Webpage Title:\\n{self.title}\\nWebpage Contents:\\n{self.text}\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38313d9-05a1-4307-8281-2341e000ffde",
   "metadata": {},
   "outputs": [],
   "source": [
    "ì´ ì½”ë“œëŠ” ì›¹í˜ì´ì§€ë¥¼ ê°€ì ¸ì™€ì„œ ì œëª©, ë³¸ë¬¸ í…ìŠ¤íŠ¸, ë§í¬ë¥¼ ì¶”ì¶œí•˜ëŠ” ë„ìš°ë¯¸ í´ë˜ìŠ¤ì˜ˆìš”.\n",
    "ë‹¨ê³„ë³„ë¡œ í’€ì–´ë³´ë©´ ì´ë ‡ê²Œ ë©ë‹ˆë‹¤.\n",
    "\n",
    "1. ì›¹ ìš”ì²­ í—¤ë” ì„¤ì •\n",
    "python\n",
    "ì½”ë“œ ë³µì‚¬\n",
    "headers = {\n",
    " \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) ...\"\n",
    "}\n",
    "ì¼ë¶€ ì›¹ì‚¬ì´íŠ¸ëŠ” ê·¸ëƒ¥ requestsë¡œ ì ‘ì†í•˜ë©´ ë¡œë´‡ìœ¼ë¡œ ì¸ì‹í•´ì„œ ì°¨ë‹¨í•©ë‹ˆë‹¤.\n",
    "\n",
    "ê·¸ë˜ì„œ ë¸Œë¼ìš°ì €(í¬ë¡¬)ì—ì„œ ì˜¨ ê²ƒì²˜ëŸ¼ ì†ì´ëŠ” User-Agentë¥¼ ì¶”ê°€í•´ì¤ë‹ˆë‹¤.\n",
    "\n",
    "2. Website í´ë˜ìŠ¤\n",
    "python\n",
    "ì½”ë“œ ë³µì‚¬\n",
    "class Website:\n",
    "    \"\"\"ì›¹í˜ì´ì§€ì˜ ì œëª©, ë³¸ë¬¸, ë§í¬ë¥¼ ì €ì¥í•˜ëŠ” í´ë˜ìŠ¤\"\"\"\n",
    "í•˜ë‚˜ì˜ ì›¹í˜ì´ì§€ë¥¼ í‘œí˜„í•˜ëŠ” ê°ì²´.\n",
    "\n",
    "URLì„ ë„£ìœ¼ë©´ í•´ë‹¹ í˜ì´ì§€ë¥¼ ê°€ì ¸ì™€ì„œ í•„ìš”í•œ ì •ë³´ë¥¼ ìë™ìœ¼ë¡œ ë½‘ì•„ì˜µë‹ˆë‹¤.\n",
    "\n",
    "3. ì´ˆê¸°í™” ë©”ì„œë“œ (__init__)\n",
    "python\n",
    "ì½”ë“œ ë³µì‚¬\n",
    "def __init__(self, url):\n",
    "    self.url = url\n",
    "ì‚¬ìš©ìê°€ Website(\"https://example.com\")ì²˜ëŸ¼ URLì„ ë„£ìœ¼ë©´ ì‹¤í–‰ë©ë‹ˆë‹¤.\n",
    "\n",
    "ì£¼ìš” ê¸°ëŠ¥:\n",
    "\n",
    "ì›¹í˜ì´ì§€ ìš”ì²­\n",
    "\n",
    "python\n",
    "ì½”ë“œ ë³µì‚¬\n",
    "response = requests.get(url, headers=headers)\n",
    "self.body = response.content\n",
    "â†’ URLì˜ HTML ë‚´ìš©ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.\n",
    "\n",
    "HTML íŒŒì‹±\n",
    "\n",
    "python\n",
    "ì½”ë“œ ë³µì‚¬\n",
    "soup = BeautifulSoup(self.body, 'html.parser')\n",
    "â†’ BeautifulSoupìœ¼ë¡œ HTMLì„ êµ¬ì¡°ì ìœ¼ë¡œ ë¶„ì„.\n",
    "\n",
    "ì œëª© ì¶”ì¶œ\n",
    "\n",
    "python\n",
    "ì½”ë“œ ë³µì‚¬\n",
    "self.title = soup.title.string if soup.title else \"No title found\"\n",
    "â†’ <title> íƒœê·¸ê°€ ìˆìœ¼ë©´ ì œëª© ì €ì¥, ì—†ìœ¼ë©´ \"No title found\".\n",
    "\n",
    "ë³¸ë¬¸ í…ìŠ¤íŠ¸ ì •ë¦¬\n",
    "\n",
    "python\n",
    "ì½”ë“œ ë³µì‚¬\n",
    "for irrelevant in soup.body([\"script\", \"style\", \"img\", \"input\"]):\n",
    "    irrelevant.decompose()\n",
    "self.text = soup.body.get_text(separator=\"\\n\", strip=True)\n",
    "â†’ script, style, img, input ê°™ì€ í•„ìš” ì—†ëŠ” íƒœê·¸ ì‚­ì œ í›„,\n",
    "ë³¸ë¬¸ í…ìŠ¤íŠ¸ë§Œ ê¹”ë”í•˜ê²Œ ì¶”ì¶œ.\n",
    "\n",
    "ë§í¬ ìˆ˜ì§‘\n",
    "\n",
    "python\n",
    "ì½”ë“œ ë³µì‚¬\n",
    "links = [link.get('href') for link in soup.find_all('a')]\n",
    "self.links = [link for link in links if link]\n",
    "â†’ <a> íƒœê·¸ì˜ href ì†ì„± ê°’ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ì €ì¥ (ë¹ˆ ê°’ ì œì™¸).\n",
    "\n",
    "4. ì½˜í…ì¸  ë°˜í™˜ ë©”ì„œë“œ\n",
    "python\n",
    "ì½”ë“œ ë³µì‚¬\n",
    "def get_contents(self):\n",
    "    return f\"Webpage Title:\\n{self.title}\\nWebpage Contents:\\n{self.text}\\n\\n\"\n",
    "ì €ì¥ëœ ì œëª©ê³¼ ë³¸ë¬¸ í…ìŠ¤íŠ¸ë¥¼ ë¬¸ìì—´ í˜•íƒœë¡œ ëŒë ¤ì¤ë‹ˆë‹¤.\n",
    "\n",
    "ğŸ’¡ ì‰½ê²Œ ë¹„ìœ \n",
    "ì´ê±´ ë§ˆì¹˜ ì›¹í˜ì´ì§€ ìŠ¤ìºë„ˆì˜ˆìš”.\n",
    "\n",
    "Website(url) â†’ ê·¸ í˜ì´ì§€ì˜ HTMLì„ ë°›ì•„ì™€ì„œ\n",
    "\n",
    "ì œëª©, í…ìŠ¤íŠ¸, ë§í¬ë¥¼ ìë™ìœ¼ë¡œ ë½‘ê³  ì €ì¥\n",
    "\n",
    "í•„ìš”í•˜ë©´ get_contents()ë¡œ ê¹”ë”í•˜ê²Œ ë‚´ìš© ë³´ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205c2edb-5ba4-4354-90d1-e38f7f8b6782",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e30d8128-933b-44cc-81c8-ab4c9d86589a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://edwarddonner.com/',\n",
       " 'https://edwarddonner.com/connect-four/',\n",
       " 'https://edwarddonner.com/outsmart/',\n",
       " 'https://edwarddonner.com/about-me-and-about-nebula/',\n",
       " 'https://edwarddonner.com/posts/',\n",
       " 'https://edwarddonner.com/',\n",
       " 'https://news.ycombinator.com',\n",
       " 'https://nebula.io/?utm_source=ed&utm_medium=referral',\n",
       " 'https://www.prnewswire.com/news-releases/wynden-stark-group-acquires-nyc-venture-backed-tech-startup-untapt-301269512.html',\n",
       " 'https://patents.google.com/patent/US20210049536A1/',\n",
       " 'https://www.linkedin.com/in/eddonner/',\n",
       " 'https://edwarddonner.com/2025/05/28/connecting-my-courses-become-an-llm-expert-and-leader/',\n",
       " 'https://edwarddonner.com/2025/05/28/connecting-my-courses-become-an-llm-expert-and-leader/',\n",
       " 'https://edwarddonner.com/2025/05/18/2025-ai-executive-briefing/',\n",
       " 'https://edwarddonner.com/2025/05/18/2025-ai-executive-briefing/',\n",
       " 'https://edwarddonner.com/2025/04/21/the-complete-agentic-ai-engineering-course/',\n",
       " 'https://edwarddonner.com/2025/04/21/the-complete-agentic-ai-engineering-course/',\n",
       " 'https://edwarddonner.com/2025/01/23/llm-workshop-hands-on-with-agents-resources/',\n",
       " 'https://edwarddonner.com/2025/01/23/llm-workshop-hands-on-with-agents-resources/',\n",
       " 'https://edwarddonner.com/',\n",
       " 'https://edwarddonner.com/connect-four/',\n",
       " 'https://edwarddonner.com/outsmart/',\n",
       " 'https://edwarddonner.com/about-me-and-about-nebula/',\n",
       " 'https://edwarddonner.com/posts/',\n",
       " 'mailto:hello@mygroovydomain.com',\n",
       " 'https://www.linkedin.com/in/eddonner/',\n",
       " 'https://twitter.com/edwarddonner',\n",
       " 'https://www.facebook.com/edward.donner.52']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ed = Website(\"https://edwarddonner.com\")\n",
    "ed.links"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1771af9c-717a-4fca-bbbe-8a95893312c3",
   "metadata": {},
   "source": [
    "## First step: Have GPT-4o-mini figure out which links are relevant\n",
    "\n",
    "### Use a call to gpt-4o-mini to read the links on a webpage, and respond in structured JSON.  \n",
    "It should decide which links are relevant, and replace relative links such as \"/about\" with \"https://company.com/about\".  \n",
    "We will use \"one shot prompting\" in which we provide an example of how it should respond in the prompt.\n",
    "\n",
    "This is an excellent use case for an LLM, because it requires nuanced understanding. Imagine trying to code this without LLMs by parsing and analyzing the webpage - it would be very hard!\n",
    "\n",
    "Sidenote: there is a more advanced technique called \"Structured Outputs\" in which we require the model to respond according to a spec. We cover this technique in Week 8 during our autonomous Agentic AI project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c8b7a2-f6c6-4e9f-b28f-2bd7d36f0957",
   "metadata": {},
   "outputs": [],
   "source": [
    "ì²« ë²ˆì§¸ ë‹¨ê³„: GPT-4o-minië¡œ ì–´ë–¤ ë§í¬ê°€ ê´€ë ¨ ìˆëŠ”ì§€ íŒë‹¨í•˜ê¸°\n",
    "gpt-4o-minië¥¼ í˜¸ì¶œí•˜ì—¬ ì›¹í˜ì´ì§€ì˜ ë§í¬ë¥¼ ì½ê³ , êµ¬ì¡°í™”ëœ JSONìœ¼ë¡œ ì‘ë‹µí•˜ê²Œ í•©ë‹ˆë‹¤.\n",
    "ì´ ê³¼ì •ì—ì„œ ì–´ë–¤ ë§í¬ê°€ ê´€ë ¨ ìˆëŠ”ì§€ë¥¼ íŒë‹¨í•˜ê³ , \"/about\" ê°™ì€ ìƒëŒ€ ê²½ë¡œ ë§í¬ë¥¼ \"https://company.com/about\"ì²˜ëŸ¼ ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "ìš°ë¦¬ëŠ” One-shot í”„ë¡¬í”„íŠ¸ ê¸°ë²•ì„ ì‚¬ìš©í•  ê²ƒì´ë©°, í”„ë¡¬í”„íŠ¸ì— ëª¨ë¸ì´ ì–´ë–»ê²Œ ì‘ë‹µí•´ì•¼ í•˜ëŠ”ì§€ ì˜ˆì‹œë¥¼ í•¨ê»˜ ì œê³µí•©ë‹ˆë‹¤.\n",
    "\n",
    "ì´ ì‘ì—…ì€ LLMì˜ í›Œë¥­í•œ í™œìš© ì‚¬ë¡€ì…ë‹ˆë‹¤. ì™œëƒí•˜ë©´ ë¯¸ë¬˜í•œ ë§¥ë½ ì´í•´ê°€ í•„ìš”í•˜ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤. LLM ì—†ì´ ë‹¨ìˆœíˆ ì½”ë“œë¥¼ ì‘ì„±í•´ ì›¹í˜ì´ì§€ë¥¼ íŒŒì‹±í•˜ê³  ë¶„ì„í•˜ë ¤ê³  í•˜ë©´, ë§¤ìš° ì–´ë ¤ìš´ ì‘ì—…ì´ ë  ê²ƒì…ë‹ˆë‹¤.\n",
    "\n",
    "ì°¸ê³ : ë” ê³ ê¸‰ ê¸°ë²•ìœ¼ë¡œ Structured Outputsê°€ ìˆìŠµë‹ˆë‹¤. ì´ ë°©ë²•ì€ ëª¨ë¸ì´ íŠ¹ì • ìŠ¤í™ì— ë§ì¶° ì‘ë‹µí•˜ë„ë¡ ìš”êµ¬í•©ë‹ˆë‹¤. ì´ ê¸°ë²•ì€ 8ì£¼ì°¨ ììœ¨í˜• Agentic AI í”„ë¡œì íŠ¸ì—ì„œ ë‹¤ë£° ì˜ˆì •ì…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6957b079-0d96-45f7-a26a-3487510e9b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "link_system_prompt = \"You are provided with a list of links found on a webpage. \\\n",
    "You are able to decide which of the links would be most relevant to include in a brochure about the company, \\\n",
    "such as links to an About page, or a Company page, or Careers/Jobs pages.\\n\"\n",
    "link_system_prompt += \"You should respond in JSON as in this example:\"\n",
    "link_system_prompt += \"\"\"\n",
    "{\n",
    "    \"links\": [\n",
    "        {\"type\": \"about page\", \"url\": \"https://full.url/goes/here/about\"},\n",
    "        {\"type\": \"careers page\": \"url\": \"https://another.full.url/careers\"}\n",
    "    ]\n",
    "} \n",
    "\"\"\"\n",
    "###ì›ìƒ· í”„ë¡¬í”„íŠ¸ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "304d8595-6f1c-4966-a73c-791f0e31ab93",
   "metadata": {},
   "outputs": [],
   "source": [
    "##ë©€í‹°ìƒ· í”„ë¡¬í”„íŠ¸\n",
    "link_system_prompt = \"\"\"You are provided with a list of links found on a webpage.\n",
    "Choose links relevant for a company brochure (About, Company, Careers/Jobs, Press).\n",
    "Exclude Terms, Privacy, email links, login, and ads. Always return absolute https URLs.\n",
    "Respond ONLY in JSON like:\n",
    "{ \"links\": [ { \"type\": \"<about|careers|...>\", \"url\": \"https://...\" } ] }\n",
    "\n",
    "# Example 1\n",
    "Input (base: https://companyA.com):\n",
    "/about\n",
    "/contact\n",
    "/privacy\n",
    "/terms\n",
    "mailto:hello@companyA.com\n",
    "/careers\n",
    "\n",
    "Output:\n",
    "{\n",
    "  \"links\": [\n",
    "    {\"type\": \"about page\", \"url\": \"https://companyA.com/about\"},\n",
    "    {\"type\": \"careers page\", \"url\": \"https://companyA.com/careers\"}\n",
    "  ]\n",
    "}\n",
    "\n",
    "# Example 2\n",
    "Input (base: https://www.startup.io):\n",
    "https://www.startup.io/company\n",
    "/login\n",
    "/products\n",
    "/newsroom\n",
    "/privacy-policy\n",
    "/jobs\n",
    "\n",
    "Output:\n",
    "{\n",
    "  \"links\": [\n",
    "    {\"type\": \"company page\", \"url\": \"https://www.startup.io/company\"},\n",
    "    {\"type\": \"careers page\", \"url\": \"https://www.startup.io/jobs\"},\n",
    "    {\"type\": \"press/newsroom page\", \"url\": \"https://www.startup.io/newsroom\"}\n",
    "  ]\n",
    "}\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b97e4068-97ed-4120-beae-c42105e4d59a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are provided with a list of links found on a webpage. You are able to decide which of the links would be most relevant to include in a brochure about the company, such as links to an About page, or a Company page, or Careers/Jobs pages.\n",
      "You should respond in JSON as in this example:\n",
      "{\n",
      "    \"links\": [\n",
      "        {\"type\": \"about page\", \"url\": \"https://full.url/goes/here/about\"},\n",
      "        {\"type\": \"careers page\": \"url\": \"https://another.full.url/careers\"}\n",
      "    ]\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(link_system_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e1f601b-2eaf-499d-b6b8-c99050c9d6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_links_user_prompt(website):\n",
    "    user_prompt = f\"Here is the list of links on the website of {website.url} - \"\n",
    "    user_prompt += \"please decide which of these are relevant web links for a brochure about the company, respond with the full https URL in JSON format. \\\n",
    "Do not include Terms of Service, Privacy, email links.\\n\"\n",
    "    user_prompt += \"Links (some might be relative links):\\n\"\n",
    "    user_prompt += \"\\n\".join(website.links)\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d90630-5d19-43ea-94fc-ac77c2d5343c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ì´ ì½”ë“œëŠ” ì›¹ì‚¬ì´íŠ¸ì˜ ë§í¬ ëª©ë¡ì„ GPT ê°™ì€ ëª¨ë¸ì— ë³´ë‚¼ í”„ë¡¬í”„íŠ¸(ì§ˆë¬¸ë¬¸)ë¥¼ ë§Œë“œëŠ” í•¨ìˆ˜ì˜ˆìš”.\n",
    "ë‹¨ê³„ë³„ë¡œ í’€ë©´ ì´ë ‡ê²Œ ë©ë‹ˆë‹¤.\n",
    "\n",
    "1. í•¨ìˆ˜ ì •ì˜\n",
    "python\n",
    "ì½”ë“œ ë³µì‚¬\n",
    "def get_links_user_prompt(website):\n",
    "websiteëŠ” ì•ì„œ ë§Œë“  Website í´ë˜ìŠ¤ ê°™ì€ ê°ì²´ì¼ ê°€ëŠ¥ì„±ì´ í½ë‹ˆë‹¤.\n",
    "\n",
    "ì¦‰, website.url â†’ í•´ë‹¹ ì›¹ì‚¬ì´íŠ¸ ì£¼ì†Œ\n",
    "\n",
    "website.links â†’ ê·¸ ì‚¬ì´íŠ¸ì—ì„œ ìˆ˜ì§‘í•œ ë§í¬ ëª©ë¡\n",
    "\n",
    "2. ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ ì‹œì‘\n",
    "python\n",
    "ì½”ë“œ ë³µì‚¬\n",
    "user_prompt = f\"Here is the list of links on the website of {website.url} - \"\n",
    "í”„ë¡¬í”„íŠ¸ ì²« ë¶€ë¶„ì— \"ì´ ì‚¬ì´íŠ¸({website.url})ì˜ ë§í¬ ëª©ë¡ì…ë‹ˆë‹¤\"ë¼ëŠ” ë¬¸ì¥ì„ ì‘ì„±.\n",
    "\n",
    "3. ìš”ì²­ ë‚´ìš© ì¶”ê°€\n",
    "python\n",
    "ì½”ë“œ ë³µì‚¬\n",
    "user_prompt += \"please decide which of these are relevant web links for a brochure about the company, respond with the full https URL in JSON format. \\\n",
    "Do not include Terms of Service, Privacy, email links.\\n\"\n",
    "ëª¨ë¸ì—ê²Œ ì§€ì‹œ:\n",
    "\n",
    "íšŒì‚¬ ë¸Œë¡œì…”ì— ì“¸ë§Œí•œ ê´€ë ¨ ìˆëŠ” ë§í¬ë§Œ ê³ ë¥´ê¸°\n",
    "\n",
    "ì „ì²´ HTTPS URLë¡œ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ê¸°\n",
    "\n",
    "ì´ìš© ì•½ê´€, ê°œì¸ì •ë³´ ì²˜ë¦¬ë°©ì¹¨, ì´ë©”ì¼ ë§í¬ëŠ” ì œì™¸í•˜ê¸°\n",
    "\n",
    "4. ë§í¬ ëª©ë¡ ì•ˆë‚´ ë¬¸êµ¬\n",
    "python\n",
    "ì½”ë“œ ë³µì‚¬\n",
    "user_prompt += \"Links (some might be relative links):\\n\"\n",
    "ë‹¤ìŒì— ë‚˜ì˜¬ ë§í¬ë“¤ì´ ì¼ë¶€ëŠ” /aboutì²˜ëŸ¼ ìƒëŒ€ ê²½ë¡œì¼ ìˆ˜ ìˆë‹¤ëŠ” ê±¸ ì•Œë ¤ì¤Œ.\n",
    "\n",
    "5. ì‹¤ì œ ë§í¬ë“¤ ì¶”ê°€\n",
    "python\n",
    "ì½”ë“œ ë³µì‚¬\n",
    "user_prompt += \"\\n\".join(website.links)\n",
    "website.links ë¦¬ìŠ¤íŠ¸ì˜ ëª¨ë“  ë§í¬ë¥¼ ì¤„ë°”ê¿ˆìœ¼ë¡œ ì´ì–´ë¶™ì„.\n",
    "\n",
    "6. ì™„ì„±ëœ í”„ë¡¬í”„íŠ¸ ë°˜í™˜\n",
    "python\n",
    "ì½”ë“œ ë³µì‚¬\n",
    "return user_prompt\n",
    "ì™„ì„±ëœ GPT ìš”ì²­ìš© ë¬¸ìì—´ì„ ëŒë ¤ì¤Œ.\n",
    "\n",
    "ğŸ’¡ ì‰½ê²Œ ë§í•˜ë©´\n",
    "ì´ í•¨ìˆ˜ëŠ”\n",
    "\n",
    "â€œì´ ì‚¬ì´íŠ¸ ë§í¬ ëª©ë¡ì„ ì¤„ í…Œë‹ˆ, ë¸Œë¡œì…”ì— í•„ìš”í•œ ë§í¬ë§Œ ê³¨ë¼ì„œ JSONìœ¼ë¡œ ì¤˜â€\n",
    "ë¼ëŠ” ìš”ì²­ë¬¸ì„ ìë™ìœ¼ë¡œ ë§Œë“¤ì–´ì£¼ëŠ” í”„ë¡¬í”„íŠ¸ ìƒì„±ê¸°ì…ë‹ˆë‹¤.\n",
    "\n",
    "ì›í•˜ë©´ ì œê°€ ì´ í•¨ìˆ˜ë¥¼ ì‹¤í–‰í–ˆì„ ë•Œ ì‹¤ì œë¡œ ë§Œë“¤ì–´ì§€ëŠ” í”„ë¡¬í”„íŠ¸ ì˜ˆì‹œë¥¼ í•˜ë‚˜ ë³´ì—¬ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "ê·¸ë ‡ê²Œ í•´ë“œë¦´ê¹Œìš”?\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ë‚˜ì˜ ë§:\n",
    "ì‘ ì˜ˆì‹œë„ ë³´ì—¬ì¤˜\n",
    "\n",
    "\n",
    "ChatGPTì˜ ë§:\n",
    "ì¢‹ì•„ìš” ğŸ‘\n",
    "ì˜ˆë¥¼ ë“¤ì–´, Website ê°ì²´ê°€ ì´ë ‡ê²Œ ìƒê²¼ë‹¤ê³  ê°€ì •í•´ë³¼ê²Œìš”.\n",
    "\n",
    "python\n",
    "ì½”ë“œ ë³µì‚¬\n",
    "website = Website(\"https://company.com\")\n",
    "website.links = [\n",
    "    \"/about\",\n",
    "    \"/products\",\n",
    "    \"/contact\",\n",
    "    \"/privacy-policy\",\n",
    "    \"https://company.com/blog\",\n",
    "    \"mailto:info@company.com\"\n",
    "]\n",
    "ì´ ìƒíƒœì—ì„œ í•¨ìˆ˜ë¥¼ ì‹¤í–‰í•˜ë©´:\n",
    "\n",
    "python\n",
    "ì½”ë“œ ë³µì‚¬\n",
    "print(get_links_user_prompt(website))\n",
    "ì‹¤ì œ ê²°ê³¼ ì˜ˆì‹œ\n",
    "swift\n",
    "ì½”ë“œ ë³µì‚¬\n",
    "Here is the list of links on the website of https://company.com - please decide which of these are relevant web links for a brochure about the company, respond with the full https URL in JSON format. Do not include Terms of Service, Privacy, email links.\n",
    "Links (some might be relative links):\n",
    "/about\n",
    "/products\n",
    "/contact\n",
    "/privacy-policy\n",
    "https://company.com/blog\n",
    "mailto:info@company.com\n",
    "ğŸ“Œ ì´ í”„ë¡¬í”„íŠ¸ë¥¼ GPTì— ë³´ë‚´ë©´ ëª¨ë¸ì€ ì´ëŸ° ì‹ìœ¼ë¡œ ì‘ë‹µí•  ìˆ˜ ìˆì–´ìš”:\n",
    "\n",
    "json\n",
    "ì½”ë“œ ë³µì‚¬\n",
    "[\n",
    "  \"https://company.com/about\",\n",
    "  \"https://company.com/products\",\n",
    "  \"https://company.com/contact\",\n",
    "  \"https://company.com/blog\"\n",
    "]\n",
    "â†’ privacy-policyë‚˜ mailto: ê°™ì€ ê±´ ì œì™¸í•˜ê³ , ìƒëŒ€ ê²½ë¡œëŠ” ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜í•´ì„œ ì¤ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6bcbfa78-6395-4685-b92c-22d592050fd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the list of links on the website of https://edwarddonner.com - please decide which of these are relevant web links for a brochure about the company, respond with the full https URL in JSON format. Do not include Terms of Service, Privacy, email links.\n",
      "Links (some might be relative links):\n",
      "https://edwarddonner.com/\n",
      "https://edwarddonner.com/connect-four/\n",
      "https://edwarddonner.com/outsmart/\n",
      "https://edwarddonner.com/about-me-and-about-nebula/\n",
      "https://edwarddonner.com/posts/\n",
      "https://edwarddonner.com/\n",
      "https://news.ycombinator.com\n",
      "https://nebula.io/?utm_source=ed&utm_medium=referral\n",
      "https://www.prnewswire.com/news-releases/wynden-stark-group-acquires-nyc-venture-backed-tech-startup-untapt-301269512.html\n",
      "https://patents.google.com/patent/US20210049536A1/\n",
      "https://www.linkedin.com/in/eddonner/\n",
      "https://edwarddonner.com/2025/05/28/connecting-my-courses-become-an-llm-expert-and-leader/\n",
      "https://edwarddonner.com/2025/05/28/connecting-my-courses-become-an-llm-expert-and-leader/\n",
      "https://edwarddonner.com/2025/05/18/2025-ai-executive-briefing/\n",
      "https://edwarddonner.com/2025/05/18/2025-ai-executive-briefing/\n",
      "https://edwarddonner.com/2025/04/21/the-complete-agentic-ai-engineering-course/\n",
      "https://edwarddonner.com/2025/04/21/the-complete-agentic-ai-engineering-course/\n",
      "https://edwarddonner.com/2025/01/23/llm-workshop-hands-on-with-agents-resources/\n",
      "https://edwarddonner.com/2025/01/23/llm-workshop-hands-on-with-agents-resources/\n",
      "https://edwarddonner.com/\n",
      "https://edwarddonner.com/connect-four/\n",
      "https://edwarddonner.com/outsmart/\n",
      "https://edwarddonner.com/about-me-and-about-nebula/\n",
      "https://edwarddonner.com/posts/\n",
      "mailto:hello@mygroovydomain.com\n",
      "https://www.linkedin.com/in/eddonner/\n",
      "https://twitter.com/edwarddonner\n",
      "https://www.facebook.com/edward.donner.52\n"
     ]
    }
   ],
   "source": [
    "print(get_links_user_prompt(ed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a29aca19-ca13-471c-a4b4-5abbfa813f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_links(url):\n",
    "    website = Website(url)\n",
    "    response = openai.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": link_system_prompt},\n",
    "            {\"role\": \"user\", \"content\": get_links_user_prompt(website)}\n",
    "      ],\n",
    "        response_format={\"type\": \"json_object\"}    ###RESPONSE í¬ë§· ì„¤ì • ê°€ëŠ¥, í”„ë¡¬í”„íŠ¸ì—ë„ ëª…ì‹œí•´ì•¼ ë™ì‘\n",
    "    )\n",
    "    result = response.choices[0].message.content\n",
    "    return json.loads(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef93ca0e-fe51-4711-87bf-c219e258469c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ì¢‹ì•„ìš”! ì´ í•œ ì¤„ì´ í•˜ëŠ” ì¼ì„ ìª¼ê°œì„œ ì•„ì£¼ ì‰½ê²Œ ì„¤ëª…í•´ë³¼ê²Œìš”.\n",
    "\n",
    "í•µì‹¬ ìš”ì•½\n",
    "response ì•ˆì—ëŠ” ëª¨ë¸ì˜ ì—¬ëŸ¬ í›„ë³´ ë‹µë³€(choices) ì´ ë“¤ì–´ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "choices[0]ëŠ” ê·¸ì¤‘ ì²« ë²ˆì§¸ ë‹µë³€ì´ê³ , .message.contentê°€ ê·¸ ë‹µë³€ì˜ ìˆœìˆ˜ í…ìŠ¤íŠ¸ ë‚´ìš©ì…ë‹ˆë‹¤.\n",
    "\n",
    "ê·¸ë˜ì„œ resultëŠ” ëª¨ë¸ì´ ì¶œë ¥í•œ í…ìŠ¤íŠ¸ ë¬¸ìì—´ì´ ë©ë‹ˆë‹¤.\n",
    "\n",
    "ì‰¬ìš´ ë¹„ìœ \n",
    "ëª¨ë¸ì´ ë‹µì•ˆì„ ì—¬ëŸ¬ ì¥ ì œì¶œí•  ìˆ˜ë„ ìˆì–´ìš”(ì‹œí—˜ì§€ ì—¬ëŸ¬ ë²„ì „). choicesëŠ” ê·¸ ë‹µì•ˆ ë¬¶ìŒì´ê³ , choices[0]ëŠ” 1ë²ˆ ë‹µì•ˆì§€, ê·¸ ì•ˆì˜ message.contentëŠ” ì‹¤ì œ ì íŒ ê¸€ì´ì—ìš”. ìš°ë¦¬ëŠ” â€œì²« ë²ˆì§¸ ë‹µì•ˆì§€ì˜ ê¸€â€ì„ êº¼ë‚´ resultì— ë‹´ëŠ” ì…ˆì´ì£ .\n",
    "\n",
    "êµ¬ì¡°ë¡œ ë³´ê¸° (ì‘ë‹µ ê°ì²´ì˜ ì „í˜•ì ì¸ í˜•íƒœ)\n",
    "scss\n",
    "ì½”ë“œ ë³µì‚¬\n",
    "response\n",
    "â””â”€ choices  â† ë¦¬ìŠ¤íŠ¸(ì—¬ëŸ¬ ê°œì¼ ìˆ˜ ìˆìŒ)\n",
    "   â”œâ”€ [0]\n",
    "   â”‚   â”œâ”€ index\n",
    "   â”‚   â”œâ”€ message\n",
    "   â”‚   â”‚   â”œâ”€ role (\"assistant\")\n",
    "   â”‚   â”‚   â””â”€ content  â† ëª¨ë¸ì´ ë§Œë“  í…ìŠ¤íŠ¸\n",
    "   â”‚   â””â”€ finish_reason\n",
    "   â””â”€ [1], [2], ...\n",
    "ì½”ë“œ í•œ ì¤„ í•´ì„\n",
    "python\n",
    "ì½”ë“œ ë³µì‚¬\n",
    "result = response.choices[0].message.content\n",
    "response.choices : ëª¨ë¸ ë‹µë³€ í›„ë³´ë“¤ì˜ ë¦¬ìŠ¤íŠ¸\n",
    "\n",
    "[0] : ì²« ë²ˆì§¸ í›„ë³´ ì„ íƒ\n",
    "\n",
    ".message : ê·¸ í›„ë³´ì˜ ë©”ì‹œì§€ ê°ì²´\n",
    "\n",
    ".content : ê·¸ ë©”ì‹œì§€ì˜ í…ìŠ¤íŠ¸(ìŠ¤íŠ¸ë§)\n",
    "\n",
    "ì‹¤ì „ íŒ & ì£¼ì˜ì‚¬í•­\n",
    "ì—¬ëŸ¬ í›„ë³´ë¥¼ ìš”ì²­í•œ ê²½ìš°\n",
    "n=3 ê°™ì€ ì˜µì…˜ìœ¼ë¡œ ì—¬ëŸ¬ ë‹µë³€ì„ ë°›ì•˜ë‹¤ë©´, [1], [2]ì—ì„œë„ message.contentë¥¼ êº¼ë‚¼ ìˆ˜ ìˆì–´ìš”.\n",
    "\n",
    "í•¨ìˆ˜/íˆ´ í˜¸ì¶œ ì‘ë‹µ\n",
    "ì¼ë¶€ í˜¸ì¶œ(ì˜ˆ: tool/function call)ì—ì„œëŠ” contentê°€ ë¹„ì–´ ìˆê³  tool_callsë§Œ ìˆì„ ìˆ˜ ìˆì–´ìš”. ê·¸ë• ì•„ë˜ì²˜ëŸ¼ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬í•˜ì„¸ìš”.\n",
    "\n",
    "python\n",
    "ì½”ë“œ ë³µì‚¬\n",
    "msg = response.choices[0].message\n",
    "text = msg.content or \"\"\n",
    "if getattr(msg, \"tool_calls\", None):\n",
    "    # ì—¬ê¸°ì„œ íˆ´ í˜¸ì¶œ ì •ë³´ë¥¼ ì²˜ë¦¬\n",
    "    pass\n",
    "ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œ(stream=True)\n",
    "ìŠ¤íŠ¸ë¦¬ë°ì´ë©´ responseê°€ ì´ë²¤íŠ¸ ìŠ¤íŠ¸ë¦¼ í˜•íƒœë¼ ì´ í•œ ì¤„ë¡œëŠ” ëª» êº¼ëƒ…ë‹ˆë‹¤. ì²­í¬ë¥¼ ëª¨ì•„ ì´ì–´ë¶™ì—¬ì•¼ í•´ìš”.\n",
    "\n",
    "ë‹¤ë¥¸ APIì™€ í˜¼ë™ ì£¼ì˜\n",
    "ì˜ˆì „ Completions APIëŠ” choices[0].textì˜€ê³ , Chat Completionsì€ choices[0].message.contentì…ë‹ˆë‹¤. í—·ê°ˆë¦¬ë©´ ë¬¸ì„œë¥¼ í™•ì¸í•˜ì„¸ìš”.\n",
    "\n",
    "ì›í•˜ë©´ ì§€ê¸ˆ ì“°ê³  ìˆëŠ” í˜¸ì¶œ ì½”ë“œì— ë§ì¶˜ ê²¬ê³ í•œ ì¶”ì¶œ í•¨ìˆ˜(ë‹¨ì¼/ë‹¤ì¤‘ í›„ë³´, íˆ´ì½œ/ìŠ¤íŠ¸ë¦¬ë° ëŒ€ë¹„)ë„ ë§Œë“¤ì–´ ë“œë¦´ê²Œìš”.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ChatGPTì—ê²Œ ë¬»ê¸°\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "74a827a0-2782-4ae5-b210-4a242a8b4cc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/',\n",
       " '/models',\n",
       " '/datasets',\n",
       " '/spaces',\n",
       " '/docs',\n",
       " '/enterprise',\n",
       " '/pricing',\n",
       " '/login',\n",
       " '/join',\n",
       " '/spaces',\n",
       " '/models',\n",
       " '/openai/gpt-oss-120b',\n",
       " '/openai/gpt-oss-20b',\n",
       " '/Qwen/Qwen-Image',\n",
       " '/tencent/Hunyuan-1.8B-Instruct',\n",
       " '/rednote-hilab/dots.ocr',\n",
       " '/models',\n",
       " '/spaces/Qwen/Qwen-Image',\n",
       " '/spaces/enzostvs/deepsite',\n",
       " '/spaces/black-forest-labs/FLUX.1-Krea-dev',\n",
       " '/spaces/Wan-AI/Wan-2.2-5B',\n",
       " '/spaces/alexnasa/OmniAvatar',\n",
       " '/spaces',\n",
       " '/datasets/fka/awesome-chatgpt-prompts',\n",
       " '/datasets/jxm/gpt-oss20b-samples',\n",
       " '/datasets/HuggingFaceH4/Multilingual-Thinking',\n",
       " '/datasets/openai/BrowseCompLongContext',\n",
       " '/datasets/nvidia/Nemotron-Post-Training-Dataset-v1',\n",
       " '/datasets',\n",
       " '/join',\n",
       " '/pricing#endpoints',\n",
       " '/pricing#spaces',\n",
       " '/pricing',\n",
       " '/enterprise',\n",
       " '/enterprise',\n",
       " '/enterprise',\n",
       " '/enterprise',\n",
       " '/enterprise',\n",
       " '/enterprise',\n",
       " '/enterprise',\n",
       " '/allenai',\n",
       " '/facebook',\n",
       " '/amazon',\n",
       " '/google',\n",
       " '/Intel',\n",
       " '/microsoft',\n",
       " '/grammarly',\n",
       " '/Writer',\n",
       " '/docs/transformers',\n",
       " '/docs/diffusers',\n",
       " '/docs/safetensors',\n",
       " '/docs/huggingface_hub',\n",
       " '/docs/tokenizers',\n",
       " '/docs/trl',\n",
       " '/docs/transformers.js',\n",
       " '/docs/smolagents',\n",
       " '/docs/peft',\n",
       " '/docs/datasets',\n",
       " '/docs/text-generation-inference',\n",
       " '/docs/accelerate',\n",
       " '/models',\n",
       " '/datasets',\n",
       " '/spaces',\n",
       " '/changelog',\n",
       " 'https://endpoints.huggingface.co',\n",
       " '/chat',\n",
       " '/huggingface',\n",
       " '/brand',\n",
       " '/terms-of-service',\n",
       " '/privacy',\n",
       " 'https://apply.workable.com/huggingface/',\n",
       " 'mailto:press@huggingface.co',\n",
       " '/learn',\n",
       " '/docs',\n",
       " '/blog',\n",
       " 'https://discuss.huggingface.co',\n",
       " 'https://status.huggingface.co/',\n",
       " 'https://github.com/huggingface',\n",
       " 'https://twitter.com/huggingface',\n",
       " 'https://www.linkedin.com/company/huggingface/',\n",
       " '/join/discord']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Anthropic has made their site harder to scrape, so I'm using HuggingFace..\n",
    "\n",
    "huggingface = Website(\"https://huggingface.co\")\n",
    "huggingface.links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3d583e2-dcc4-40cc-9b28-1e8dbf402924",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'links': [{'type': 'about page', 'url': 'https://huggingface.co/'},\n",
       "  {'type': 'enterprise page', 'url': 'https://huggingface.co/enterprise'},\n",
       "  {'type': 'pricing page', 'url': 'https://huggingface.co/pricing'},\n",
       "  {'type': 'careers page', 'url': 'https://apply.workable.com/huggingface/'},\n",
       "  {'type': 'blog page', 'url': 'https://huggingface.co/blog'},\n",
       "  {'type': 'company page',\n",
       "   'url': 'https://www.linkedin.com/company/huggingface/'}]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_links(\"https://huggingface.co\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d74128e-dfb6-47ec-9549-288b621c838c",
   "metadata": {},
   "source": [
    "## Second step: make the brochure!\n",
    "\n",
    "Assemble all the details into another prompt to GPT4-o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "85a5b6e2-e7ef-44a9-bc7f-59ede71037b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_details(url):\n",
    "    result = \"Landing page:\\n\"\n",
    "    result += Website(url).get_contents()  #í•´ë‹¹ URLì˜ ë³¸ë¬¸\n",
    "    links = get_links(url)  ## ëª¨ë¸ ì¨ì„œ ê´€ë ¨ìˆëŠ” ë§í¬ë“¤ ë¶ˆëŸ¬ì™€\n",
    "    print(\"Found links:\", links) # ê·¸ê±° í”„ë¦°íŠ¸\n",
    "    for link in links[\"links\"]:\n",
    "        result += f\"\\n\\n{link['type']}\\n\"\n",
    "        result += Website(link[\"url\"]).get_contents()  #ê° ë§í¬ì— ëŒ€í•œ ì»¨í…ì¸  ë¦¬ì ˆíŠ¸ì— ì¶”ê°€\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef2bf63-87c8-49c7-8bde-c52dcd43d224",
   "metadata": {},
   "outputs": [],
   "source": [
    "ì¢‹ì•„ìš” ğŸ‘\n",
    "ì´ í•¨ìˆ˜ëŠ” ì›¹ì‚¬ì´íŠ¸ ë©”ì¸ í˜ì´ì§€ì™€, ê·¸ ì•ˆì—ì„œ ë½‘ì•„ë‚¸ ê´€ë ¨ ë§í¬ë“¤ì˜ í˜ì´ì§€ ë‚´ìš©ì„ í•œ ë²ˆì— ëª¨ì•„ì£¼ëŠ” í•¨ìˆ˜ì˜ˆìš”.\n",
    "ë‹¨ê³„ë³„ë¡œ ì„¤ëª…í•´ ë“œë¦´ê²Œìš”.\n",
    "\n",
    "1. í•¨ìˆ˜ ì •ì˜\n",
    "python\n",
    "ì½”ë“œ ë³µì‚¬\n",
    "def get_all_details(url):\n",
    "url : ì¡°ì‚¬í•  ì›¹ì‚¬ì´íŠ¸ ì£¼ì†Œ (ì˜ˆ: \"https://company.com\").\n",
    "\n",
    "2. ê²°ê³¼ ë¬¸ìì—´ ì´ˆê¸°í™”\n",
    "python\n",
    "ì½”ë“œ ë³µì‚¬\n",
    "result = \"Landing page:\\n\"\n",
    "resultë¼ëŠ” ë¬¸ìì—´ì„ ë§Œë“¤ê³ , ë§¨ ì•ì— \"Landing page:\\n\"ë¥¼ ë„£ì–´ë‘¡ë‹ˆë‹¤.\n",
    "\n",
    "ë‚˜ì¤‘ì— ì—¬ê¸°ì— ê° í˜ì´ì§€ì˜ ë‚´ìš©ì„ ê³„ì† ë§ë¶™ì¼ ê±°ì˜ˆìš”.\n",
    "\n",
    "3. ë©”ì¸ í˜ì´ì§€ ë‚´ìš© ê°€ì ¸ì˜¤ê¸°\n",
    "python\n",
    "ì½”ë“œ ë³µì‚¬\n",
    "result += Website(url).get_contents()\n",
    "Website(url) â†’ ì•ì—ì„œ ë§Œë“  Website í´ë˜ìŠ¤ë¡œ í•´ë‹¹ URL í˜ì´ì§€ë¥¼ ë¶ˆëŸ¬ì˜´.\n",
    "\n",
    ".get_contents() â†’ ê·¸ í˜ì´ì§€ì˜ ì œëª©ê³¼ ë³¸ë¬¸ í…ìŠ¤íŠ¸ë¥¼ ë¬¸ìì—´ë¡œ ê°€ì ¸ì˜´.\n",
    "\n",
    "ì´ê±¸ resultì— ì´ì–´ë¶™ì„.\n",
    "\n",
    "4. ê´€ë ¨ ë§í¬ ê°€ì ¸ì˜¤ê¸°\n",
    "python\n",
    "ì½”ë“œ ë³µì‚¬\n",
    "links = get_links(url)\n",
    "get_links(url) : GPT ê°™ì€ ëª¨ë¸ì„ ì¨ì„œ ë©”ì¸ í˜ì´ì§€ì—ì„œ íšŒì‚¬ ë¸Œë¡œì…”ì— ì“¸ë§Œí•œ ê´€ë ¨ ë§í¬ë“¤ë§Œ ë½‘ì•„ì£¼ëŠ” í•¨ìˆ˜.\n",
    "\n",
    "ë°˜í™˜ê°’ ì˜ˆì‹œ:\n",
    "\n",
    "python\n",
    "ì½”ë“œ ë³µì‚¬\n",
    "{\n",
    "    \"links\": [\n",
    "        {\"type\": \"About\", \"url\": \"https://company.com/about\"},\n",
    "        {\"type\": \"Products\", \"url\": \"https://company.com/products\"}\n",
    "    ]\n",
    "}\n",
    "5. ì°¾ì€ ë§í¬ ì¶œë ¥\n",
    "python\n",
    "ì½”ë“œ ë³µì‚¬\n",
    "print(\"Found links:\", links)\n",
    "ì½˜ì†”ì— ì–´ë–¤ ë§í¬ë¥¼ ì°¾ì•˜ëŠ”ì§€ í™•ì¸ìš©ìœ¼ë¡œ ì¶œë ¥.\n",
    "\n",
    "6. ê° ë§í¬ í˜ì´ì§€ ë‚´ìš© ì¶”ê°€\n",
    "python\n",
    "ì½”ë“œ ë³µì‚¬\n",
    "for link in links[\"links\"]:\n",
    "    result += f\"\\n\\n{link['type']}\\n\"\n",
    "    result += Website(link[\"url\"]).get_contents()\n",
    "links[\"links\"] ì•ˆì— ìˆëŠ” ë§í¬ë“¤ì„ í•˜ë‚˜ì”© êº¼ë‚´ì„œ:\n",
    "\n",
    "link['type'] : í˜ì´ì§€ ìœ í˜•(About, Products ë“±) ì œëª©ì„ resultì— ì¶”ê°€\n",
    "\n",
    "Website(link[\"url\"]).get_contents() : ê·¸ í˜ì´ì§€ì˜ ì œëª©ê³¼ ë³¸ë¬¸ í…ìŠ¤íŠ¸ë¥¼ ê°€ì ¸ì™€ì„œ resultì— ì´ì–´ë¶™ì„.\n",
    "\n",
    "7. ìµœì¢… ê²°ê³¼ ë°˜í™˜\n",
    "python\n",
    "ì½”ë“œ ë³µì‚¬\n",
    "return result\n",
    "ë©”ì¸ í˜ì´ì§€ + ê´€ë ¨ ë§í¬ í˜ì´ì§€ë“¤ì˜ ë‚´ìš©ì„ í•œ ë©ì–´ë¦¬ë¡œ í•©ì¹œ ë¬¸ìì—´ì„ ëŒë ¤ì¤ë‹ˆë‹¤.\n",
    "\n",
    "ğŸ’¡ ì‰½ê²Œ ë¹„ìœ \n",
    "ì´ê±´ **â€œí™ˆí˜ì´ì§€ë‘, ì¤‘ìš”í•œ ë‹¤ë¥¸ í˜ì´ì§€ë“¤ê¹Œì§€ í•œ ë²ˆì— ìŠ¤í¬ë©í•´ì„œ í•œ ë¬¸ì„œë¡œ ëª¨ì•„ì£¼ëŠ” ìˆ˜ì§‘ê¸°â€**ì˜ˆìš”.\n",
    "\n",
    "1ë‹¨ê³„ : ë©”ì¸ í˜ì´ì§€ ë‚´ìš© ìˆ˜ì§‘\n",
    "\n",
    "2ë‹¨ê³„ : AIê°€ ì¤‘ìš”í•œ ë§í¬ ì¶”ì²œ\n",
    "\n",
    "3ë‹¨ê³„ : ê·¸ ë§í¬ í˜ì´ì§€ë“¤ ë‚´ìš© ìˆ˜ì§‘\n",
    "\n",
    "4ë‹¨ê³„ : ì „ë¶€ í•©ì³ì„œ í•˜ë‚˜ì˜ ê²°ê³¼ë¬¼ë¡œ ë°˜í™˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5dd885-e5b1-4587-b372-568e35e658b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ê·¸ëŸ¼ get_all_details()ê°€ ì‹¤í–‰ëì„ ë•Œ ë‚˜ì˜¬ ë²•í•œ ì˜ˆì‹œë¥¼ ë§Œë“¤ì–´ë“œë¦´ê²Œìš”.\n",
    "\n",
    "ê°€ì •\n",
    "URL: \"https://company.com\"\n",
    "\n",
    "get_links(url)ì´ ë°˜í™˜í•˜ëŠ” ê°’:\n",
    "\n",
    "python\n",
    "ì½”ë“œ ë³µì‚¬\n",
    "{\n",
    "    \"links\": [\n",
    "        {\"type\": \"About\", \"url\": \"https://company.com/about\"},\n",
    "        {\"type\": \"Products\", \"url\": \"https://company.com/products\"}\n",
    "    ]\n",
    "}\n",
    "ê° í˜ì´ì§€ì—ëŠ” ê°„ë‹¨í•œ ì œëª©ê³¼ ë³¸ë¬¸ì´ ìˆë‹¤ê³  ê°€ì •.\n",
    "\n",
    "ì‹¤í–‰ ì½”ë“œ\n",
    "python\n",
    "ì½”ë“œ ë³µì‚¬\n",
    "output = get_all_details(\"https://company.com\")\n",
    "print(output)\n",
    "ê²°ê³¼ ì˜ˆì‹œ\n",
    "yaml\n",
    "ì½”ë“œ ë³µì‚¬\n",
    "Landing page:\n",
    "Webpage Title:\n",
    "Company - Welcome\n",
    "Webpage Contents:\n",
    "Welcome to our company website.\n",
    "We offer a range of products and services to suit your needs.\n",
    "\n",
    "Found links: {\n",
    "    \"links\": [\n",
    "        {\"type\": \"About\", \"url\": \"https://company.com/about\"},\n",
    "        {\"type\": \"Products\", \"url\": \"https://company.com/products\"}\n",
    "    ]\n",
    "}\n",
    "\n",
    "About\n",
    "Webpage Title:\n",
    "About Us - Company\n",
    "Webpage Contents:\n",
    "Our company was founded in 2010 with the mission to deliver high-quality products worldwide.\n",
    "We value innovation, customer satisfaction, and sustainability.\n",
    "\n",
    "Products\n",
    "Webpage Title:\n",
    "Our Products - Company\n",
    "Webpage Contents:\n",
    "We offer electronics, home appliances, and software solutions.\n",
    "Visit our online store to learn more about each category.\n",
    "ğŸ“Œ íë¦„ ì •ë¦¬\n",
    "\n",
    "\"Landing page:\" â†’ ë©”ì¸ í˜ì´ì§€ ì œëª©ê³¼ ë³¸ë¬¸\n",
    "\n",
    "\"Found links: ...\" â†’ AIê°€ ê³ ë¥¸ ê´€ë ¨ ë§í¬ ì¶œë ¥\n",
    "\n",
    "ê° ë§í¬ì˜ typeê³¼ ê·¸ í˜ì´ì§€ì˜ ì œëª©Â·ë³¸ë¬¸ì„ ìˆœì„œëŒ€ë¡œ ì¶”ê°€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5099bd14-076d-4745-baf3-dac08d8e5ab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found links: {'links': [{'type': 'about page', 'url': 'https://huggingface.co'}, {'type': 'careers page', 'url': 'https://apply.workable.com/huggingface/'}, {'type': 'blog page', 'url': 'https://huggingface.co/blog'}, {'type': 'company page', 'url': 'https://www.linkedin.com/company/huggingface/'}, {'type': 'support page', 'url': 'https://discuss.huggingface.co'}, {'type': 'status page', 'url': 'https://status.huggingface.co'}]}\n",
      "Landing page:\n",
      "Webpage Title:\n",
      "Hugging Face â€“ The AI community building the future.\n",
      "Webpage Contents:\n",
      "Hugging Face\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Community\n",
      "Docs\n",
      "Enterprise\n",
      "Pricing\n",
      "Log In\n",
      "Sign Up\n",
      "The AI community building the future.\n",
      "The platform where the machine learning community collaborates on models, datasets, and applications.\n",
      "Explore AI Apps\n",
      "or\n",
      "Browse 1M+ models\n",
      "Trending on\n",
      "this week\n",
      "Models\n",
      "openai/gpt-oss-120b\n",
      "Updated\n",
      "3 days ago\n",
      "â€¢\n",
      "429k\n",
      "â€¢\n",
      "3.16k\n",
      "openai/gpt-oss-20b\n",
      "Updated\n",
      "3 days ago\n",
      "â€¢\n",
      "2M\n",
      "â€¢\n",
      "2.73k\n",
      "Qwen/Qwen-Image\n",
      "Updated\n",
      "5 days ago\n",
      "â€¢\n",
      "62.8k\n",
      "â€¢\n",
      "1.42k\n",
      "tencent/Hunyuan-1.8B-Instruct\n",
      "Updated\n",
      "5 days ago\n",
      "â€¢\n",
      "3.1k\n",
      "â€¢\n",
      "573\n",
      "rednote-hilab/dots.ocr\n",
      "Updated\n",
      "4 days ago\n",
      "â€¢\n",
      "16.2k\n",
      "â€¢\n",
      "563\n",
      "Browse 1M+ models\n",
      "Spaces\n",
      "Running\n",
      "on\n",
      "Zero\n",
      "415\n",
      "415\n",
      "Qwen Image\n",
      "ğŸ–¼\n",
      "Generate images from text prompts\n",
      "Running\n",
      "11.7k\n",
      "11.7k\n",
      "DeepSite v2\n",
      "ğŸ³\n",
      "Generate any application with DeepSeek\n",
      "Running\n",
      "on\n",
      "Zero\n",
      "264\n",
      "264\n",
      "FLUX.1 Krea Dev\n",
      "ğŸ“š\n",
      "Generate images from text prompts\n",
      "Running\n",
      "on\n",
      "Zero\n",
      "MCP\n",
      "282\n",
      "282\n",
      "Wan 2.2 5B\n",
      "ğŸš€\n",
      "Generate high-quality videos from text prompts and images\n",
      "Running\n",
      "on\n",
      "Zero\n",
      "120\n",
      "120\n",
      "OmniAvatar\n",
      "ğŸ¨\n",
      "Generate podcast and tiktok style video avatars\n",
      "Browse 400k+ applications\n",
      "Datasets\n",
      "fka/awesome-chatgpt-prompts\n",
      "Updated\n",
      "Jan 6\n",
      "â€¢\n",
      "32.4k\n",
      "â€¢\n",
      "8.65k\n",
      "jxm/gpt-oss20b-samples\n",
      "Updated\n",
      "3 days ago\n",
      "â€¢\n",
      "1.03k\n",
      "â€¢\n",
      "55\n",
      "HuggingFaceH4/Multilingual-Thinking\n",
      "Updated\n",
      "4 days ago\n",
      "â€¢\n",
      "6.15k\n",
      "â€¢\n",
      "44\n",
      "openai/BrowseCompLongContext\n",
      "Updated\n",
      "2 days ago\n",
      "â€¢\n",
      "568\n",
      "â€¢\n",
      "30\n",
      "nvidia/Nemotron-Post-Training-Dataset-v1\n",
      "Updated\n",
      "10 days ago\n",
      "â€¢\n",
      "15.9k\n",
      "â€¢\n",
      "103\n",
      "Browse 250k+ datasets\n",
      "The Home of Machine Learning\n",
      "Create, discover and collaborate on ML better.\n",
      "The collaboration platform\n",
      "Host and collaborate on unlimited public models, datasets and applications.\n",
      "Move faster\n",
      "With the HF Open source stack.\n",
      "Explore all modalities\n",
      "Text, image, video, audio or even 3D.\n",
      "Build your portfolio\n",
      "Share your work with the world and build your ML profile.\n",
      "Sign Up\n",
      "Accelerate your ML\n",
      "We provide paid Compute and Enterprise solutions.\n",
      "Compute\n",
      "Deploy on optimized\n",
      "Inference Endpoints\n",
      "or update your\n",
      "Spaces applications\n",
      "to a GPU in a few clicks.\n",
      "View pricing\n",
      "Starting at $0.60/hour for GPU\n",
      "Team & Enterprise\n",
      "Give your team the most advanced platform to build AI with enterprise-grade security, access controls and\n",
      "\t\t\tdedicated support.\n",
      "Getting started\n",
      "Starting at $20/user/month\n",
      "Single Sign-On\n",
      "Regions\n",
      "Priority Support\n",
      "Audit Logs\n",
      "Resource Groups\n",
      "Private Datasets Viewer\n",
      "More than 50,000 organizations are using Hugging Face\n",
      "Ai2\n",
      "Enterprise\n",
      "non-profit\n",
      "â€¢\n",
      "776 models\n",
      "â€¢\n",
      "3.78k followers\n",
      "AI at Meta\n",
      "Enterprise\n",
      "company\n",
      "â€¢\n",
      "2.2k models\n",
      "â€¢\n",
      "7.11k followers\n",
      "Amazon\n",
      "company\n",
      "â€¢\n",
      "20 models\n",
      "â€¢\n",
      "3.35k followers\n",
      "Google\n",
      "Enterprise\n",
      "company\n",
      "â€¢\n",
      "1.04k models\n",
      "â€¢\n",
      "23.9k followers\n",
      "Intel\n",
      "company\n",
      "â€¢\n",
      "239 models\n",
      "â€¢\n",
      "2.86k followers\n",
      "Microsoft\n",
      "company\n",
      "â€¢\n",
      "419 models\n",
      "â€¢\n",
      "14.1k followers\n",
      "Grammarly\n",
      "Team\n",
      "company\n",
      "â€¢\n",
      "10 models\n",
      "â€¢\n",
      "171 followers\n",
      "Writer\n",
      "Enterprise\n",
      "company\n",
      "â€¢\n",
      "21 models\n",
      "â€¢\n",
      "318 followers\n",
      "Our Open Source\n",
      "We are building the foundation of ML tooling with the community.\n",
      "Transformers\n",
      "148,174\n",
      "State-of-the-art AI models for PyTorch\n",
      "Diffusers\n",
      "30,205\n",
      "State-of-the-art Diffusion models in PyTorch\n",
      "Safetensors\n",
      "3,392\n",
      "Safe way to store/distribute neural network weights\n",
      "Hub Python Library\n",
      "2,831\n",
      "Python client to interact with the Hugging Face Hub\n",
      "Tokenizers\n",
      "9,978\n",
      "Fast tokenizers optimized for research & production\n",
      "TRL\n",
      "15,028\n",
      "Train transformers LMs with reinforcement learning\n",
      "Transformers.js\n",
      "14,316\n",
      "State-of-the-art ML running directly in your browser\n",
      "smolagents\n",
      "21,995\n",
      "Smol library to build great agents in Python\n",
      "PEFT\n",
      "19,281\n",
      "Parameter-efficient finetuning for large language models\n",
      "Datasets\n",
      "20,484\n",
      "Access & share datasets for any ML tasks\n",
      "Text Generation Inference\n",
      "10,412\n",
      "Serve language models with TGI optimized toolkit\n",
      "Accelerate\n",
      "9,021\n",
      "Train PyTorch models with multi-GPU, TPU, mixed precision\n",
      "System theme\n",
      "Website\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Changelog\n",
      "Inference Endpoints\n",
      "HuggingChat\n",
      "Company\n",
      "About\n",
      "Brand assets\n",
      "Terms of service\n",
      "Privacy\n",
      "Jobs\n",
      "Press\n",
      "Resources\n",
      "Learn\n",
      "Documentation\n",
      "Blog\n",
      "Forum\n",
      "Service Status\n",
      "Social\n",
      "GitHub\n",
      "Twitter\n",
      "LinkedIn\n",
      "Discord\n",
      "\n",
      "\n",
      "\n",
      "about page\n",
      "Webpage Title:\n",
      "Hugging Face â€“ The AI community building the future.\n",
      "Webpage Contents:\n",
      "Hugging Face\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Community\n",
      "Docs\n",
      "Enterprise\n",
      "Pricing\n",
      "Log In\n",
      "Sign Up\n",
      "The AI community building the future.\n",
      "The platform where the machine learning community collaborates on models, datasets, and applications.\n",
      "Explore AI Apps\n",
      "or\n",
      "Browse 1M+ models\n",
      "Trending on\n",
      "this week\n",
      "Models\n",
      "openai/gpt-oss-120b\n",
      "Updated\n",
      "3 days ago\n",
      "â€¢\n",
      "429k\n",
      "â€¢\n",
      "3.16k\n",
      "openai/gpt-oss-20b\n",
      "Updated\n",
      "3 days ago\n",
      "â€¢\n",
      "2M\n",
      "â€¢\n",
      "2.73k\n",
      "Qwen/Qwen-Image\n",
      "Updated\n",
      "5 days ago\n",
      "â€¢\n",
      "62.8k\n",
      "â€¢\n",
      "1.42k\n",
      "tencent/Hunyuan-1.8B-Instruct\n",
      "Updated\n",
      "5 days ago\n",
      "â€¢\n",
      "3.1k\n",
      "â€¢\n",
      "573\n",
      "rednote-hilab/dots.ocr\n",
      "Updated\n",
      "4 days ago\n",
      "â€¢\n",
      "16.2k\n",
      "â€¢\n",
      "563\n",
      "Browse 1M+ models\n",
      "Spaces\n",
      "Running\n",
      "on\n",
      "Zero\n",
      "415\n",
      "415\n",
      "Qwen Image\n",
      "ğŸ–¼\n",
      "Generate images from text prompts\n",
      "Running\n",
      "11.7k\n",
      "11.7k\n",
      "DeepSite v2\n",
      "ğŸ³\n",
      "Generate any application with DeepSeek\n",
      "Running\n",
      "on\n",
      "Zero\n",
      "264\n",
      "264\n",
      "FLUX.1 Krea Dev\n",
      "ğŸ“š\n",
      "Generate images from text prompts\n",
      "Running\n",
      "on\n",
      "Zero\n",
      "MCP\n",
      "282\n",
      "282\n",
      "Wan 2.2 5B\n",
      "ğŸš€\n",
      "Generate high-quality videos from text prompts and images\n",
      "Running\n",
      "on\n",
      "Zero\n",
      "120\n",
      "120\n",
      "OmniAvatar\n",
      "ğŸ¨\n",
      "Generate podcast and tiktok style video avatars\n",
      "Browse 400k+ applications\n",
      "Datasets\n",
      "fka/awesome-chatgpt-prompts\n",
      "Updated\n",
      "Jan 6\n",
      "â€¢\n",
      "32.4k\n",
      "â€¢\n",
      "8.65k\n",
      "jxm/gpt-oss20b-samples\n",
      "Updated\n",
      "3 days ago\n",
      "â€¢\n",
      "1.03k\n",
      "â€¢\n",
      "55\n",
      "HuggingFaceH4/Multilingual-Thinking\n",
      "Updated\n",
      "4 days ago\n",
      "â€¢\n",
      "6.15k\n",
      "â€¢\n",
      "44\n",
      "openai/BrowseCompLongContext\n",
      "Updated\n",
      "2 days ago\n",
      "â€¢\n",
      "568\n",
      "â€¢\n",
      "30\n",
      "nvidia/Nemotron-Post-Training-Dataset-v1\n",
      "Updated\n",
      "10 days ago\n",
      "â€¢\n",
      "15.9k\n",
      "â€¢\n",
      "103\n",
      "Browse 250k+ datasets\n",
      "The Home of Machine Learning\n",
      "Create, discover and collaborate on ML better.\n",
      "The collaboration platform\n",
      "Host and collaborate on unlimited public models, datasets and applications.\n",
      "Move faster\n",
      "With the HF Open source stack.\n",
      "Explore all modalities\n",
      "Text, image, video, audio or even 3D.\n",
      "Build your portfolio\n",
      "Share your work with the world and build your ML profile.\n",
      "Sign Up\n",
      "Accelerate your ML\n",
      "We provide paid Compute and Enterprise solutions.\n",
      "Compute\n",
      "Deploy on optimized\n",
      "Inference Endpoints\n",
      "or update your\n",
      "Spaces applications\n",
      "to a GPU in a few clicks.\n",
      "View pricing\n",
      "Starting at $0.60/hour for GPU\n",
      "Team & Enterprise\n",
      "Give your team the most advanced platform to build AI with enterprise-grade security, access controls and\n",
      "\t\t\tdedicated support.\n",
      "Getting started\n",
      "Starting at $20/user/month\n",
      "Single Sign-On\n",
      "Regions\n",
      "Priority Support\n",
      "Audit Logs\n",
      "Resource Groups\n",
      "Private Datasets Viewer\n",
      "More than 50,000 organizations are using Hugging Face\n",
      "Ai2\n",
      "Enterprise\n",
      "non-profit\n",
      "â€¢\n",
      "776 models\n",
      "â€¢\n",
      "3.78k followers\n",
      "AI at Meta\n",
      "Enterprise\n",
      "company\n",
      "â€¢\n",
      "2.2k models\n",
      "â€¢\n",
      "7.11k followers\n",
      "Amazon\n",
      "company\n",
      "â€¢\n",
      "20 models\n",
      "â€¢\n",
      "3.35k followers\n",
      "Google\n",
      "Enterprise\n",
      "company\n",
      "â€¢\n",
      "1.04k models\n",
      "â€¢\n",
      "23.9k followers\n",
      "Intel\n",
      "company\n",
      "â€¢\n",
      "239 models\n",
      "â€¢\n",
      "2.86k followers\n",
      "Microsoft\n",
      "company\n",
      "â€¢\n",
      "419 models\n",
      "â€¢\n",
      "14.1k followers\n",
      "Grammarly\n",
      "Team\n",
      "company\n",
      "â€¢\n",
      "10 models\n",
      "â€¢\n",
      "171 followers\n",
      "Writer\n",
      "Enterprise\n",
      "company\n",
      "â€¢\n",
      "21 models\n",
      "â€¢\n",
      "318 followers\n",
      "Our Open Source\n",
      "We are building the foundation of ML tooling with the community.\n",
      "Transformers\n",
      "148,174\n",
      "State-of-the-art AI models for PyTorch\n",
      "Diffusers\n",
      "30,205\n",
      "State-of-the-art Diffusion models in PyTorch\n",
      "Safetensors\n",
      "3,392\n",
      "Safe way to store/distribute neural network weights\n",
      "Hub Python Library\n",
      "2,831\n",
      "Python client to interact with the Hugging Face Hub\n",
      "Tokenizers\n",
      "9,978\n",
      "Fast tokenizers optimized for research & production\n",
      "TRL\n",
      "15,028\n",
      "Train transformers LMs with reinforcement learning\n",
      "Transformers.js\n",
      "14,316\n",
      "State-of-the-art ML running directly in your browser\n",
      "smolagents\n",
      "21,995\n",
      "Smol library to build great agents in Python\n",
      "PEFT\n",
      "19,281\n",
      "Parameter-efficient finetuning for large language models\n",
      "Datasets\n",
      "20,484\n",
      "Access & share datasets for any ML tasks\n",
      "Text Generation Inference\n",
      "10,412\n",
      "Serve language models with TGI optimized toolkit\n",
      "Accelerate\n",
      "9,021\n",
      "Train PyTorch models with multi-GPU, TPU, mixed precision\n",
      "System theme\n",
      "Website\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Changelog\n",
      "Inference Endpoints\n",
      "HuggingChat\n",
      "Company\n",
      "About\n",
      "Brand assets\n",
      "Terms of service\n",
      "Privacy\n",
      "Jobs\n",
      "Press\n",
      "Resources\n",
      "Learn\n",
      "Documentation\n",
      "Blog\n",
      "Forum\n",
      "Service Status\n",
      "Social\n",
      "GitHub\n",
      "Twitter\n",
      "LinkedIn\n",
      "Discord\n",
      "Zhihu\n",
      "WeChat\n",
      "\n",
      "\n",
      "\n",
      "careers page\n",
      "Webpage Title:\n",
      "Hugging Face - Current Openings\n",
      "Webpage Contents:\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "blog page\n",
      "Webpage Title:\n",
      "Hugging Face â€“ Blog\n",
      "Webpage Contents:\n",
      "Hugging Face\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Community\n",
      "Docs\n",
      "Enterprise\n",
      "Pricing\n",
      "Log In\n",
      "Sign Up\n",
      "Blog, Articles, and discussions\n",
      "New Article\n",
      "Everything\n",
      "community\n",
      "guide\n",
      "open source collab\n",
      "partnerships\n",
      "research\n",
      "NLP\n",
      "Audio\n",
      "CV\n",
      "RL\n",
      "ethics\n",
      "Diffusion\n",
      "Game Development\n",
      "RLHF\n",
      "Leaderboard\n",
      "Case Studies\n",
      "LeRobot\n",
      "Inference Providers\n",
      "Introducing AI Sheets: a tool to work with datasets using open AI models!\n",
      "By\n",
      "dvilasuero\n",
      "August 8, 2025\n",
      "â€¢\n",
      "26\n",
      "Community Articles\n",
      "view all\n",
      "What Open-Source Developers Need to Know about the EU AI Act's Rules for GPAI Models\n",
      "By\n",
      "yjernite\n",
      "and 5 others\n",
      "â€¢\n",
      "7 days ago\n",
      "â€¢\n",
      "23\n",
      "AWorld Multi-Agent System Hits #1 on GAIA Leaderboard\n",
      "By\n",
      "chengle\n",
      "â€¢\n",
      "4 days ago\n",
      "â€¢\n",
      "18\n",
      "Towards Open Evolutionary Agents\n",
      "By\n",
      "driaforall\n",
      "and 1 other\n",
      "â€¢\n",
      "7 days ago\n",
      "â€¢\n",
      "12\n",
      "The GPT-OSS models are hereâ€¦ and theyâ€™re energy-efficient!\n",
      "By\n",
      "sasha\n",
      "â€¢\n",
      "4 days ago\n",
      "â€¢\n",
      "12\n",
      "Code a simple RAG from scratch\n",
      "By\n",
      "ngxson\n",
      "â€¢\n",
      "Oct 29, 2024\n",
      "â€¢\n",
      "147\n",
      "Uncensor any LLM with abliteration\n",
      "By\n",
      "mlabonne\n",
      "â€¢\n",
      "Jun 13, 2024\n",
      "â€¢\n",
      "647\n",
      "LLM agent experiment with a purpose-built RPG and tool calls. (Work in progress)\n",
      "By\n",
      "neph1\n",
      "â€¢\n",
      "6 days ago\n",
      "â€¢\n",
      "7\n",
      "DeepSeek-R1 Dissection: Understanding PPO & GRPO Without Any Prior Reinforcement Learning Knowledge\n",
      "By\n",
      "NormalUhr\n",
      "â€¢\n",
      "Feb 7\n",
      "â€¢\n",
      "201\n",
      "Building Enterprise-Ready Text Classifiers in Minutes with Adaptive Learning\n",
      "By\n",
      "codelion\n",
      "â€¢\n",
      "2 days ago\n",
      "â€¢\n",
      "6\n",
      "ChatML vs Harmony: Understanding the new Format from OpenAI ğŸ”\n",
      "By\n",
      "kuotient\n",
      "â€¢\n",
      "2 days ago\n",
      "â€¢\n",
      "6\n",
      "Introducing ColQwen-Omni: Retrieve in every modality\n",
      "By\n",
      "manu\n",
      "and 4 others\n",
      "â€¢\n",
      "25 days ago\n",
      "â€¢\n",
      "64\n",
      "What I Learned Upscaling a Long-distance Midjourney Photo w/ Stable Diffusion PLUS unboxing Qwen Image & Wan 2.2\n",
      "By\n",
      "jasonhargrove\n",
      "â€¢\n",
      "3 days ago\n",
      "â€¢\n",
      "5\n",
      "Luth: Efficient French Specialization for Small Language Models\n",
      "By\n",
      "MaxLSB\n",
      "and 1 other\n",
      "â€¢\n",
      "about 4 hours ago\n",
      "â€¢\n",
      "5\n",
      "RynnVLA-001: Using Human Demonstrations to Improve Robot Manipulation\n",
      "By\n",
      "Alibaba-DAMO-Academy\n",
      "and 9 others\n",
      "â€¢\n",
      "about 3 hours ago\n",
      "â€¢\n",
      "5\n",
      "makeMoE: Implement a Sparse Mixture of Experts Language Model from Scratch\n",
      "By\n",
      "AviSoori1x\n",
      "â€¢\n",
      "May 7, 2024\n",
      "â€¢\n",
      "93\n",
      "G2P Shrinks Speech Models\n",
      "By\n",
      "hexgrad\n",
      "â€¢\n",
      "Feb 5\n",
      "â€¢\n",
      "66\n",
      "Measuring Open-Source Llama Nemotron Models on DeepResearch Bench\n",
      "By\n",
      "nvidia\n",
      "â€¢\n",
      "7 days ago\n",
      "â€¢\n",
      "4\n",
      "From GRPO to DAPO and GSPO: What, Why, and How\n",
      "By\n",
      "NormalUhr\n",
      "â€¢\n",
      "2 days ago\n",
      "â€¢\n",
      "4\n",
      "OpenAI just dropped two massive open-weight models â€” *but how do we separate the reality from the hype?*\n",
      "By\n",
      "stefanwebb\n",
      "and 2 others\n",
      "â€¢\n",
      "1 day ago\n",
      "â€¢\n",
      "4\n",
      "ColPali: Efficient Document Retrieval with Vision Language Models ğŸ‘€\n",
      "By\n",
      "manu\n",
      "â€¢\n",
      "Jul 5, 2024\n",
      "â€¢\n",
      "286\n",
      "Accelerate ND-Parallel: A Guide to Efficient Multi-GPU Training\n",
      "By\n",
      "siro1\n",
      "August 8, 2025\n",
      "â€¢\n",
      "32\n",
      "Vision Language Model Alignment in TRL âš¡ï¸\n",
      "By\n",
      "sergiopaniego\n",
      "August 7, 2025\n",
      "â€¢\n",
      "37\n",
      "Welcome GPT OSS, the new open-source model family from OpenAI!\n",
      "By\n",
      "reach-vb\n",
      "August 5, 2025\n",
      "â€¢\n",
      "434\n",
      "Build an AI Shopping Assistant with Gradio MCP Servers\n",
      "By\n",
      "freddyaboulton\n",
      "July 31, 2025\n",
      "â€¢\n",
      "35\n",
      "Introducing Trackio: A Lightweight Experiment Tracking Library from Hugging Face\n",
      "By\n",
      "abidlabs\n",
      "July 29, 2025\n",
      "â€¢\n",
      "144\n",
      "Say hello to `hf`: a faster, friendlier Hugging Face CLI âœ¨\n",
      "By\n",
      "Wauplin\n",
      "July 25, 2025\n",
      "â€¢\n",
      "70\n",
      "Parquet Content-Defined Chunking\n",
      "By\n",
      "kszucs\n",
      "July 25, 2025\n",
      "â€¢\n",
      "54\n",
      "TimeScope: How Long Can Your Video Large Multimodal Model Go?\n",
      "By\n",
      "orrzohar\n",
      "July 23, 2025\n",
      "â€¢\n",
      "34\n",
      "Fast LoRA inference for Flux with Diffusers and PEFT\n",
      "By\n",
      "sayakpaul\n",
      "July 23, 2025\n",
      "â€¢\n",
      "42\n",
      "Arc Virtual Cell Challenge: A Primer\n",
      "By\n",
      "FL33TW00D-HF\n",
      "July 18, 2025\n",
      "â€¢\n",
      "50\n",
      "Consilium: When Multiple LLMs Collaborate\n",
      "By\n",
      "azettl\n",
      "July 17, 2025\n",
      "guest\n",
      "â€¢\n",
      "21\n",
      "Back to The Future: Evaluating AI Agents on Predicting Future Events\n",
      "By\n",
      "vinid\n",
      "July 17, 2025\n",
      "guest\n",
      "â€¢\n",
      "31\n",
      "Five Big Improvements to Gradio MCP Servers\n",
      "By\n",
      "freddyaboulton\n",
      "July 17, 2025\n",
      "â€¢\n",
      "20\n",
      "Seq vs Seq: the Ettin Suite of Paired Encoders and Decoders\n",
      "By\n",
      "orionweller\n",
      "July 16, 2025\n",
      "â€¢\n",
      "57\n",
      "Previous\n",
      "1\n",
      "2\n",
      "3\n",
      "...\n",
      "44\n",
      "Next\n",
      "Community Articles\n",
      "Sort:Â \n",
      "\t\tTrending\n",
      "What Open-Source Developers Need to Know about the EU AI Act's Rules for GPAI Models\n",
      "By\n",
      "yjernite\n",
      "and 5 others\n",
      "â€¢\n",
      "7 days ago\n",
      "â€¢\n",
      "23\n",
      "AWorld Multi-Agent System Hits #1 on GAIA Leaderboard\n",
      "By\n",
      "chengle\n",
      "â€¢\n",
      "4 days ago\n",
      "â€¢\n",
      "18\n",
      "Towards Open Evolutionary Agents\n",
      "By\n",
      "driaforall\n",
      "and 1 other\n",
      "â€¢\n",
      "7 days ago\n",
      "â€¢\n",
      "12\n",
      "The GPT-OSS models are hereâ€¦ and theyâ€™re energy-efficient!\n",
      "By\n",
      "sasha\n",
      "â€¢\n",
      "4 days ago\n",
      "â€¢\n",
      "12\n",
      "Code a simple RAG from scratch\n",
      "By\n",
      "ngxson\n",
      "â€¢\n",
      "Oct 29, 2024\n",
      "â€¢\n",
      "147\n",
      "Uncensor any LLM with abliteration\n",
      "By\n",
      "mlabonne\n",
      "â€¢\n",
      "Jun 13, 2024\n",
      "â€¢\n",
      "647\n",
      "LLM agent experiment with a purpose-built RPG and tool calls. (Work in progress)\n",
      "By\n",
      "neph1\n",
      "â€¢\n",
      "6 days ago\n",
      "â€¢\n",
      "7\n",
      "DeepSeek-R1 Dissection: Understanding PPO & GRPO Without Any Prior Reinforcement Learning Knowledge\n",
      "By\n",
      "NormalUhr\n",
      "â€¢\n",
      "Feb 7\n",
      "â€¢\n",
      "201\n",
      "Building Enterprise-Ready Text Classifiers in Minutes with Adaptive Learning\n",
      "By\n",
      "codelion\n",
      "â€¢\n",
      "2 days ago\n",
      "â€¢\n",
      "6\n",
      "ChatML vs Harmony: Understanding the new Format from OpenAI ğŸ”\n",
      "By\n",
      "kuotient\n",
      "â€¢\n",
      "2 days ago\n",
      "â€¢\n",
      "6\n",
      "Introducing ColQwen-Omni: Retrieve in every modality\n",
      "By\n",
      "manu\n",
      "and 4 others\n",
      "â€¢\n",
      "25 days ago\n",
      "â€¢\n",
      "64\n",
      "What I Learned Upscaling a Long-distance Midjourney Photo w/ Stable Diffusion PLUS unboxing Qwen Image & Wan 2.2\n",
      "By\n",
      "jasonhargrove\n",
      "â€¢\n",
      "3 days ago\n",
      "â€¢\n",
      "5\n",
      "Luth: Efficient French Specialization for Small Language Models\n",
      "By\n",
      "MaxLSB\n",
      "and 1 other\n",
      "â€¢\n",
      "about 4 hours ago\n",
      "â€¢\n",
      "5\n",
      "RynnVLA-001: Using Human Demonstrations to Improve Robot Manipulation\n",
      "By\n",
      "Alibaba-DAMO-Academy\n",
      "and 9 others\n",
      "â€¢\n",
      "about 3 hours ago\n",
      "â€¢\n",
      "5\n",
      "makeMoE: Implement a Sparse Mixture of Experts Language Model from Scratch\n",
      "By\n",
      "AviSoori1x\n",
      "â€¢\n",
      "May 7, 2024\n",
      "â€¢\n",
      "93\n",
      "G2P Shrinks Speech Models\n",
      "By\n",
      "hexgrad\n",
      "â€¢\n",
      "Feb 5\n",
      "â€¢\n",
      "66\n",
      "Measuring Open-Source Llama Nemotron Models on DeepResearch Bench\n",
      "By\n",
      "nvidia\n",
      "â€¢\n",
      "7 days ago\n",
      "â€¢\n",
      "4\n",
      "From GRPO to DAPO and GSPO: What, Why, and How\n",
      "By\n",
      "NormalUhr\n",
      "â€¢\n",
      "2 days ago\n",
      "â€¢\n",
      "4\n",
      "OpenAI just dropped two massive open-weight models â€” *but how do we separate the reality from the hype?*\n",
      "By\n",
      "stefanwebb\n",
      "and 2 others\n",
      "â€¢\n",
      "1 day ago\n",
      "â€¢\n",
      "4\n",
      "ColPali: Efficient Document Retrieval with Vision Language Models ğŸ‘€\n",
      "By\n",
      "manu\n",
      "â€¢\n",
      "Jul 5, 2024\n",
      "â€¢\n",
      "286\n",
      "View all\n",
      "System theme\n",
      "Company\n",
      "TOS\n",
      "Privacy\n",
      "About\n",
      "Jobs\n",
      "Website\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Pricing\n",
      "Docs\n",
      "\n",
      "\n",
      "\n",
      "company page\n",
      "Webpage Title:\n",
      "Hugging Face | LinkedIn\n",
      "Webpage Contents:\n",
      "Skip to main content\n",
      "LinkedIn\n",
      "Top Content\n",
      "People\n",
      "Learning\n",
      "Jobs\n",
      "Games\n",
      "Get the app\n",
      "Join now\n",
      "Sign in\n",
      "Hugging Face\n",
      "Software Development\n",
      "The AI community building the future.\n",
      "See jobs\n",
      "Follow\n",
      "Discover all 602 employees\n",
      "Report this company\n",
      "About us\n",
      "The AI community building the future.\n",
      "Website\n",
      "https://huggingface.co\n",
      "External link for Hugging Face\n",
      "Industry\n",
      "Software Development\n",
      "Company size\n",
      "51-200 employees\n",
      "Type\n",
      "Privately Held\n",
      "Founded\n",
      "2016\n",
      "Specialties\n",
      "machine learning, natural language processing, and deep learning\n",
      "Products\n",
      "Hugging Face\n",
      "Hugging Face\n",
      "Natural Language Processing (NLP) Software\n",
      "Weâ€™re on a journey to solve and democratize artificial intelligence through natural language.\n",
      "Locations\n",
      "Primary\n",
      "Get directions\n",
      "Paris, FR\n",
      "Get directions\n",
      "Employees at Hugging Face\n",
      "Ludovic Huraux\n",
      "Rajat Arya\n",
      "Tech Lead & Software Engineer @ HF | prev: co-founder XetHub, Apple, Turi, AWS, Microsoft\n",
      "Jeff Boudier\n",
      "Product + Growth at Hugging Face\n",
      "Terrence Rohan\n",
      "Seed Investor\n",
      "See all employees\n",
      "Updates\n",
      "Hugging Face\n",
      "reposted this\n",
      "Gradio\n",
      "68,519 followers\n",
      "3h\n",
      "Edited\n",
      "Report this post\n",
      "LIA-X, the Portrait Animator! ğŸ”¥ Animate your portraits, or ğŸ†• Edit your talking head in videos -- neck, mouth, cheek, and eyes region.\n",
      "\n",
      "Gradio app released on\n",
      "Hugging Face\n",
      ":\n",
      "https://lnkd.in/gkzKsTfv\n",
      "â€¦more\n",
      "20\n",
      "1 Comment\n",
      "Like\n",
      "Comment\n",
      "Share\n",
      "Hugging Face\n",
      "1,033,968 followers\n",
      "2d\n",
      "Report this post\n",
      "ğŸ¦¾ğŸ¦¾ğŸ¦¾\n",
      "Clem Delangue ğŸ¤—\n",
      "Clem Delangue ğŸ¤— is an Influencer\n",
      "Co-founder & CEO at Hugging Face\n",
      "2d\n",
      "So excited to announce that\n",
      "Hugging Face\n",
      "LeRobot can now be installed with a simple pip install and just crossed 15,000\n",
      "GitHub\n",
      "stars!\n",
      "\n",
      "It's already integrated into hundreds of robots, ranging from simple hand grippers like the SO-100/101 all the way to some of the most complex humanoid robots like\n",
      "Pollen Robotics\n",
      "Reachy 2.\n",
      "\n",
      "Thanks to all contributors of policies, models & datasets (like\n",
      "NVIDIA\n",
      ",\n",
      "Physical Intelligence\n",
      ",\n",
      "Microsoft\n",
      ", SmolVLA,...) who already shared over 1,500 models & 15,000 datasets, it's becoming the standard to bridge hardware and software in AI robotics.\n",
      "\n",
      "Let's go open AI robotics ğŸ¦¾ğŸ¦¾ğŸ¦¾\n",
      "226\n",
      "6 Comments\n",
      "Like\n",
      "Comment\n",
      "Share\n",
      "Hugging Face\n",
      "reposted this\n",
      "Daniel Vila Suero\n",
      "Building data tools @ Hugging Face ğŸ¤—\n",
      "2d\n",
      "Report this post\n",
      "Tired of just reading about how good or bad the latest AI models are? Introducing\n",
      "Hugging Face\n",
      "AI Sheets, the open-source tool for getting data work done ğŸ‘‡ \n",
      "\n",
      "\n",
      "I'm super excited to release this open-source tool for the community.\n",
      "\n",
      "It lets you experiment with thousands of models on data you care about! \n",
      "\n",
      "You can run it on the Hub or locally (yes, it works with local models too).\n",
      "\n",
      "Let's go open source AI!\n",
      "\n",
      "Repo:\n",
      "https://lnkd.in/gdKeV-zW\n",
      "Blog post in the first comment.\n",
      "141\n",
      "10 Comments\n",
      "Like\n",
      "Comment\n",
      "Share\n",
      "Hugging Face\n",
      "reposted this\n",
      "Gradio\n",
      "68,519 followers\n",
      "3d\n",
      "Report this post\n",
      "Introducing\n",
      "https://gpt.gradio.app/\n",
      ", now you can chat with\n",
      "OpenAI\n",
      "'s latest gpt-oss models and use thousands of\n",
      "Hugging Face\n",
      "Spaces as MCP servers.\n",
      "â€¦more\n",
      "124\n",
      "5 Comments\n",
      "Like\n",
      "Comment\n",
      "Share\n",
      "Hugging Face\n",
      "reposted this\n",
      "Daniel van Strien\n",
      "Machine Learning Librarian at Hugging Face ğŸ¤— | Making AI work for libraries, archives, and their communities\n",
      "3d\n",
      "Report this post\n",
      "What if OCR models could show you their thought process?\n",
      "\n",
      "NuMarkdown-8B-Thinking from\n",
      "NuMind (YC S22)\n",
      "doesn't just extract text - it reasons through documents first, showing you exactly HOW it analyses structure before converting to markdown.\n",
      "\n",
      "Could this be particularly useful for challenging historical documents? \n",
      "Â \n",
      "- Complex multi-column layouts? It thinks through the reading order\n",
      "- Nested tables with merged cells? It maps the structure first\n",
      "- Mixed fonts and decorative elements? It identifies what's content vs decoration\n",
      "\n",
      "Here's it analysing a 1878 medical report from Calcutta (from the\n",
      "National Library of Scotland\n",
      ") - you can literally see it thinking through the layout step-by-step before extraction.\n",
      "\n",
      "You can try the model easily yourself thanks to\n",
      "Hugging Face\n",
      "Jobs and\n",
      "Astral\n",
      "uv\n",
      "\n",
      "hf jobs uv run --flavor l4x4 \\\n",
      "[\n",
      "script-url.html\n",
      "] \\\n",
      "your-dataset \\\n",
      "output-dataset \\\n",
      "--include-thinking\n",
      "\n",
      "My UV Scripts OCR collection now has 3 VLM based OCR models:\n",
      "Â ğŸš€ RolmOCR - one of the OG of the recent OCR VLMs from\n",
      "Reducto\n",
      "ğŸ“ Nanonets - LaTeX & complex tables\n",
      "Â ğŸ§  NuMarkdown - Reasoning-based (NEW!) from\n",
      "NuMind (YC S22)\n",
      "All can be run easily against an existing\n",
      "Hugging Face\n",
      "dataset with no setup! \n",
      "\n",
      "You can view the results on OCR Time Capsule:\n",
      "https://lnkd.in/eyX4zJhK\n",
      ".\n",
      "\n",
      "Full collection of OCR scripts:\n",
      "https://lnkd.in/eDmzb5Hv\n",
      "#DigitalHumanities\n",
      "#OCR\n",
      "#GLAM\n",
      "#MachineLearning\n",
      "#AI\n",
      "652\n",
      "23 Comments\n",
      "Like\n",
      "Comment\n",
      "Share\n",
      "Hugging Face\n",
      "reposted this\n",
      "Merve Noyan\n",
      "open-sourceress at ğŸ¤—\n",
      "3d\n",
      "Report this post\n",
      "new TRL comes with GRPO & MPO support for vision language models ğŸ’¥\n",
      "\n",
      "we also dropped an explainer on them & how to train with one-liner CLI commands ğŸ«¡ \n",
      "find it in comments ğŸ’¬\n",
      "204\n",
      "3 Comments\n",
      "Like\n",
      "Comment\n",
      "Share\n",
      "Hugging Face\n",
      "reposted this\n",
      "Gradio\n",
      "68,519 followers\n",
      "4d\n",
      "Report this post\n",
      "ChatGPT, but with access to 2700+ MCP Servers ğŸ¤¯ \n",
      "\n",
      "Much before 10 am PT ğŸ˜‰ Stay tuned!\n",
      "â€¦more\n",
      "86\n",
      "3 Comments\n",
      "Like\n",
      "Comment\n",
      "Share\n",
      "Hugging Face\n",
      "reposted this\n",
      "Daniel van Strien\n",
      "Machine Learning Librarian at Hugging Face ğŸ¤— | Making AI work for libraries, archives, and their communities\n",
      "5d\n",
      "Report this post\n",
      "Generate synthetic data using\n",
      "OpenAI\n",
      "'s GPT OSS models on\n",
      "Hugging Face\n",
      "Jobs!\n",
      "\n",
      "I just shipped a simple script that runs with one command - no local setup needed (powered by\n",
      "Astral\n",
      "'s uv under the hood!) \n",
      "\n",
      "Â hf jobs uv run --flavor l4x4Â Â SCRIPT_URLÂ Â --input-dataset your/datasetÂ Â --output-dataset your/output\n",
      "\n",
      "Â - Works on L4 GPUs\n",
      "Â - Captures reasoning traces\n",
      "Â - Auto-handles dataset upload\n",
      "\n",
      "I already used it to generate some low reasoning effort haiku! \n",
      "\n",
      "Check it out:\n",
      "https://lnkd.in/eQbc2484\n",
      "#AI\n",
      "#MachineLearning\n",
      "#OpenSource\n",
      "#SyntheticData\n",
      "198\n",
      "5 Comments\n",
      "Like\n",
      "Comment\n",
      "Share\n",
      "Hugging Face\n",
      "1,033,968 followers\n",
      "5d\n",
      "Report this post\n",
      "Welcome to\n",
      "OpenAI\n",
      "on\n",
      "Hugging Face\n",
      "!\n",
      "613\n",
      "17 Comments\n",
      "Like\n",
      "Comment\n",
      "Share\n",
      "Join now to see what you are missing\n",
      "Find people you know at Hugging Face\n",
      "Browse recommended jobs for you\n",
      "View all updates, news, and articles\n",
      "Join now\n",
      "Similar pages\n",
      "Anthropic\n",
      "Research Services\n",
      "Perplexity\n",
      "Software Development\n",
      "San Francisco, California\n",
      "Mistral AI\n",
      "Technology, Information and Internet\n",
      "Paris, France\n",
      "OpenAI\n",
      "Research Services\n",
      "San Francisco, CA\n",
      "LangChain\n",
      "Technology, Information and Internet\n",
      "Generative AI\n",
      "Technology, Information and Internet\n",
      "Google DeepMind\n",
      "Research Services\n",
      "London, London\n",
      "DeepLearning.AI\n",
      "Software Development\n",
      "Palo Alto, California\n",
      "Cohere\n",
      "Software Development\n",
      "Toronto, Ontario\n",
      "LlamaIndex\n",
      "Technology, Information and Internet\n",
      "San Francisco, California\n",
      "Show more similar pages\n",
      "Show fewer similar pages\n",
      "Browse jobs\n",
      "Engineer jobs\n",
      "555,845 open jobs\n",
      "Machine Learning Engineer jobs\n",
      "148,937 open jobs\n",
      "Scientist jobs\n",
      "48,969 open jobs\n",
      "Software Engineer jobs\n",
      "300,699 open jobs\n",
      "Analyst jobs\n",
      "694,057 open jobs\n",
      "Intern jobs\n",
      "71,196 open jobs\n",
      "Developer jobs\n",
      "258,935 open jobs\n",
      "Manager jobs\n",
      "1,880,925 open jobs\n",
      "Product Manager jobs\n",
      "199,941 open jobs\n",
      "Director jobs\n",
      "1,220,357 open jobs\n",
      "Python Developer jobs\n",
      "46,642 open jobs\n",
      "Data Scientist jobs\n",
      "264,158 open jobs\n",
      "Data Analyst jobs\n",
      "329,009 open jobs\n",
      "Senior Software Engineer jobs\n",
      "78,145 open jobs\n",
      "Project Manager jobs\n",
      "253,048 open jobs\n",
      "Researcher jobs\n",
      "195,654 open jobs\n",
      "Associate jobs\n",
      "1,091,945 open jobs\n",
      "Data Engineer jobs\n",
      "192,126 open jobs\n",
      "Vice President jobs\n",
      "235,270 open jobs\n",
      "Specialist jobs\n",
      "768,666 open jobs\n",
      "Show more jobs like this\n",
      "Show fewer jobs like this\n",
      "Funding\n",
      "Hugging Face\n",
      "8 total rounds\n",
      "Last Round\n",
      "Series unknown\n",
      "Sep 1, 2024\n",
      "External Crunchbase Link for last round of funding\n",
      "See more info on\n",
      "crunchbase\n",
      "More searches\n",
      "More searches\n",
      "Engineer jobs\n",
      "Scientist jobs\n",
      "Machine Learning Engineer jobs\n",
      "Software Engineer jobs\n",
      "Intern jobs\n",
      "Developer jobs\n",
      "Analyst jobs\n",
      "Manager jobs\n",
      "Senior Software Engineer jobs\n",
      "Data Scientist jobs\n",
      "Researcher jobs\n",
      "Product Manager jobs\n",
      "Director jobs\n",
      "Associate jobs\n",
      "Intelligence Specialist jobs\n",
      "Data Analyst jobs\n",
      "Data Science Specialist jobs\n",
      "Python Developer jobs\n",
      "Quantitative Analyst jobs\n",
      "Project Manager jobs\n",
      "Account Executive jobs\n",
      "Specialist jobs\n",
      "Data Engineer jobs\n",
      "Designer jobs\n",
      "Quantitative Researcher jobs\n",
      "Consultant jobs\n",
      "Solutions Architect jobs\n",
      "Vice President jobs\n",
      "User Experience Designer jobs\n",
      "Head jobs\n",
      "Full Stack Engineer jobs\n",
      "Engineering Manager jobs\n",
      "Software Engineer Intern jobs\n",
      "Junior Software Engineer jobs\n",
      "Software Intern jobs\n",
      "Product Designer jobs\n",
      "Solutions Engineer jobs\n",
      "Staff Software Engineer jobs\n",
      "Program Manager jobs\n",
      "Senior Scientist jobs\n",
      "Writer jobs\n",
      "Research Intern jobs\n",
      "Senior Product Manager jobs\n",
      "Summer Intern jobs\n",
      "Account Manager jobs\n",
      "Recruiter jobs\n",
      "Lead jobs\n",
      "Research Engineer jobs\n",
      "Computer Science Intern jobs\n",
      "Platform Engineer jobs\n",
      "Junior Developer jobs\n",
      "Android Developer jobs\n",
      "User Experience Researcher jobs\n",
      "Java Software Engineer jobs\n",
      "Site Reliability Engineer jobs\n",
      "Graduate jobs\n",
      "Software Engineering Manager jobs\n",
      "Representative jobs\n",
      "Business Development Specialist jobs\n",
      "Computer Engineer jobs\n",
      "LinkedIn\n",
      "Â© 2025\n",
      "About\n",
      "Accessibility\n",
      "User Agreement\n",
      "Privacy Policy\n",
      "Cookie Policy\n",
      "Copyright Policy\n",
      "Brand Policy\n",
      "Guest Controls\n",
      "Community Guidelines\n",
      "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© (Arabic)\n",
      "à¦¬à¦¾à¦‚à¦²à¦¾ (Bangla)\n",
      "ÄŒeÅ¡tina (Czech)\n",
      "Dansk (Danish)\n",
      "Deutsch (German)\n",
      "Î•Î»Î»Î·Î½Î¹ÎºÎ¬ (Greek)\n",
      "English (English)\n",
      "EspaÃ±ol (Spanish)\n",
      "ÙØ§Ø±Ø³ÛŒ (Persian)\n",
      "Suomi (Finnish)\n",
      "FranÃ§ais (French)\n",
      "à¤¹à¤¿à¤‚à¤¦à¥€ (Hindi)\n",
      "Magyar (Hungarian)\n",
      "Bahasa Indonesia (Indonesian)\n",
      "Italiano (Italian)\n",
      "×¢×‘×¨×™×ª (Hebrew)\n",
      "æ—¥æœ¬èª (Japanese)\n",
      "í•œêµ­ì–´ (Korean)\n",
      "à¤®à¤°à¤¾à¤ à¥€ (Marathi)\n",
      "Bahasa Malaysia (Malay)\n",
      "Nederlands (Dutch)\n",
      "Norsk (Norwegian)\n",
      "à¨ªà©°à¨œà¨¾à¨¬à©€ (Punjabi)\n",
      "Polski (Polish)\n",
      "PortuguÃªs (Portuguese)\n",
      "RomÃ¢nÄƒ (Romanian)\n",
      "Ğ ÑƒÑÑĞºĞ¸Ğ¹ (Russian)\n",
      "Svenska (Swedish)\n",
      "à°¤à±†à°²à±à°—à± (Telugu)\n",
      "à¸ à¸²à¸©à¸²à¹„à¸—à¸¢ (Thai)\n",
      "Tagalog (Tagalog)\n",
      "TÃ¼rkÃ§e (Turkish)\n",
      "Ğ£ĞºÑ€Ğ°Ñ—Ğ½ÑÑŒĞºĞ° (Ukrainian)\n",
      "Tiáº¿ng Viá»‡t (Vietnamese)\n",
      "ç®€ä½“ä¸­æ–‡ (Chinese (Simplified))\n",
      "æ­£é«”ä¸­æ–‡ (Chinese (Traditional))\n",
      "Language\n",
      "Agree & Join LinkedIn\n",
      "By clicking Continue to join or sign in, you agree to LinkedInâ€™s\n",
      "User Agreement\n",
      ",\n",
      "Privacy Policy\n",
      ", and\n",
      "Cookie Policy\n",
      ".\n",
      "Sign in to see who you already know at Hugging Face\n",
      "Sign in\n",
      "Welcome back\n",
      "Email or phone\n",
      "Password\n",
      "Show\n",
      "Forgot password?\n",
      "Sign in\n",
      "or\n",
      "By clicking Continue to join or sign in, you agree to LinkedInâ€™s\n",
      "User Agreement\n",
      ",\n",
      "Privacy Policy\n",
      ", and\n",
      "Cookie Policy\n",
      ".\n",
      "New to LinkedIn?\n",
      "Join now\n",
      "or\n",
      "New to LinkedIn?\n",
      "Join now\n",
      "By clicking Continue to join or sign in, you agree to LinkedInâ€™s\n",
      "User Agreement\n",
      ",\n",
      "Privacy Policy\n",
      ", and\n",
      "Cookie Policy\n",
      ".\n",
      "LinkedIn\n",
      "LinkedIn is better on the app\n",
      "Donâ€™t have the app? Get it in the Microsoft Store.\n",
      "Open the app\n",
      "\n",
      "\n",
      "\n",
      "support page\n",
      "Webpage Title:\n",
      "Hugging Face Forums - Hugging Face Community Discussion\n",
      "Webpage Contents:\n",
      "Hugging Face Forums\n",
      "Topic\n",
      "Replies\n",
      "Views\n",
      "Activity\n",
      "Local LLM and ML platform with RTX 5090 GPU\n",
      "Show and Tell\n",
      "2\n",
      "6\n",
      "August 11, 2025\n",
      "How to fine-tune an LLM model with an entire document in a format such as *.txt/docx/pdf ect\n",
      "ğŸ¤—AutoTrain\n",
      "7\n",
      "7320\n",
      "August 11, 2025\n",
      "Struggling to Build an AI That Can Detect â€œNot Goodâ€ vs â€œGoodâ€ Environment Photos\n",
      "Beginners\n",
      "0\n",
      "7\n",
      "August 11, 2025\n",
      "Privacy question\n",
      "Spaces\n",
      "2\n",
      "12\n",
      "August 11, 2025\n",
      "Organization Verification Stuck on â€˜Pendingâ€™\n",
      "Beginners\n",
      "1\n",
      "7\n",
      "August 11, 2025\n",
      "Zero GPU Worker Error\n",
      "Spaces\n",
      "30\n",
      "267\n",
      "August 11, 2025\n",
      "Latest llama.cpp won't build in Spaces\n",
      "Spaces\n",
      "1\n",
      "8\n",
      "August 11, 2025\n",
      "Can't get my uzu model.... got the token but still gated?\n",
      "Models\n",
      "0\n",
      "6\n",
      "August 11, 2025\n",
      "Under 500 MB in storage, but indicates 1 GB\n",
      "Site Feedback\n",
      "1\n",
      "8\n",
      "August 10, 2025\n",
      "Getting this error while trying to access Mistral model using Streamlit\n",
      "Models\n",
      "1\n",
      "9\n",
      "August 11, 2025\n",
      "[Runtime Error] Using Undistro (Wolfi OS) in HF Docker Spaces\n",
      "Spaces\n",
      "1\n",
      "11\n",
      "August 10, 2025\n",
      "ChatGPT 5 An Initial Review\n",
      "Research\n",
      "11\n",
      "169\n",
      "August 10, 2025\n",
      "How to run validation on multiple evaluation datasets simultaneously during Qwen2.5-VL-7B-Instruct fine-tuning?\n",
      "ğŸ¤—Transformers\n",
      "2\n",
      "15\n",
      "August 10, 2025\n",
      "Error with Doc-Builder in smolagents documentation NotFound[Error]\n",
      "Beginners\n",
      "3\n",
      "16\n",
      "August 10, 2025\n",
      "Looking for Datasets for Session Understanding by LLMs\n",
      "Research\n",
      "1\n",
      "20\n",
      "August 9, 2025\n",
      "Defaulting to the same model - Smolagents\n",
      "Beginners\n",
      "2\n",
      "15\n",
      "August 9, 2025\n",
      "Reward Hacking Solutions\n",
      "Research\n",
      "0\n",
      "18\n",
      "August 9, 2025\n",
      "Need Help in creating ai chatbot for my app\n",
      "Intermediate\n",
      "22\n",
      "119\n",
      "August 8, 2025\n",
      "Feedback on LLM-as-a-Judge design for open-source library\n",
      "Show and Tell\n",
      "0\n",
      "11\n",
      "August 9, 2025\n",
      "Ai conscious base\n",
      "Research\n",
      "20\n",
      "154\n",
      "August 11, 2025\n",
      "Error while initializing ZeroGPU\n",
      "Models\n",
      "13\n",
      "198\n",
      "August 10, 2025\n",
      "LLM Recommendation for unstructured text to json file converrsion?\n",
      "Beginners\n",
      "1\n",
      "29\n",
      "August 8, 2025\n",
      "Process of High Quality Chat Dataset Synthesis\n",
      "Intermediate\n",
      "4\n",
      "25\n",
      "August 8, 2025\n",
      "Could Qwen Be the Best Alternative to Claude Code?\n",
      "Beginners\n",
      "4\n",
      "442\n",
      "August 5, 2025\n",
      "Storage Usage never update?\n",
      "Beginners\n",
      "3\n",
      "11\n",
      "August 9, 2025\n",
      "Can you use PAYG for an entreprise without a Team/Entreprise plan?\n",
      "Beginners\n",
      "6\n",
      "21\n",
      "August 7, 2025\n",
      "ValueError: Image path is None/Invalid Imagedata dictionary\n",
      "Spaces\n",
      "2\n",
      "60\n",
      "August 10, 2025\n",
      "Help Needed: LLM Model for Summarization\n",
      "Beginners\n",
      "2\n",
      "51\n",
      "August 6, 2025\n",
      "Extend codellama\n",
      "Models\n",
      "2\n",
      "14\n",
      "August 9, 2025\n",
      "Rethinking How We Do Research in the Age of AI\n",
      "Intermediate\n",
      "4\n",
      "65\n",
      "August 8, 2025\n",
      "next page â†’\n",
      "Home\n",
      "Categories\n",
      "Guidelines\n",
      "Terms of Service\n",
      "Privacy Policy\n",
      "Powered by\n",
      "Discourse\n",
      ", best viewed with JavaScript enabled\n",
      "\n",
      "\n",
      "\n",
      "status page\n",
      "Webpage Title:\n",
      "\n",
      "Hugging Face status\n",
      "\n",
      "Webpage Contents:\n",
      "Status\n",
      "Maintenance\n",
      "Previous incidents\n",
      "Get updates\n",
      "Get status updates\n",
      "E-mail\n",
      "RSS\n",
      "JSON\n",
      "Webhook\n",
      "Get e-mail notifications whenever Hugging Face creates, updates or resolves an incident.\n",
      "Subscribe to specific components\n",
      "Current status by service\n",
      "Huggingface Hub\n",
      "Git Hosting and Serving\n",
      "Inference Endpoints\n",
      "Inference Endpoints UI\n",
      "Inference Endpoints API\n",
      "Spaces\n",
      "Spaces Proxy\n",
      "Subscribe\n",
      "Get the RSS feed\n",
      "Get the entire status page as JSON\n",
      "Get a request to your URL whenever Hugging Face creates, updates or resolves an incident.\n",
      "We'll email you with confirmation and when there's an issue with your URL\n",
      "Subscribe to specific components\n",
      "Current status by service\n",
      "Huggingface Hub\n",
      "Git Hosting and Serving\n",
      "Inference Endpoints\n",
      "Inference Endpoints UI\n",
      "Inference Endpoints API\n",
      "Spaces\n",
      "Spaces Proxy\n",
      "Subscribe\n",
      "All services are online\n",
      "Last updated on Aug 11 at 07:53am EDT\n",
      "Current status by service\n",
      "Operational\n",
      "Huggingface Hub\n",
      "99.960% uptime\n",
      "Operational\n",
      "May 14, 2025\n",
      "Operational\n",
      "May 15, 2025\n",
      "Operational\n",
      "May 16, 2025\n",
      "Operational\n",
      "May 17, 2025\n",
      "Operational\n",
      "May 18, 2025\n",
      "Operational\n",
      "May 19, 2025\n",
      "Operational\n",
      "May 20, 2025\n",
      "Operational\n",
      "May 21, 2025\n",
      "Operational\n",
      "May 22, 2025\n",
      "Operational\n",
      "May 23, 2025\n",
      "Operational\n",
      "May 24, 2025\n",
      "Operational\n",
      "May 25, 2025\n",
      "Operational\n",
      "May 26, 2025\n",
      "Operational\n",
      "May 27, 2025\n",
      "Operational\n",
      "May 28, 2025\n",
      "Operational\n",
      "May 29, 2025\n",
      "Operational\n",
      "May 30, 2025\n",
      "Operational\n",
      "May 31, 2025\n",
      "Operational\n",
      "Jun 01, 2025\n",
      "Operational\n",
      "Jun 02, 2025\n",
      "Operational\n",
      "Jun 03, 2025\n",
      "Operational\n",
      "Jun 04, 2025\n",
      "Operational\n",
      "Jun 05, 2025\n",
      "Operational\n",
      "Jun 06, 2025\n",
      "Operational\n",
      "Jun 07, 2025\n",
      "Downtime\n",
      "Down for 4Â minutes\n",
      "Jun 08, 2025\n",
      "Operational\n",
      "Jun 09, 2025\n",
      "Operational\n",
      "Jun 10, 2025\n",
      "Operational\n",
      "Jun 11, 2025\n",
      "Operational\n",
      "Jun 12, 2025\n",
      "Operational\n",
      "Jun 13, 2025\n",
      "Downtime\n",
      "Down for 33Â minutes\n",
      "Jun 14, 2025\n",
      "Operational\n",
      "Jun 15, 2025\n",
      "Downtime\n",
      "Down for 5Â minutes\n",
      "Jun 16, 2025\n",
      "Operational\n",
      "Jun 17, 2025\n",
      "Operational\n",
      "Jun 18, 2025\n",
      "Downtime\n",
      "Down for 4Â minutes\n",
      "Jun 19, 2025\n",
      "Operational\n",
      "Jun 20, 2025\n",
      "Operational\n",
      "Jun 21, 2025\n",
      "Operational\n",
      "Jun 22, 2025\n",
      "Operational\n",
      "Jun 23, 2025\n",
      "Downtime\n",
      "Down for 4Â minutes\n",
      "Jun 24, 2025\n",
      "Operational\n",
      "Jun 25, 2025\n",
      "Operational\n",
      "Jun 26, 2025\n",
      "Operational\n",
      "Jun 27, 2025\n",
      "Operational\n",
      "Jun 28, 2025\n",
      "Operational\n",
      "Jun 29, 2025\n",
      "Operational\n",
      "Jun 30, 2025\n",
      "Operational\n",
      "Jul 01, 2025\n",
      "Operational\n",
      "Jul 02, 2025\n",
      "Operational\n",
      "Jul 03, 2025\n",
      "Operational\n",
      "Jul 04, 2025\n",
      "Operational\n",
      "Jul 05, 2025\n",
      "Operational\n",
      "Jul 06, 2025\n",
      "Operational\n",
      "Jul 07, 2025\n",
      "Operational\n",
      "Jul 08, 2025\n",
      "Operational\n",
      "Jul 09, 2025\n",
      "Operational\n",
      "Jul 10, 2025\n",
      "Operational\n",
      "Jul 11, 2025\n",
      "Operational\n",
      "Jul 12, 2025\n",
      "Operational\n",
      "Jul 13, 2025\n",
      "Operational\n",
      "Jul 14, 2025\n",
      "Operational\n",
      "Jul 15, 2025\n",
      "Operational\n",
      "Jul 16, 2025\n",
      "Operational\n",
      "Jul 17, 2025\n",
      "Operational\n",
      "Jul 18, 2025\n",
      "Operational\n",
      "Jul 19, 2025\n",
      "Operational\n",
      "Jul 20, 2025\n",
      "Operational\n",
      "Jul 21, 2025\n",
      "Operational\n",
      "Jul 22, 2025\n",
      "Operational\n",
      "Jul 23, 2025\n",
      "Operational\n",
      "Jul 24, 2025\n",
      "Operational\n",
      "Jul 25, 2025\n",
      "Operational\n",
      "Jul 26, 2025\n",
      "Operational\n",
      "Jul 27, 2025\n",
      "Operational\n",
      "Jul 28, 2025\n",
      "Operational\n",
      "Jul 29, 2025\n",
      "Operational\n",
      "Jul 30, 2025\n",
      "Operational\n",
      "Jul 31, 2025\n",
      "Operational\n",
      "Aug 01, 2025\n",
      "Operational\n",
      "Aug 02, 2025\n",
      "Operational\n",
      "Aug 03, 2025\n",
      "Operational\n",
      "Aug 04, 2025\n",
      "Operational\n",
      "Aug 05, 2025\n",
      "Operational\n",
      "Aug 06, 2025\n",
      "Operational\n",
      "Aug 07, 2025\n",
      "Operational\n",
      "Aug 08, 2025\n",
      "Operational\n",
      "Aug 09, 2025\n",
      "Operational\n",
      "Aug 10, 2025\n",
      "Operational\n",
      "Aug 11, 2025\n",
      "30 days ago\n",
      "60 days ago\n",
      "90 days ago\n",
      "Today\n",
      "Git Hosting and Serving\n",
      "99.928% uptime\n",
      "Operational\n",
      "May 14, 2025\n",
      "Operational\n",
      "May 15, 2025\n",
      "Operational\n",
      "May 16, 2025\n",
      "Operational\n",
      "May 17, 2025\n",
      "Operational\n",
      "May 18, 2025\n",
      "Operational\n",
      "May 19, 2025\n",
      "Operational\n",
      "May 20, 2025\n",
      "Operational\n",
      "May 21, 2025\n",
      "Operational\n",
      "May 22, 2025\n",
      "Operational\n",
      "May 23, 2025\n",
      "Operational\n",
      "May 24, 2025\n",
      "Operational\n",
      "May 25, 2025\n",
      "Operational\n",
      "May 26, 2025\n",
      "Operational\n",
      "May 27, 2025\n",
      "Operational\n",
      "May 28, 2025\n",
      "Operational\n",
      "May 29, 2025\n",
      "Operational\n",
      "May 30, 2025\n",
      "Operational\n",
      "May 31, 2025\n",
      "Operational\n",
      "Jun 01, 2025\n",
      "Operational\n",
      "Jun 02, 2025\n",
      "Operational\n",
      "Jun 03, 2025\n",
      "Operational\n",
      "Jun 04, 2025\n",
      "Operational\n",
      "Jun 05, 2025\n",
      "Downtime\n",
      "Down for 6Â minutes\n",
      "Jun 06, 2025\n",
      "Operational\n",
      "Jun 07, 2025\n",
      "Downtime\n",
      "Down for 33Â minutes\n",
      "Jun 08, 2025\n",
      "Operational\n",
      "Jun 09, 2025\n",
      "Operational\n",
      "Jun 10, 2025\n",
      "Operational\n",
      "Jun 11, 2025\n",
      "Operational\n",
      "Jun 12, 2025\n",
      "Operational\n",
      "Jun 13, 2025\n",
      "Downtime\n",
      "Down for 33Â minutes\n",
      "Jun 14, 2025\n",
      "Operational\n",
      "Jun 15, 2025\n",
      "Operational\n",
      "Jun 16, 2025\n",
      "Operational\n",
      "Jun 17, 2025\n",
      "Downtime\n",
      "Down for 4Â minutes\n",
      "Jun 18, 2025\n",
      "Operational\n",
      "Jun 19, 2025\n",
      "Operational\n",
      "Jun 20, 2025\n",
      "Operational\n",
      "Jun 21, 2025\n",
      "Operational\n",
      "Jun 22, 2025\n",
      "Operational\n",
      "Jun 23, 2025\n",
      "Downtime\n",
      "Down for 10Â minutes\n",
      "Jun 24, 2025\n",
      "Operational\n",
      "Jun 25, 2025\n",
      "Downtime\n",
      "Down for 4Â minutes\n",
      "Jun 26, 2025\n",
      "Operational\n",
      "Jun 27, 2025\n",
      "Operational\n",
      "Jun 28, 2025\n",
      "Operational\n",
      "Jun 29, 2025\n",
      "Operational\n",
      "Jun 30, 2025\n",
      "Operational\n",
      "Jul 01, 2025\n",
      "Operational\n",
      "Jul 02, 2025\n",
      "Operational\n",
      "Jul 03, 2025\n",
      "Operational\n",
      "Jul 04, 2025\n",
      "Operational\n",
      "Jul 05, 2025\n",
      "Operational\n",
      "Jul 06, 2025\n",
      "Operational\n",
      "Jul 07, 2025\n",
      "Operational\n",
      "Jul 08, 2025\n",
      "Operational\n",
      "Jul 09, 2025\n",
      "Operational\n",
      "Jul 10, 2025\n",
      "Operational\n",
      "Jul 11, 2025\n",
      "Operational\n",
      "Jul 12, 2025\n",
      "Operational\n",
      "Jul 13, 2025\n",
      "Operational\n",
      "Jul 14, 2025\n",
      "Operational\n",
      "Jul 15, 2025\n",
      "Operational\n",
      "Jul 16, 2025\n",
      "Operational\n",
      "Jul 17, 2025\n",
      "Operational\n",
      "Jul 18, 2025\n",
      "Operational\n",
      "Jul 19, 2025\n",
      "Operational\n",
      "Jul 20, 2025\n",
      "Operational\n",
      "Jul 21, 2025\n",
      "Operational\n",
      "Jul 22, 2025\n",
      "Operational\n",
      "Jul 23, 2025\n",
      "Operational\n",
      "Jul 24, 2025\n",
      "Operational\n",
      "Jul 25, 2025\n",
      "Operational\n",
      "Jul 26, 2025\n",
      "Operational\n",
      "Jul 27, 2025\n",
      "Operational\n",
      "Jul 28, 2025\n",
      "Operational\n",
      "Jul 29, 2025\n",
      "Operational\n",
      "Jul 30, 2025\n",
      "Operational\n",
      "Jul 31, 2025\n",
      "Operational\n",
      "Aug 01, 2025\n",
      "Operational\n",
      "Aug 02, 2025\n",
      "Operational\n",
      "Aug 03, 2025\n",
      "Operational\n",
      "Aug 04, 2025\n",
      "Operational\n",
      "Aug 05, 2025\n",
      "Operational\n",
      "Aug 06, 2025\n",
      "Operational\n",
      "Aug 07, 2025\n",
      "Operational\n",
      "Aug 08, 2025\n",
      "Operational\n",
      "Aug 09, 2025\n",
      "Operational\n",
      "Aug 10, 2025\n",
      "Operational\n",
      "Aug 11, 2025\n",
      "30 days ago\n",
      "60 days ago\n",
      "90 days ago\n",
      "Today\n",
      "Inference Endpoints\n",
      "Operational\n",
      "Inference Endpoints UI\n",
      "99.969% uptime\n",
      "Operational\n",
      "May 14, 2025\n",
      "Operational\n",
      "May 15, 2025\n",
      "Operational\n",
      "May 16, 2025\n",
      "Operational\n",
      "May 17, 2025\n",
      "Operational\n",
      "May 18, 2025\n",
      "Operational\n",
      "May 19, 2025\n",
      "Operational\n",
      "May 20, 2025\n",
      "Operational\n",
      "May 21, 2025\n",
      "Operational\n",
      "May 22, 2025\n",
      "Operational\n",
      "May 23, 2025\n",
      "Operational\n",
      "May 24, 2025\n",
      "Operational\n",
      "May 25, 2025\n",
      "Operational\n",
      "May 26, 2025\n",
      "Operational\n",
      "May 27, 2025\n",
      "Operational\n",
      "May 28, 2025\n",
      "Operational\n",
      "May 29, 2025\n",
      "Operational\n",
      "May 30, 2025\n",
      "Operational\n",
      "May 31, 2025\n",
      "Operational\n",
      "Jun 01, 2025\n",
      "Operational\n",
      "Jun 02, 2025\n",
      "Operational\n",
      "Jun 03, 2025\n",
      "Operational\n",
      "Jun 04, 2025\n",
      "Operational\n",
      "Jun 05, 2025\n",
      "Operational\n",
      "Jun 06, 2025\n",
      "Operational\n",
      "Jun 07, 2025\n",
      "Operational\n",
      "Jun 08, 2025\n",
      "Operational\n",
      "Jun 09, 2025\n",
      "Operational\n",
      "Jun 10, 2025\n",
      "Operational\n",
      "Jun 11, 2025\n",
      "Downtime\n",
      "Down for 19Â minutes\n",
      "Jun 12, 2025\n",
      "Operational\n",
      "Jun 13, 2025\n",
      "Operational\n",
      "Jun 14, 2025\n",
      "Operational\n",
      "Jun 15, 2025\n",
      "Operational\n",
      "Jun 16, 2025\n",
      "Operational\n",
      "Jun 17, 2025\n",
      "Operational\n",
      "Jun 18, 2025\n",
      "Operational\n",
      "Jun 19, 2025\n",
      "Downtime\n",
      "Down for 20Â minutes\n",
      "Jun 20, 2025\n",
      "Operational\n",
      "Jun 21, 2025\n",
      "Operational\n",
      "Jun 22, 2025\n",
      "Operational\n",
      "Jun 23, 2025\n",
      "Operational\n",
      "Jun 24, 2025\n",
      "Operational\n",
      "Jun 25, 2025\n",
      "Operational\n",
      "Jun 26, 2025\n",
      "Operational\n",
      "Jun 27, 2025\n",
      "Operational\n",
      "Jun 28, 2025\n",
      "Operational\n",
      "Jun 29, 2025\n",
      "Operational\n",
      "Jun 30, 2025\n",
      "Operational\n",
      "Jul 01, 2025\n",
      "Operational\n",
      "Jul 02, 2025\n",
      "Operational\n",
      "Jul 03, 2025\n",
      "Operational\n",
      "Jul 04, 2025\n",
      "Operational\n",
      "Jul 05, 2025\n",
      "Operational\n",
      "Jul 06, 2025\n",
      "Operational\n",
      "Jul 07, 2025\n",
      "Operational\n",
      "Jul 08, 2025\n",
      "Operational\n",
      "Jul 09, 2025\n",
      "Operational\n",
      "Jul 10, 2025\n",
      "Operational\n",
      "Jul 11, 2025\n",
      "Operational\n",
      "Jul 12, 2025\n",
      "Operational\n",
      "Jul 13, 2025\n",
      "Operational\n",
      "Jul 14, 2025\n",
      "Operational\n",
      "Jul 15, 2025\n",
      "Operational\n",
      "Jul 16, 2025\n",
      "Operational\n",
      "Jul 17, 2025\n",
      "Operational\n",
      "Jul 18, 2025\n",
      "Operational\n",
      "Jul 19, 2025\n",
      "Operational\n",
      "Jul 20, 2025\n",
      "Operational\n",
      "Jul 21, 2025\n",
      "Operational\n",
      "Jul 22, 2025\n",
      "Operational\n",
      "Jul 23, 2025\n",
      "Operational\n",
      "Jul 24, 2025\n",
      "Operational\n",
      "Jul 25, 2025\n",
      "Operational\n",
      "Jul 26, 2025\n",
      "Operational\n",
      "Jul 27, 2025\n",
      "Operational\n",
      "Jul 28, 2025\n",
      "Operational\n",
      "Jul 29, 2025\n",
      "Operational\n",
      "Jul 30, 2025\n",
      "Operational\n",
      "Jul 31, 2025\n",
      "Operational\n",
      "Aug 01, 2025\n",
      "Operational\n",
      "Aug 02, 2025\n",
      "Operational\n",
      "Aug 03, 2025\n",
      "Operational\n",
      "Aug 04, 2025\n",
      "Operational\n",
      "Aug 05, 2025\n",
      "Operational\n",
      "Aug 06, 2025\n",
      "Operational\n",
      "Aug 07, 2025\n",
      "Operational\n",
      "Aug 08, 2025\n",
      "Operational\n",
      "Aug 09, 2025\n",
      "Operational\n",
      "Aug 10, 2025\n",
      "Operational\n",
      "Aug 11, 2025\n",
      "30 days ago\n",
      "60 days ago\n",
      "90 days ago\n",
      "Today\n",
      "Inference Endpoints API\n",
      "100.000% uptime\n",
      "Operational\n",
      "May 14, 2025\n",
      "Operational\n",
      "May 15, 2025\n",
      "Operational\n",
      "May 16, 2025\n",
      "Operational\n",
      "May 17, 2025\n",
      "Operational\n",
      "May 18, 2025\n",
      "Operational\n",
      "May 19, 2025\n",
      "Operational\n",
      "May 20, 2025\n",
      "Operational\n",
      "May 21, 2025\n",
      "Operational\n",
      "May 22, 2025\n",
      "Operational\n",
      "May 23, 2025\n",
      "Operational\n",
      "May 24, 2025\n",
      "Operational\n",
      "May 25, 2025\n",
      "Operational\n",
      "May 26, 2025\n",
      "Operational\n",
      "May 27, 2025\n",
      "Operational\n",
      "May 28, 2025\n",
      "Operational\n",
      "May 29, 2025\n",
      "Operational\n",
      "May 30, 2025\n",
      "Operational\n",
      "May 31, 2025\n",
      "Operational\n",
      "Jun 01, 2025\n",
      "Operational\n",
      "Jun 02, 2025\n",
      "Operational\n",
      "Jun 03, 2025\n",
      "Operational\n",
      "Jun 04, 2025\n",
      "Operational\n",
      "Jun 05, 2025\n",
      "Operational\n",
      "Jun 06, 2025\n",
      "Operational\n",
      "Jun 07, 2025\n",
      "Operational\n",
      "Jun 08, 2025\n",
      "Operational\n",
      "Jun 09, 2025\n",
      "Operational\n",
      "Jun 10, 2025\n",
      "Operational\n",
      "Jun 11, 2025\n",
      "Operational\n",
      "Jun 12, 2025\n",
      "Operational\n",
      "Jun 13, 2025\n",
      "Operational\n",
      "Jun 14, 2025\n",
      "Operational\n",
      "Jun 15, 2025\n",
      "Operational\n",
      "Jun 16, 2025\n",
      "Operational\n",
      "Jun 17, 2025\n",
      "Operational\n",
      "Jun 18, 2025\n",
      "Operational\n",
      "Jun 19, 2025\n",
      "Operational\n",
      "Jun 20, 2025\n",
      "Operational\n",
      "Jun 21, 2025\n",
      "Operational\n",
      "Jun 22, 2025\n",
      "Operational\n",
      "Jun 23, 2025\n",
      "Operational\n",
      "Jun 24, 2025\n",
      "Operational\n",
      "Jun 25, 2025\n",
      "Operational\n",
      "Jun 26, 2025\n",
      "Operational\n",
      "Jun 27, 2025\n",
      "Operational\n",
      "Jun 28, 2025\n",
      "Operational\n",
      "Jun 29, 2025\n",
      "Operational\n",
      "Jun 30, 2025\n",
      "Operational\n",
      "Jul 01, 2025\n",
      "Operational\n",
      "Jul 02, 2025\n",
      "Operational\n",
      "Jul 03, 2025\n",
      "Operational\n",
      "Jul 04, 2025\n",
      "Operational\n",
      "Jul 05, 2025\n",
      "Operational\n",
      "Jul 06, 2025\n",
      "Operational\n",
      "Jul 07, 2025\n",
      "Operational\n",
      "Jul 08, 2025\n",
      "Operational\n",
      "Jul 09, 2025\n",
      "Operational\n",
      "Jul 10, 2025\n",
      "Operational\n",
      "Jul 11, 2025\n",
      "Operational\n",
      "Jul 12, 2025\n",
      "Operational\n",
      "Jul 13, 2025\n",
      "Operational\n",
      "Jul 14, 2025\n",
      "Operational\n",
      "Jul 15, 2025\n",
      "Operational\n",
      "Jul 16, 2025\n",
      "Operational\n",
      "Jul 17, 2025\n",
      "Operational\n",
      "Jul 18, 2025\n",
      "Operational\n",
      "Jul 19, 2025\n",
      "Operational\n",
      "Jul 20, 2025\n",
      "Operational\n",
      "Jul 21, 2025\n",
      "Operational\n",
      "Jul 22, 2025\n",
      "Operational\n",
      "Jul 23, 2025\n",
      "Operational\n",
      "Jul 24, 2025\n",
      "Operational\n",
      "Jul 25, 2025\n",
      "Operational\n",
      "Jul 26, 2025\n",
      "Operational\n",
      "Jul 27, 2025\n",
      "Operational\n",
      "Jul 28, 2025\n",
      "Operational\n",
      "Jul 29, 2025\n",
      "Operational\n",
      "Jul 30, 2025\n",
      "Operational\n",
      "Jul 31, 2025\n",
      "Operational\n",
      "Aug 01, 2025\n",
      "Operational\n",
      "Aug 02, 2025\n",
      "Operational\n",
      "Aug 03, 2025\n",
      "Operational\n",
      "Aug 04, 2025\n",
      "Operational\n",
      "Aug 05, 2025\n",
      "Operational\n",
      "Aug 06, 2025\n",
      "Operational\n",
      "Aug 07, 2025\n",
      "Operational\n",
      "Aug 08, 2025\n",
      "Operational\n",
      "Aug 09, 2025\n",
      "Operational\n",
      "Aug 10, 2025\n",
      "Operational\n",
      "Aug 11, 2025\n",
      "30 days ago\n",
      "60 days ago\n",
      "90 days ago\n",
      "Today\n",
      "Spaces\n",
      "Operational\n",
      "Spaces Proxy\n",
      "100.000% uptime\n",
      "Operational\n",
      "May 14, 2025\n",
      "Operational\n",
      "May 15, 2025\n",
      "Operational\n",
      "May 16, 2025\n",
      "Operational\n",
      "May 17, 2025\n",
      "Operational\n",
      "May 18, 2025\n",
      "Operational\n",
      "May 19, 2025\n",
      "Operational\n",
      "May 20, 2025\n",
      "Operational\n",
      "May 21, 2025\n",
      "Operational\n",
      "May 22, 2025\n",
      "Operational\n",
      "May 23, 2025\n",
      "Operational\n",
      "May 24, 2025\n",
      "Operational\n",
      "May 25, 2025\n",
      "Operational\n",
      "May 26, 2025\n",
      "Operational\n",
      "May 27, 2025\n",
      "Operational\n",
      "May 28, 2025\n",
      "Operational\n",
      "May 29, 2025\n",
      "Operational\n",
      "May 30, 2025\n",
      "Operational\n",
      "May 31, 2025\n",
      "Operational\n",
      "Jun 01, 2025\n",
      "Operational\n",
      "Jun 02, 2025\n",
      "Operational\n",
      "Jun 03, 2025\n",
      "Operational\n",
      "Jun 04, 2025\n",
      "Operational\n",
      "Jun 05, 2025\n",
      "Operational\n",
      "Jun 06, 2025\n",
      "Operational\n",
      "Jun 07, 2025\n",
      "Operational\n",
      "Jun 08, 2025\n",
      "Operational\n",
      "Jun 09, 2025\n",
      "Operational\n",
      "Jun 10, 2025\n",
      "Operational\n",
      "Jun 11, 2025\n",
      "Operational\n",
      "Jun 12, 2025\n",
      "Operational\n",
      "Jun 13, 2025\n",
      "Operational\n",
      "Jun 14, 2025\n",
      "Operational\n",
      "Jun 15, 2025\n",
      "Operational\n",
      "Jun 16, 2025\n",
      "Operational\n",
      "Jun 17, 2025\n",
      "Operational\n",
      "Jun 18, 2025\n",
      "Operational\n",
      "Jun 19, 2025\n",
      "Operational\n",
      "Jun 20, 2025\n",
      "Operational\n",
      "Jun 21, 2025\n",
      "Operational\n",
      "Jun 22, 2025\n",
      "Operational\n",
      "Jun 23, 2025\n",
      "Operational\n",
      "Jun 24, 2025\n",
      "Operational\n",
      "Jun 25, 2025\n",
      "Operational\n",
      "Jun 26, 2025\n",
      "Operational\n",
      "Jun 27, 2025\n",
      "Operational\n",
      "Jun 28, 2025\n",
      "Operational\n",
      "Jun 29, 2025\n",
      "Operational\n",
      "Jun 30, 2025\n",
      "Operational\n",
      "Jul 01, 2025\n",
      "Operational\n",
      "Jul 02, 2025\n",
      "Operational\n",
      "Jul 03, 2025\n",
      "Operational\n",
      "Jul 04, 2025\n",
      "Operational\n",
      "Jul 05, 2025\n",
      "Operational\n",
      "Jul 06, 2025\n",
      "Operational\n",
      "Jul 07, 2025\n",
      "Operational\n",
      "Jul 08, 2025\n",
      "Operational\n",
      "Jul 09, 2025\n",
      "Operational\n",
      "Jul 10, 2025\n",
      "Operational\n",
      "Jul 11, 2025\n",
      "Operational\n",
      "Jul 12, 2025\n",
      "Operational\n",
      "Jul 13, 2025\n",
      "Operational\n",
      "Jul 14, 2025\n",
      "Operational\n",
      "Jul 15, 2025\n",
      "Operational\n",
      "Jul 16, 2025\n",
      "Operational\n",
      "Jul 17, 2025\n",
      "Operational\n",
      "Jul 18, 2025\n",
      "Operational\n",
      "Jul 19, 2025\n",
      "Operational\n",
      "Jul 20, 2025\n",
      "Operational\n",
      "Jul 21, 2025\n",
      "Operational\n",
      "Jul 22, 2025\n",
      "Operational\n",
      "Jul 23, 2025\n",
      "Operational\n",
      "Jul 24, 2025\n",
      "Operational\n",
      "Jul 25, 2025\n",
      "Operational\n",
      "Jul 26, 2025\n",
      "Operational\n",
      "Jul 27, 2025\n",
      "Operational\n",
      "Jul 28, 2025\n",
      "Operational\n",
      "Jul 29, 2025\n",
      "Operational\n",
      "Jul 30, 2025\n",
      "Operational\n",
      "Jul 31, 2025\n",
      "Operational\n",
      "Aug 01, 2025\n",
      "Operational\n",
      "Aug 02, 2025\n",
      "Operational\n",
      "Aug 03, 2025\n",
      "Operational\n",
      "Aug 04, 2025\n",
      "Operational\n",
      "Aug 05, 2025\n",
      "Operational\n",
      "Aug 06, 2025\n",
      "Operational\n",
      "Aug 07, 2025\n",
      "Operational\n",
      "Aug 08, 2025\n",
      "Operational\n",
      "Aug 09, 2025\n",
      "Operational\n",
      "Aug 10, 2025\n",
      "Operational\n",
      "Aug 11, 2025\n",
      "30 days ago\n",
      "60 days ago\n",
      "90 days ago\n",
      "Today\n",
      "Powered by\n",
      "Better Stack\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(get_all_details(\"https://huggingface.co\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9b863a55-f86c-4e3f-8a79-94e24c1a8cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# system_prompt = \"You are an assistant that analyzes the contents of several relevant pages from a company website \\\n",
    "# and creates a short brochure about the company for prospective customers, investors and recruits. Respond in markdown.\\\n",
    "# Include details of company culture, customers and careers/jobs if you have the information.\"\n",
    "\n",
    "system_prompt = \"You are an assistant that analyzes the contents of several relevant pages from a company website \\\n",
    "and creates a short brochure about the company for prospective customers, investors and recruits. You are recruiting Korean workers, so \\\n",
    "you have to make brochure which are written by Korean. Respond in markdown.\\\n",
    "Include details of company culture, customers and careers/jobs if you have the information.\"\n",
    "\n",
    "# í•œêµ­ì–´ ë¸Œë¡œì…”ë¡œ ë³€ê²½í•œ í”„ë¡¬í”„íŠ¸\n",
    "\n",
    "# Or uncomment the lines below for a more humorous brochure - this demonstrates how easy it is to incorporate 'tone':\n",
    "\n",
    "# system_prompt = \"You are an assistant that analyzes the contents of several relevant pages from a company website \\\n",
    "# and creates a short humorous, entertaining, jokey brochure about the company for prospective customers, investors and recruits. Respond in markdown.\\\n",
    "# Include details of company culture, customers and careers/jobs if you have the information.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6ab83d92-d36b-4ce0-8bcc-5bb4c2f8ff23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_brochure_user_prompt(company_name, url):\n",
    "    user_prompt = f\"You are looking at a company called: {company_name}\\n\"\n",
    "    user_prompt += f\"Here are the contents of its landing page and other relevant pages; use this information to build a short brochure of the company in markdown.\\n\"\n",
    "    user_prompt += get_all_details(url)  # ë©”ì¸í˜ì´ì§€+ ê´€ë ¨ í˜ì´ì§€ê¹Œì§€ ë‹¤ 1ê°œë¡œ í•©ì¹œ ê±° \n",
    "    user_prompt = user_prompt[:5_000] # Truncate if more than 5,000 characters\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cd909e0b-1312-4ce2-a553-821e795d7572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found links: {'links': [{'type': 'about page', 'url': 'https://huggingface.co/about'}, {'type': 'careers page', 'url': 'https://apply.workable.com/huggingface/'}, {'type': 'company page', 'url': 'https://huggingface.co/enterprise'}, {'type': 'blog', 'url': 'https://huggingface.co/blog'}, {'type': 'docs page', 'url': 'https://huggingface.co/docs'}, {'type': 'community page', 'url': 'https://discuss.huggingface.co'}, {'type': 'Github', 'url': 'https://github.com/huggingface'}, {'type': 'LinkedIn', 'url': 'https://www.linkedin.com/company/huggingface/'}, {'type': 'Twitter', 'url': 'https://twitter.com/huggingface'}]}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"You are looking at a company called: HuggingFace\\nHere are the contents of its landing page and other relevant pages; use this information to build a short brochure of the company in markdown.\\nLanding page:\\nWebpage Title:\\nHugging Face â€“ The AI community building the future.\\nWebpage Contents:\\nHugging Face\\nModels\\nDatasets\\nSpaces\\nCommunity\\nDocs\\nEnterprise\\nPricing\\nLog In\\nSign Up\\nThe AI community building the future.\\nThe platform where the machine learning community collaborates on models, datasets, and applications.\\nExplore AI Apps\\nor\\nBrowse 1M+ models\\nTrending on\\nthis week\\nModels\\nopenai/gpt-oss-120b\\nUpdated\\n3 days ago\\nâ€¢\\n429k\\nâ€¢\\n3.16k\\nopenai/gpt-oss-20b\\nUpdated\\n3 days ago\\nâ€¢\\n2M\\nâ€¢\\n2.73k\\nQwen/Qwen-Image\\nUpdated\\n5 days ago\\nâ€¢\\n62.8k\\nâ€¢\\n1.43k\\ntencent/Hunyuan-1.8B-Instruct\\nUpdated\\n5 days ago\\nâ€¢\\n3.1k\\nâ€¢\\n573\\nrednote-hilab/dots.ocr\\nUpdated\\n4 days ago\\nâ€¢\\n16.2k\\nâ€¢\\n563\\nBrowse 1M+ models\\nSpaces\\nRunning\\non\\nZero\\n415\\n415\\nQwen Image\\nğŸ–¼\\nGenerate images from text prompts\\nRunning\\n11.7k\\n11.7k\\nDeepSite v2\\nğŸ³\\nGenerate any application with DeepSeek\\nRunning\\non\\nZero\\n264\\n264\\nFLUX.1 Krea Dev\\nğŸ“š\\nGenerate images from text prompts\\nRunning\\non\\nZero\\nMCP\\n282\\n282\\nWan 2.2 5B\\nğŸš€\\nGenerate high-quality videos from text prompts and images\\nRunning\\non\\nZero\\n120\\n120\\nOmniAvatar\\nğŸ¨\\nGenerate podcast and tiktok style video avatars\\nBrowse 400k+ applications\\nDatasets\\nfka/awesome-chatgpt-prompts\\nUpdated\\nJan 6\\nâ€¢\\n32.4k\\nâ€¢\\n8.65k\\njxm/gpt-oss20b-samples\\nUpdated\\n3 days ago\\nâ€¢\\n1.03k\\nâ€¢\\n55\\nHuggingFaceH4/Multilingual-Thinking\\nUpdated\\n4 days ago\\nâ€¢\\n6.15k\\nâ€¢\\n44\\nopenai/BrowseCompLongContext\\nUpdated\\n2 days ago\\nâ€¢\\n568\\nâ€¢\\n30\\nnvidia/Nemotron-Post-Training-Dataset-v1\\nUpdated\\n10 days ago\\nâ€¢\\n15.9k\\nâ€¢\\n103\\nBrowse 250k+ datasets\\nThe Home of Machine Learning\\nCreate, discover and collaborate on ML better.\\nThe collaboration platform\\nHost and collaborate on unlimited public models, datasets and applications.\\nMove faster\\nWith the HF Open source stack.\\nExplore all modalities\\nText, image, video, audio or even 3D.\\nBuild your portfolio\\nShare your work with the world and build your ML profile.\\nSign Up\\nAccelerate your ML\\nWe provide paid Compute and Enterprise solutions.\\nCompute\\nDeploy on optimized\\nInference Endpoints\\nor update your\\nSpaces applications\\nto a GPU in a few clicks.\\nView pricing\\nStarting at $0.60/hour for GPU\\nTeam & Enterprise\\nGive your team the most advanced platform to build AI with enterprise-grade security, access controls and\\n\\t\\t\\tdedicated support.\\nGetting started\\nStarting at $20/user/month\\nSingle Sign-On\\nRegions\\nPriority Support\\nAudit Logs\\nResource Groups\\nPrivate Datasets Viewer\\nMore than 50,000 organizations are using Hugging Face\\nAi2\\nEnterprise\\nnon-profit\\nâ€¢\\n776 models\\nâ€¢\\n3.78k followers\\nAI at Meta\\nEnterprise\\ncompany\\nâ€¢\\n2.2k models\\nâ€¢\\n7.11k followers\\nAmazon\\ncompany\\nâ€¢\\n20 models\\nâ€¢\\n3.35k followers\\nGoogle\\nEnterprise\\ncompany\\nâ€¢\\n1.04k models\\nâ€¢\\n23.9k followers\\nIntel\\ncompany\\nâ€¢\\n239 models\\nâ€¢\\n2.86k followers\\nMicrosoft\\ncompany\\nâ€¢\\n419 models\\nâ€¢\\n14.1k followers\\nGrammarly\\nTeam\\ncompany\\nâ€¢\\n10 models\\nâ€¢\\n171 followers\\nWriter\\nEnterprise\\ncompany\\nâ€¢\\n21 models\\nâ€¢\\n318 followers\\nOur Open Source\\nWe are building the foundation of ML tooling with the community.\\nTransformers\\n148,174\\nState-of-the-art AI models for PyTorch\\nDiffusers\\n30,205\\nState-of-the-art Diffusion models in PyTorch\\nSafetensors\\n3,392\\nSafe way to store/distribute neural network weights\\nHub Python Library\\n2,831\\nPython client to interact with the Hugging Face Hub\\nTokenizers\\n9,978\\nFast tokenizers optimized for research & production\\nTRL\\n15,028\\nTrain transformers LMs with reinforcement learning\\nTransformers.js\\n14,316\\nState-of-the-art ML running directly in your browser\\nsmolagents\\n21,995\\nSmol library to build great agents in Python\\nPEFT\\n19,281\\nParameter-efficient finetuning for large language models\\nDatasets\\n20,484\\nAccess & share datasets for any ML tasks\\nText Generation Inference\\n10,412\\nServe language models with TGI optimized toolkit\\nAccelerate\\n9,021\\nTrain PyTorch models with multi-GPU, TPU, mixed precision\\nSystem theme\\nWebsite\\nModels\\nDatasets\\nSpaces\\nChangelog\\nInference Endpoints\\nHuggingChat\\nCompany\\nAbout\\nBrand assets\\nTerms of service\\nPrivacy\\nJobs\\nPress\\nResources\\nLearn\\nDocumentation\\nBlog\\nForum\\nService Status\\nSocial\\nGitHub\\nTwitter\\nLinkedIn\\nDiscord\\n\\n\\n\\nabout page\\nWebpage Title:\\nabout (Sergei)\\nWebpage Contents:\\nHugging Face\\nModels\\nDatasets\\nSpaces\\nCommunity\\nDocs\\nEnterprise\\nPricing\\nLog In\\nSign Up\\nSergei\\nabout\\nFollow\\njondelamothe's profile picture\\nRenumathi's profile picture\\nKalaipriya's profile picture\\n5\\n\\t\\t\\t\\t\\tfollowers\\nÂ·\\n0 following\\nAI & ML interests\\nNone yet\\nOrganizations\\nNone yet\\nmodels\\n0\\nNone public yet\\ndatasets\\n0\\nNone public yet\\nSystem theme\\nCompany\\nTOS\\nPrivacy\\nAbout\\nJobs\\nWebsite\\nModels\\nDatasets\\nSpaces\\nPricing\\nDocs\\n\\n\\n\\ncareers page\\nWebpage Title:\\nHugging Face - Current Openings\\nWebpage Contents:\\n\\n\\n\\n\\ncompany page\\nWebpage Title:\\nEnterprise Hub - Hugging Face\\nWebpage Contents:\\nHugging Face\\nModels\\nDatasets\\nSpaces\\nCommunity\\nDocs\\nEnterprise\\nPricing\\nLog In\\nSign Up\\nTeam & Enterprise Hub\\nScale your organization with the worldâ€™s leading AI platform\\nSubscribe to\\nTeam\\nstarting at $20/user/mon\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_brochure_user_prompt(\"HuggingFace\", \"https://huggingface.co\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e44de579-4a1a-4e6a-a510-20ea3e4b8d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_brochure(company_name, url):\n",
    "    response = openai.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": get_brochure_user_prompt(company_name, url)}\n",
    "          ],\n",
    "    )\n",
    "    result = response.choices[0].message.content\n",
    "    display(Markdown(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e093444a-9407-42ae-924a-145730591a39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found links: {'links': [{'type': 'about page', 'url': 'https://huggingface.co/huggingface'}, {'type': 'careers page', 'url': 'https://apply.workable.com/huggingface/'}, {'type': 'blog', 'url': 'https://huggingface.co/blog'}, {'type': 'company page', 'url': 'https://huggingface.co/enterprise'}, {'type': 'pricing page', 'url': 'https://huggingface.co/pricing'}, {'type': 'community page', 'url': 'https://discuss.huggingface.co'}, {'type': 'GitHub page', 'url': 'https://github.com/huggingface'}, {'type': 'Twitter page', 'url': 'https://twitter.com/huggingface'}, {'type': 'LinkedIn page', 'url': 'https://www.linkedin.com/company/huggingface/'}]}\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "```markdown\n",
       "# Hugging Face: The AI Community Building the Future\n",
       "\n",
       "Welcome to Hugging Face, a pioneering platform that empowers the machine learning community through collaboration, innovation, and shared resources. Our mission is to accelerate the development of AI technologies and democratize access to machine learning tools for everyone.\n",
       "\n",
       "## What We Offer\n",
       "\n",
       "- **Models**: Access over 1 million machine learning models, including cutting-edge architectures like GPT, diffusion models, and more.\n",
       "  \n",
       "- **Datasets**: Explore a vast library of over 250,000 datasets tailored for various machine learning tasks.\n",
       "\n",
       "- **Spaces**: Utilize our user-friendly interface to create and share applications, allowing for seamless collaboration and innovation.\n",
       "\n",
       "- **Enterprise Solutions**: We provide tailored enterprise-grade services, ensuring security, access control, and dedicated support for organizations looking to harness the power of AI.\n",
       "\n",
       "## Our Community\n",
       "\n",
       "Hugging Face is not just a platform, but a vibrant community of over 50,000 organizations and many active users. Major companies like Google, Amazon, Microsoft, and Grammarly utilize our tools and models, demonstrating our commitment to serving both individual developers and large enterprises.\n",
       "\n",
       "### Collaboration at Our Core\n",
       "\n",
       "We believe in the power of community and open-source. Our projects like Transformer models, Diffusers, and Tokenizers are designed for collaborative building and sharing, creating a robust ecosystem for machine learning developers.\n",
       "\n",
       "## Company Culture\n",
       "\n",
       "At Hugging Face, we foster a culture of inclusivity, innovation, and continuous improvement. We encourage our team members to explore new ideas, collaborate across functions, and contribute to an open-source community that thrives on shared knowledge.\n",
       "\n",
       "- **Team Size**: Currently featuring over 211 dedicated professionals passionate about AI and machine learning.\n",
       "  \n",
       "- **Work Environment**: We promote flexibility, creativity, and a consultancy-like atmosphere where every team member's input is valued.\n",
       "\n",
       "## Careers at Hugging Face\n",
       "\n",
       "Join a team that is shaping the future of AI! We are always on the lookout for talented individuals who are excited about contributing to impactful projects. \n",
       "\n",
       "### Positions Available:\n",
       "- Machine Learning Engineers\n",
       "- Data Scientists\n",
       "- Software Developers\n",
       "- Community Managers\n",
       "- Product Designers\n",
       "\n",
       "Explore opportunities on our [Careers Page](https://huggingface.co/jobs) and find out how you can become part of the Hugging Face family.\n",
       "\n",
       "## Getting Started\n",
       "\n",
       "Whether youâ€™re an AI enthusiast, developer, or someone looking for robust machine learning solutions, Hugging Face is the place to be. \n",
       "\n",
       "- **Explore AI Apps**: Dive deep into our extensive application ecosystem.\n",
       "- **Sign Up**: Create an account to start building or collaborating on models and datasets.\n",
       "\n",
       "**Hugging Face** - Building the AI community of the future, together.\n",
       "\n",
       "ğŸ”— [Visit Our Website](https://huggingface.co)  \n",
       "ğŸ”— [Join Us on GitHub](https://github.com/huggingface)  \n",
       "ğŸ”— [Follow Us on Twitter](https://twitter.com/huggingface)  \n",
       "ğŸ”— [Connect with Us on LinkedIn](https://linkedin.com/company/huggingface/)  \n",
       "```\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "create_brochure(\"HuggingFace\", \"https://huggingface.co\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61eaaab7-0b47-4b29-82d4-75d474ad8d18",
   "metadata": {},
   "source": [
    "## Finally - a minor improvement\n",
    "\n",
    "With a small adjustment, we can change this so that the results stream back from OpenAI,\n",
    "with the familiar typewriter animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "51db0e49-f261-4137-aabe-92dd601f7725",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_brochure(company_name, url):\n",
    "    stream = openai.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": get_brochure_user_prompt(company_name, url)}\n",
    "          ],\n",
    "        stream=True\n",
    "    )\n",
    "    \n",
    "    response = \"\"\n",
    "    display_handle = display(Markdown(\"\"), display_id=True)\n",
    "    for chunk in stream:\n",
    "        response += chunk.choices[0].delta.content or ''\n",
    "        response = response.replace(\"```\",\"\").replace(\"markdown\", \"\")\n",
    "        update_display(Markdown(response), display_id=display_handle.display_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e2b31b-a6bb-48d4-a171-e92da43d9018",
   "metadata": {},
   "outputs": [],
   "source": [
    "ì´ í•¨ìˆ˜ stream_brochure()ëŠ” OpenAI APIì˜ ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œë¥¼ ì‚¬ìš©í•´ì„œ, íšŒì‚¬ ë¸Œë¡œì…” ë‚´ìš©ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ í™”ë©´ì— ì¶œë ¥í•˜ëŠ” ê¸°ëŠ¥ì´ì—ìš”.\n",
    "ë‹¨ê³„ë³„ë¡œ í’€ì–´ë³´ë©´ ì´ë ‡ê²Œ ë©ë‹ˆë‹¤.\n",
    "\n",
    "1. í•¨ìˆ˜ ì •ì˜\n",
    "python\n",
    "ì½”ë“œ ë³µì‚¬\n",
    "def stream_brochure(company_name, url):\n",
    "ë§¤ê°œë³€ìˆ˜\n",
    "\n",
    "company_name: íšŒì‚¬ ì´ë¦„ (ì˜ˆ: \"OpenAI\")\n",
    "\n",
    "url: í•´ë‹¹ íšŒì‚¬ ì›¹ì‚¬ì´íŠ¸ ì£¼ì†Œ (ì˜ˆ: \"https://openai.com\")\n",
    "\n",
    "2. GPT í˜¸ì¶œ ì¤€ë¹„ (ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œ)\n",
    "python\n",
    "ì½”ë“œ ë³µì‚¬\n",
    "stream = openai.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": get_brochure_user_prompt(company_name, url)}\n",
    "      ],\n",
    "    stream=True\n",
    ")\n",
    "model=MODEL : ì‚¬ìš©í•  ëª¨ë¸ ì´ë¦„(ì˜ˆ: \"gpt-4o-mini\").\n",
    "\n",
    "messages : ì±—ë´‡ ëŒ€í™” ë§¥ë½\n",
    "\n",
    "ì²« ë²ˆì§¸ ë©”ì‹œì§€ (system) â†’ ì „ì²´ì ì¸ ì—­í• Â·ê·œì¹™ì„ ì„¤ëª…í•˜ëŠ” ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸\n",
    "\n",
    "ë‘ ë²ˆì§¸ ë©”ì‹œì§€ (user) â†’ get_brochure_user_prompt()ë¡œ ë§Œë“  ì‚¬ìš©ì ìš”ì²­(ë¸Œë¡œì…” ì‘ì„± ì§€ì‹œë¬¸)\n",
    "\n",
    "stream=True : ëª¨ë¸ì´ í•œ ë²ˆì— ì „ë¶€ ì‘ë‹µí•˜ëŠ” ê²Œ ì•„ë‹ˆë¼ ì¡°ê°(chunk) ë‹¨ìœ„ë¡œ ì‹¤ì‹œê°„ ì „ì†¡í•˜ë„ë¡ í•¨.\n",
    "\n",
    "3. ì´ˆê¸° í™”ë©´ ì¶œë ¥ ì¤€ë¹„\n",
    "python\n",
    "ì½”ë“œ ë³µì‚¬\n",
    "response = \"\"\n",
    "display_handle = display(Markdown(\"\"), display_id=True)\n",
    "response : ì§€ê¸ˆê¹Œì§€ ë°›ì€ í…ìŠ¤íŠ¸ë¥¼ ëˆ„ì í•  ë³€ìˆ˜.\n",
    "\n",
    "display_handle : í™”ë©´ì— ë§ˆí¬ë‹¤ìš´ í˜•íƒœë¡œ í‘œì‹œí•  ìˆ˜ ìˆëŠ” ì˜ì—­ì„ ìƒì„±(ì˜ˆ: Jupyter Notebook í™˜ê²½).\n",
    "\n",
    "4. ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ì²˜ë¦¬\n",
    "python\n",
    "ì½”ë“œ ë³µì‚¬\n",
    "for chunk in stream:\n",
    "    response += chunk.choices[0].delta.content or ''\n",
    "    response = response.replace(\"```\",\"\").replace(\"markdown\", \"\")\n",
    "    update_display(Markdown(response), display_id=display_handle.display_id)\n",
    "for chunk in stream â†’ GPTê°€ ë³´ë‚´ì£¼ëŠ” **ì¡°ê°(chunk)**ì„ í•˜ë‚˜ì”© ë°›ìŒ.\n",
    "\n",
    "chunk.choices[0].delta.content â†’ ì´ ì¡°ê°ì˜ ìƒˆë¡œ ìƒì„±ëœ í…ìŠ¤íŠ¸ ë¶€ë¶„\n",
    "(or ''ëŠ” None ë°©ì§€)\n",
    "\n",
    "response += ... â†’ ì „ì²´ ì‘ë‹µì— ìƒˆ í…ìŠ¤íŠ¸ ëˆ„ì .\n",
    "\n",
    ".replace(\"```\",\"\").replace(\"markdown\", \"\") â†’ ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ í‘œì‹ ì œê±°.\n",
    "\n",
    "update_display(...) â†’ í™”ë©´ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ê°±ì‹ í•´ì„œ, ì§€ê¸ˆê¹Œì§€ ë°›ì€ ë‚´ìš© ë³´ì—¬ì¤Œ.\n",
    "\n",
    "ğŸ’¡ ì‰½ê²Œ ë§í•˜ë©´\n",
    "\n",
    "stream=True ë•ë¶„ì— GPTê°€ â€œë‹µë³€ ë‹¤ ì¼ìŠµë‹ˆë‹¤â€ í•˜ê³  ê¸°ë‹¤ë¦¬ëŠ” ê²Œ ì•„ë‹ˆë¼,\n",
    "ì“°ìë§ˆì ë°”ë¡œë°”ë¡œ í™”ë©´ì— ë°˜ì˜í•  ìˆ˜ ìˆëŠ” ê±°ì˜ˆìš”.\n",
    "\n",
    "ë§ˆì¹˜ ì‹¤ì‹œê°„ ìë§‰ì²˜ëŸ¼ ë¸Œë¡œì…” ë‚´ìš©ì„ íƒ€ì´í•‘í•˜ë“¯ í‘œì‹œí•˜ëŠ” ê±°ì£ .\n",
    "\n",
    "ğŸ“Œ íë¦„ ìš”ì•½\n",
    "\n",
    "GPT ëª¨ë¸ì— â€œì´ íšŒì‚¬ì— ëŒ€í•œ ë¸Œë¡œì…” ì¨ì¤˜â€ ìš”ì²­ ë³´ëƒ„ (ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œ)\n",
    "\n",
    "ëª¨ë¸ì´ í•œ ë¬¸ì¥ì”© ë³´ë‚´ì£¼ë©´ ì¦‰ì‹œ ëˆ„ì \n",
    "\n",
    "í™”ë©´ì„ ê³„ì† ê°±ì‹ í•´ì„œ ì‹¤ì‹œê°„ìœ¼ë¡œ ë‚´ìš© í‘œì‹œ\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92cbba82-2088-4884-a1d2-900d8352019d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "56bf0ae3-ee9d-4a72-9cd6-edcac67ceb6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found links: {'links': [{'type': 'about page', 'url': 'https://huggingface.co/about'}, {'type': 'careers page', 'url': 'https://apply.workable.com/huggingface/'}, {'type': 'company page', 'url': 'https://huggingface.co/enterprise'}, {'type': 'press page', 'url': 'https://huggingface.co/blog'}]}\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "# Hugging Face ì†Œê°œ ë¸Œë¡œì…”\n",
       "\n",
       "## íšŒì‚¬ ê°œìš”\n",
       "Hugging FaceëŠ” ì¸ê³µì§€ëŠ¥(AI) ì»¤ë®¤ë‹ˆí‹°ê°€ ë¯¸ë˜ë¥¼ í•¨ê»˜ êµ¬ì¶•í•˜ëŠ” í”Œë«í¼ì…ë‹ˆë‹¤. ìš°ë¦¬ëŠ” ê¸°ê³„ í•™ìŠµ(ML) ì»¤ë®¤ë‹ˆí‹°ê°€ ëª¨ë¸, ë°ì´í„° ì„¸íŠ¸ ë° ì• í”Œë¦¬ì¼€ì´ì…˜ì— í˜‘ì—…í•  ìˆ˜ ìˆë„ë¡ ë„ì™€ì¤ë‹ˆë‹¤. Hugging FaceëŠ” ì „ ì„¸ê³„ 5ë§Œ ê°œ ì´ìƒì˜ ì¡°ì§ì—ì„œ ì‚¬ìš©ë˜ê³  ìˆìœ¼ë©°, ê¸°ì—…ê¸‰ ë³´ì•ˆê³¼ ì „ìš© ì§€ì›ì„ í†µí•´ ML ì†”ë£¨ì…˜ì„ ì œê³µí•˜ê³  ìˆìŠµë‹ˆë‹¤.\n",
       "\n",
       "## íšŒì‚¬ ë¬¸í™”\n",
       "Hugging FaceëŠ” í˜‘ë ¥ê³¼ í˜ì‹ ì„ ì¤‘ì‹œí•˜ëŠ” ë¬¸í™”ê°€ íŠ¹ì§•ì…ë‹ˆë‹¤. ìš°ë¦¬ëŠ” ì˜¤í”ˆ ì†ŒìŠ¤ ì •ì‹ ì„ í†µí•´ ì»¤ë®¤ë‹ˆí‹°ì™€ í•¨ê»˜ ë°œì „í•˜ë©°, ëˆ„êµ¬ë‚˜ ì‰½ê²Œ ê¸°ì—¬í•  ìˆ˜ ìˆëŠ” í™˜ê²½ì„ ë§Œë“­ë‹ˆë‹¤. ë‹¤ì–‘ì„±ê³¼ í¬ìš©ì„±ì„ ê°•ì¡°í•˜ì—¬, ì†Œì™¸ë˜ì§€ ì•ŠëŠ” AI ìƒíƒœê³„ë¥¼ ì¡°ì„±í•˜ëŠ” ë° í˜ì“°ê³  ìˆìŠµë‹ˆë‹¤.\n",
       "\n",
       "## ê³ ê°\n",
       "ìš°ë¦¬ëŠ” **Meta**, **Amazon**, **Google**, **Microsoft** ë“± ì—¬ëŸ¬ ê¸€ë¡œë²Œ ê¸°ì—…ê³¼ í˜‘ë ¥í•˜ê³  ìˆìŠµë‹ˆë‹¤. ë˜í•œ, ë‹¤ì–‘í•œ ë¹„ì˜ë¦¬ ê¸°ê´€ ë° ìŠ¤íƒ€íŠ¸ì—…ê³¼ í•¨ê»˜ ì¼í•˜ë©°, ê·¸ë“¤ì˜ AI í”„ë¡œì íŠ¸ë¥¼ ì§€ì›í•©ë‹ˆë‹¤.\n",
       "\n",
       "## ê²½ë ¥ ê¸°íšŒ\n",
       "Hugging Faceì—ì„œëŠ” ë‹¤ìŒê³¼ ê°™ì€ ë‹¤ì–‘í•œ ì§ë¬´ë¥¼ ì œê³µí•©ë‹ˆë‹¤:\n",
       "- ê¸°ê³„ í•™ìŠµ ì—”ì§€ë‹ˆì–´\n",
       "- ë°ì´í„° ê³¼í•™ì\n",
       "- ì†Œí”„íŠ¸ì›¨ì–´ ê°œë°œì\n",
       "- ê³ ê° ì§€ì› ì „ë¬¸ì¸\n",
       "\n",
       "ìš°ë¦¬ëŠ” ëª¨ë“  ê¸°ìˆ  ìˆ˜ì¤€ê³¼ ê²½í—˜ì„ ê°€ì§„ ì§€ì›ìë¥¼ í™˜ì˜í•©ë‹ˆë‹¤! í•¨ê»˜ AIì˜ ë¯¸ë˜ë¥¼ ë§Œë“¤ì–´ê°ˆ ì¸ì¬ë¥¼ ì°¾ê³  ìˆìŠµë‹ˆë‹¤.\n",
       "\n",
       "## ìš°ë¦¬ê°€ ì œê³µí•˜ëŠ” ê²ƒ\n",
       "- **ëª¨ë¸ ë° ë°ì´í„° ì„¸íŠ¸ì˜ ê´‘ë²”ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬**: 100ë§Œ ê°œ ì´ìƒì˜ ëª¨ë¸ê³¼ 25ë§Œ ê°œ ì´ìƒì˜ ë°ì´í„° ì„¸íŠ¸ì— ì ‘ê·¼í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
       "- **ML í¬íŠ¸í´ë¦¬ì˜¤ êµ¬ì¶•**: ì—¬ëŸ¬ë¶„ì˜ ì‘ì—…ì„ ì„¸ê³„ì™€ ê³µìœ í•˜ì„¸ìš”.\n",
       "- **ì „ë¬¸ ì§€ì› ë° ë…ì  ë„êµ¬**: íŒ€ê³¼ ê¸°ì—…ì„ ìœ„í•œ ê³ ê¸‰ í”Œë«í¼ì„ ì œê³µí•˜ë©°, ì•ˆì „í•˜ê³  íš¨ìœ¨ì ì¸ AI ê°œë°œì„ ì§€ì›í•©ë‹ˆë‹¤.\n",
       "\n",
       "ì €í¬ì™€ í•¨ê»˜ AIì˜ ë¯¸ë˜ë¥¼ ì°½ì¡°í•´ ë³´ì„¸ìš”! ë” ìì„¸í•œ ì‚¬í•­ì€ [Hugging Face ì›¹ì‚¬ì´íŠ¸](https://huggingface.co) ë¥¼ ë°©ë¬¸í•´ ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤.\n",
       "\n",
       "## ì—°ë½ì²˜\n",
       "Hugging Faceì— ëŒ€í•œ ë” ë§ì€ ì •ë³´ì™€ ê²½ë ¥ì— ëŒ€í•œ ë¬¸ì˜ëŠ” ì•„ë˜ì˜ ë§í¬ë¥¼ í†µí•´ ê°€ëŠ¥í•©ë‹ˆë‹¤.\n",
       "- [ì±„ìš© ì •ë³´](https://huggingface.co/jobs)\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stream_brochure(\"HuggingFace\", \"https://huggingface.co\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fdb3f8d8-a3eb-41c8-b1aa-9f60686a653b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found links: {'links': [{'type': 'about page', 'url': 'https://huggingface.co'}, {'type': 'enterprise page', 'url': 'https://huggingface.co/enterprise'}, {'type': 'pricing page', 'url': 'https://huggingface.co/pricing'}, {'type': 'careers page', 'url': 'https://apply.workable.com/huggingface/'}, {'type': 'blog page', 'url': 'https://huggingface.co/blog'}, {'type': 'discussion forum', 'url': 'https://discuss.huggingface.co'}, {'type': 'GitHub page', 'url': 'https://github.com/huggingface'}, {'type': 'Twitter page', 'url': 'https://twitter.com/huggingface'}, {'type': 'LinkedIn page', 'url': 'https://www.linkedin.com/company/huggingface/'}]}\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "# Hugging Face ë¸Œë¡œì…”\n",
       "\n",
       "## AI ì»¤ë®¤ë‹ˆí‹°ì˜ ë¯¸ë˜ë¥¼ í•¨ê»˜í•©ë‹ˆë‹¤.\n",
       "\n",
       "Hugging FaceëŠ” ê¸°ê³„ í•™ìŠµ ì»¤ë®¤ë‹ˆí‹°ë¥¼ ìœ„í•œ í”Œë«í¼ìœ¼ë¡œ, ëª¨ë¸, ë°ì´í„°ì…‹, ì‘ìš© í”„ë¡œê·¸ë¨ì„ í˜‘ë ¥í•˜ì—¬ ê°œë°œí•˜ëŠ” ê³µê°„ì…ë‹ˆë‹¤. ìš°ë¦¬ëŠ” ëˆ„êµ¬ë‚˜ AI ê¸°ìˆ ì— ê¸°ì—¬í•˜ê³  ê³µìœ í•  ìˆ˜ ìˆëŠ” ì—´ë¦° í™˜ê²½ì„ ì œê³µí•©ë‹ˆë‹¤.\n",
       "\n",
       "## ìš°ë¦¬ì˜ ìë‘ìŠ¤ëŸ¬ìš´ ì œê³µì•ˆ\n",
       "\n",
       "- **ëª¨ë¸**: 100ë§Œ ê°œ ì´ìƒì˜ ìµœì‹  AI ëª¨ë¸ì— ì ‘ê·¼í•˜ê³  íƒìƒ‰í•˜ì„¸ìš”.\n",
       "- **ë°ì´í„°ì…‹**: 25ë§Œ ê°œ ì´ìƒì˜ ê³µê³µ ë°ì´í„°ì…‹ìœ¼ë¡œ ê¸°ê³„ í•™ìŠµ ì‘ì—…ì„ ì§€ì›í•©ë‹ˆë‹¤.\n",
       "- **Spaces**: AI ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ìƒì„±í•˜ê³  ê³µìœ í•˜ëŠ”ë° ìµœì í™”ëœ ê³µê°„ì…ë‹ˆë‹¤.\n",
       "\n",
       "## ê³ ê°ê³¼ì˜ í˜‘ë ¥\n",
       "\n",
       "Hugging FaceëŠ” Amazon, Google, Microsoft ë“± 50,000ê°œ ì´ìƒì˜ ì¡°ì§ê³¼ í˜‘ë ¥í•˜ê³  ìˆìœ¼ë©°, ë¹„ì˜ë¦¬ ê¸°ì—…ë“¤ë„ ìš°ë¦¬ í”Œë«í¼ì„ í†µí•´ í˜ì‹ ì„ ì´ë£¨ê³  ìˆìŠµë‹ˆë‹¤. ìš°ë¦¬ì˜ ì„±ê³µì ì¸ ê³ ê°ë“¤ì€ ë‹¤ì–‘í•œ ì‚°ì—…ì— ê±¸ì³ ìˆìœ¼ë©°, ê·¸ë“¤ì˜ í•„ìš”ì— ë§ì¶˜ AI ì†”ë£¨ì…˜ì„ ì œê³µí•©ë‹ˆë‹¤.\n",
       "\n",
       "## í¬ê´„ì ì¸ íšŒì‚¬ ë¬¸í™”\n",
       "\n",
       "Hugging Faceì—ì„œì˜ ê·¼ë¬´ëŠ” êµ‰ì¥íˆ í˜‘ë ¥ì ì´ê³  í˜ì‹ ì ì…ë‹ˆë‹¤. ìš°ë¦¬ëŠ” ì—¬ëŸ¬ ë°±ê·¸ë¼ìš´ë“œë¥¼ ê°€ì§„ ì¸ì¬ë“¤ì´ ììœ ë¡­ê²Œ ì˜ê²¬ì„ êµí™˜í•˜ê³ , ì•„ì´ë””ì–´ë¥¼ ì‹¤í˜„í•  ìˆ˜ ìˆëŠ” í™˜ê²½ì„ ì¡°ì„±í•©ë‹ˆë‹¤. ê° íŒ€ì›ì€ ìì‹ ì˜ ì˜ê²¬ì´ ì¡´ì¤‘ë°›ê³ , í˜ì‹ ì ì¸ í”„ë¡œì íŠ¸ì— ì°¸ì—¬í•  ê¸°íšŒë¥¼ ê°€ì§‘ë‹ˆë‹¤.\n",
       "\n",
       "## ê²½ë ¥ ë° ì±„ìš© ì •ë³´\n",
       "\n",
       "ìš°ë¦¬ëŠ” ì§€ì†ì ì¸ ì„±ì¥ì„ ìœ„í•´ ìƒˆë¡œìš´ ì¸ì¬ë¥¼ ì°¾ê³  ìˆìŠµë‹ˆë‹¤. ë‹¤ì–‘í•œ ì§ë¬´ê°€ ìˆìœ¼ë©°, ëª¨ë‘ê°€ AIì˜ ë¯¸ë˜ë¥¼ í•¨ê»˜ ë§Œë“¤ì–´ê°€ëŠ” ì—¬ì •ì— ë™ì°¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. íŠ¹íˆ í•œêµ­ì–´ë¥¼ êµ¬ì‚¬í•˜ëŠ” ì¸ì¬ë¥¼ ìš°ëŒ€í•˜ë©°, ë‹¤êµ­ì  íŒ€ì—ì„œ ê²½í—˜ì„ ìŒ“ì„ ìˆ˜ ìˆëŠ” ê¸°íšŒë¥¼ ì œê³µí•©ë‹ˆë‹¤.\n",
       "\n",
       "## í•¨ê»˜ ë¯¸ë˜ë¥¼ ë§Œë“¤ì–´ ê°‘ë‹ˆë‹¤\n",
       "\n",
       "Hugging FaceëŠ” í˜„ëŒ€ AI ê¸°ìˆ ì˜ ìµœì „ì„ ì—ì„œ í™œë™í•˜ê³  ìˆìœ¼ë©°, ì—¬ëŸ¬ë¶„ì˜ ì°¸ì—¬ë¥¼ í†µí•´ ë” ë‚˜ì€ AI ìƒíƒœê³„ë¥¼ ë§Œë“¤ê³ ì í•©ë‹ˆë‹¤. ê´€ì‹¬ì´ ìˆìœ¼ì‹  ë¶„ë“¤ì€ [ì‹ ì²­í•˜ê¸°](https://huggingface.co/join) ë²„íŠ¼ì„ í†µí•´ ì§€ì›í•´ ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤!\n",
       "\n",
       "---\n",
       "\n",
       "**ì—°ë½ì²˜ ì •ë³´**  \n",
       "- ì›¹ì‚¬ì´íŠ¸: [Hugging Face](https://huggingface.co)  \n",
       "- ì´ë©”ì¼: info@huggingface.co  \n",
       "- ì†Œì…œ ë¯¸ë””ì–´: [Twitter](https://twitter.com/huggingface) | [LinkedIn](https://linkedin.com/company/huggingface)\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Try changing the system prompt to the humorous version when you make the Brochure for Hugging Face:\n",
    "\n",
    "stream_brochure(\"HuggingFace\", \"https://huggingface.co\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27bf9e0-665f-4645-b66b-9725e2a959b5",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../business.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#181;\">Business applications</h2>\n",
    "            <span style=\"color:#181;\">In this exercise we extended the Day 1 code to make multiple LLM calls, and generate a document.\n",
    "\n",
    "This is perhaps the first example of Agentic AI design patterns, as we combined multiple calls to LLMs. This will feature more in Week 2, and then we will return to Agentic AI in a big way in Week 8 when we build a fully autonomous Agent solution.\n",
    "\n",
    "Generating content in this way is one of the very most common Use Cases. As with summarization, this can be applied to any business vertical. Write marketing content, generate a product tutorial from a spec, create personalized email content, and so much more. Explore how you can apply content generation to your business, and try making yourself a proof-of-concept prototype. See what other students have done in the community-contributions folder -- so many valuable projects -- it's wild!</span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b2454b-8ef8-4b5c-b928-053a15e0d553",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../important.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#900;\">Before you move to Week 2 (which is tons of fun)</h2>\n",
    "            <span style=\"color:#900;\">Please see the week1 EXERCISE notebook for your challenge for the end of week 1. This will give you some essential practice working with Frontier APIs, and prepare you well for Week 2.</span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b64f0f-7d33-4493-985a-033d06e8db08",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../resources.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#f71;\">A reminder on 3 useful resources</h2>\n",
    "            <span style=\"color:#f71;\">1. The resources for the course are available <a href=\"https://edwarddonner.com/2024/11/13/llm-engineering-resources/\">here.</a><br/>\n",
    "            2. I'm on LinkedIn <a href=\"https://www.linkedin.com/in/eddonner/\">here</a> and I love connecting with people taking the course!<br/>\n",
    "            3. I'm trying out X/Twitter and I'm at <a href=\"https://x.com/edwarddonner\">@edwarddonner<a> and hoping people will teach me how it's done..  \n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f48e42e-fa7a-495f-a5d4-26bfc24d60b6",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../thankyou.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#090;\">Finally! I have a special request for you</h2>\n",
    "            <span style=\"color:#090;\">\n",
    "                My editor tells me that it makes a MASSIVE difference when students rate this course on Udemy - it's one of the main ways that Udemy decides whether to show it to others. If you're able to take a minute to rate this, I'd be so very grateful! And regardless - always please reach out to me at ed@edwarddonner.com if I can help at any point.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d3e1a1-ba54-4907-97c5-30f89a24775b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
