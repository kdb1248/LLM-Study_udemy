{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a98030af-fcd1-4d63-a36e-38ba053498fa",
   "metadata": {},
   "source": [
    "# A full business solution\n",
    "\n",
    "## Now we will take our project from Day 1 to the next level\n",
    "\n",
    "### BUSINESS CHALLENGE:\n",
    "\n",
    "Create a product that builds a Brochure for a company to be used for prospective clients, investors and potential recruits.\n",
    "\n",
    "We will be provided a company name and their primary website.\n",
    "\n",
    "See the end of this notebook for examples of real-world business applications.\n",
    "\n",
    "And remember: I'm always available if you have problems or ideas! Please do reach out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5b08506-dc8b-4443-9201-5f1848161363",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "# If these fail, please check you're running from an 'activated' environment with (llms) in the command prompt\n",
    "\n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "from typing import List\n",
    "from dotenv import load_dotenv\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display, update_display\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc5d8880-f2ee-4c06-af16-ecbc0262af61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key looks good so far\n"
     ]
    }
   ],
   "source": [
    "# Initialize and constants\n",
    "\n",
    "load_dotenv(override=True)\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "if api_key and api_key.startswith('sk-proj-') and len(api_key)>10:\n",
    "    print(\"API key looks good so far\")\n",
    "else:\n",
    "    print(\"There might be a problem with your API key? Please visit the troubleshooting notebook!\")\n",
    "    \n",
    "MODEL = 'gpt-4o-mini'\n",
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b96004-6822-4d09-8909-0410d18f0415",
   "metadata": {},
   "outputs": [],
   "source": [
    "이 코드는 OpenAI API를 쓰기 위해 환경설정과 키 점검을 하는 초기화 부분이에요.\n",
    "단계별로 풀면 이렇게 됩니다.\n",
    "\n",
    "환경변수 불러오기\n",
    "\n",
    "python\n",
    "코드 복사\n",
    "load_dotenv(override=True)\n",
    ".env 파일에 저장된 환경변수를 파이썬으로 불러옵니다.\n",
    "\n",
    "override=True는 기존 환경변수가 있어도 덮어쓴다는 의미예요.\n",
    "\n",
    "API 키 가져오기\n",
    "\n",
    "python\n",
    "코드 복사\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "불러온 환경변수 중에서 OPENAI_API_KEY 값을 읽어옵니다.\n",
    "\n",
    "이 값이 OpenAI API를 호출할 때 필요한 비밀번호 같은 거예요.\n",
    "\n",
    "API 키 유효성 점검\n",
    "\n",
    "python\n",
    "코드 복사\n",
    "if api_key and api_key.startswith('sk-proj-') and len(api_key) > 10:\n",
    "    print(\"API key looks good so far\")\n",
    "else:\n",
    "    print(\"There might be a problem with your API key? Please visit the troubleshooting notebook!\")\n",
    "API 키가 존재하는지 확인 (api_key)\n",
    "\n",
    "키가 'sk-proj-'로 시작하는지 확인 (OpenAI 프로젝트 키 형식)\n",
    "\n",
    "길이가 10자보다 긴지 확인 (너무 짧으면 잘못된 키일 가능성)\n",
    "\n",
    "조건이 맞으면 \"API key looks good so far\" 출력,\n",
    "아니면 \"There might be a problem...\" 경고 메시지 출력.\n",
    "\n",
    "모델 이름 설정\n",
    "\n",
    "python\n",
    "코드 복사\n",
    "MODEL = 'gpt-4o-mini'\n",
    "사용할 OpenAI 모델을 지정합니다.\n",
    "\n",
    "여기선 'gpt-4o-mini'를 선택했네요.\n",
    "\n",
    "OpenAI 객체 생성\n",
    "\n",
    "python\n",
    "코드 복사\n",
    "openai = OpenAI()\n",
    "OpenAI API 호출을 도와주는 객체를 만듭니다.\n",
    "\n",
    "이후 openai.chat.completions.create(...) 같은 메서드로 요청을 보낼 수 있어요.\n",
    "\n",
    "💡 쉽게 비유\n",
    "이건 마치\n",
    "\n",
    ".env에서 비밀번호 찾아오기\n",
    "\n",
    "그 비밀번호가 맞는지 대충 검사하기\n",
    "\n",
    "사용할 모델 정하기\n",
    "\n",
    "OpenAI에 연결 준비 완료!\n",
    "… 이런 준비 단계입니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "106dd65e-90af-4ca8-86b6-23a41840645b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A class to represent a Webpage\n",
    "\n",
    "# Some websites need you to use proper headers when fetching them:\n",
    "headers = {\n",
    " \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "class Website:\n",
    "    \"\"\"\n",
    "    A utility class to represent a Website that we have scraped, now with links\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, url):\n",
    "        self.url = url\n",
    "        response = requests.get(url, headers=headers)\n",
    "        self.body = response.content\n",
    "        soup = BeautifulSoup(self.body, 'html.parser')\n",
    "        self.title = soup.title.string if soup.title else \"No title found\"\n",
    "        if soup.body:\n",
    "            for irrelevant in soup.body([\"script\", \"style\", \"img\", \"input\"]):\n",
    "                irrelevant.decompose()\n",
    "            self.text = soup.body.get_text(separator=\"\\n\", strip=True)\n",
    "        else:\n",
    "            self.text = \"\"\n",
    "        links = [link.get('href') for link in soup.find_all('a')]\n",
    "        self.links = [link for link in links if link]\n",
    "\n",
    "    def get_contents(self):\n",
    "        return f\"Webpage Title:\\n{self.title}\\nWebpage Contents:\\n{self.text}\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38313d9-05a1-4307-8281-2341e000ffde",
   "metadata": {},
   "outputs": [],
   "source": [
    "이 코드는 웹페이지를 가져와서 제목, 본문 텍스트, 링크를 추출하는 도우미 클래스예요.\n",
    "단계별로 풀어보면 이렇게 됩니다.\n",
    "\n",
    "1. 웹 요청 헤더 설정\n",
    "python\n",
    "코드 복사\n",
    "headers = {\n",
    " \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) ...\"\n",
    "}\n",
    "일부 웹사이트는 그냥 requests로 접속하면 로봇으로 인식해서 차단합니다.\n",
    "\n",
    "그래서 브라우저(크롬)에서 온 것처럼 속이는 User-Agent를 추가해줍니다.\n",
    "\n",
    "2. Website 클래스\n",
    "python\n",
    "코드 복사\n",
    "class Website:\n",
    "    \"\"\"웹페이지의 제목, 본문, 링크를 저장하는 클래스\"\"\"\n",
    "하나의 웹페이지를 표현하는 객체.\n",
    "\n",
    "URL을 넣으면 해당 페이지를 가져와서 필요한 정보를 자동으로 뽑아옵니다.\n",
    "\n",
    "3. 초기화 메서드 (__init__)\n",
    "python\n",
    "코드 복사\n",
    "def __init__(self, url):\n",
    "    self.url = url\n",
    "사용자가 Website(\"https://example.com\")처럼 URL을 넣으면 실행됩니다.\n",
    "\n",
    "주요 기능:\n",
    "\n",
    "웹페이지 요청\n",
    "\n",
    "python\n",
    "코드 복사\n",
    "response = requests.get(url, headers=headers)\n",
    "self.body = response.content\n",
    "→ URL의 HTML 내용을 가져옵니다.\n",
    "\n",
    "HTML 파싱\n",
    "\n",
    "python\n",
    "코드 복사\n",
    "soup = BeautifulSoup(self.body, 'html.parser')\n",
    "→ BeautifulSoup으로 HTML을 구조적으로 분석.\n",
    "\n",
    "제목 추출\n",
    "\n",
    "python\n",
    "코드 복사\n",
    "self.title = soup.title.string if soup.title else \"No title found\"\n",
    "→ <title> 태그가 있으면 제목 저장, 없으면 \"No title found\".\n",
    "\n",
    "본문 텍스트 정리\n",
    "\n",
    "python\n",
    "코드 복사\n",
    "for irrelevant in soup.body([\"script\", \"style\", \"img\", \"input\"]):\n",
    "    irrelevant.decompose()\n",
    "self.text = soup.body.get_text(separator=\"\\n\", strip=True)\n",
    "→ script, style, img, input 같은 필요 없는 태그 삭제 후,\n",
    "본문 텍스트만 깔끔하게 추출.\n",
    "\n",
    "링크 수집\n",
    "\n",
    "python\n",
    "코드 복사\n",
    "links = [link.get('href') for link in soup.find_all('a')]\n",
    "self.links = [link for link in links if link]\n",
    "→ <a> 태그의 href 속성 값을 리스트로 저장 (빈 값 제외).\n",
    "\n",
    "4. 콘텐츠 반환 메서드\n",
    "python\n",
    "코드 복사\n",
    "def get_contents(self):\n",
    "    return f\"Webpage Title:\\n{self.title}\\nWebpage Contents:\\n{self.text}\\n\\n\"\n",
    "저장된 제목과 본문 텍스트를 문자열 형태로 돌려줍니다.\n",
    "\n",
    "💡 쉽게 비유\n",
    "이건 마치 웹페이지 스캐너예요.\n",
    "\n",
    "Website(url) → 그 페이지의 HTML을 받아와서\n",
    "\n",
    "제목, 텍스트, 링크를 자동으로 뽑고 저장\n",
    "\n",
    "필요하면 get_contents()로 깔끔하게 내용 보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205c2edb-5ba4-4354-90d1-e38f7f8b6782",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e30d8128-933b-44cc-81c8-ab4c9d86589a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://edwarddonner.com/',\n",
       " 'https://edwarddonner.com/connect-four/',\n",
       " 'https://edwarddonner.com/outsmart/',\n",
       " 'https://edwarddonner.com/about-me-and-about-nebula/',\n",
       " 'https://edwarddonner.com/posts/',\n",
       " 'https://edwarddonner.com/',\n",
       " 'https://news.ycombinator.com',\n",
       " 'https://nebula.io/?utm_source=ed&utm_medium=referral',\n",
       " 'https://www.prnewswire.com/news-releases/wynden-stark-group-acquires-nyc-venture-backed-tech-startup-untapt-301269512.html',\n",
       " 'https://patents.google.com/patent/US20210049536A1/',\n",
       " 'https://www.linkedin.com/in/eddonner/',\n",
       " 'https://edwarddonner.com/2025/05/28/connecting-my-courses-become-an-llm-expert-and-leader/',\n",
       " 'https://edwarddonner.com/2025/05/28/connecting-my-courses-become-an-llm-expert-and-leader/',\n",
       " 'https://edwarddonner.com/2025/05/18/2025-ai-executive-briefing/',\n",
       " 'https://edwarddonner.com/2025/05/18/2025-ai-executive-briefing/',\n",
       " 'https://edwarddonner.com/2025/04/21/the-complete-agentic-ai-engineering-course/',\n",
       " 'https://edwarddonner.com/2025/04/21/the-complete-agentic-ai-engineering-course/',\n",
       " 'https://edwarddonner.com/2025/01/23/llm-workshop-hands-on-with-agents-resources/',\n",
       " 'https://edwarddonner.com/2025/01/23/llm-workshop-hands-on-with-agents-resources/',\n",
       " 'https://edwarddonner.com/',\n",
       " 'https://edwarddonner.com/connect-four/',\n",
       " 'https://edwarddonner.com/outsmart/',\n",
       " 'https://edwarddonner.com/about-me-and-about-nebula/',\n",
       " 'https://edwarddonner.com/posts/',\n",
       " 'mailto:hello@mygroovydomain.com',\n",
       " 'https://www.linkedin.com/in/eddonner/',\n",
       " 'https://twitter.com/edwarddonner',\n",
       " 'https://www.facebook.com/edward.donner.52']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ed = Website(\"https://edwarddonner.com\")\n",
    "ed.links"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1771af9c-717a-4fca-bbbe-8a95893312c3",
   "metadata": {},
   "source": [
    "## First step: Have GPT-4o-mini figure out which links are relevant\n",
    "\n",
    "### Use a call to gpt-4o-mini to read the links on a webpage, and respond in structured JSON.  \n",
    "It should decide which links are relevant, and replace relative links such as \"/about\" with \"https://company.com/about\".  \n",
    "We will use \"one shot prompting\" in which we provide an example of how it should respond in the prompt.\n",
    "\n",
    "This is an excellent use case for an LLM, because it requires nuanced understanding. Imagine trying to code this without LLMs by parsing and analyzing the webpage - it would be very hard!\n",
    "\n",
    "Sidenote: there is a more advanced technique called \"Structured Outputs\" in which we require the model to respond according to a spec. We cover this technique in Week 8 during our autonomous Agentic AI project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c8b7a2-f6c6-4e9f-b28f-2bd7d36f0957",
   "metadata": {},
   "outputs": [],
   "source": [
    "첫 번째 단계: GPT-4o-mini로 어떤 링크가 관련 있는지 판단하기\n",
    "gpt-4o-mini를 호출하여 웹페이지의 링크를 읽고, 구조화된 JSON으로 응답하게 합니다.\n",
    "이 과정에서 어떤 링크가 관련 있는지를 판단하고, \"/about\" 같은 상대 경로 링크를 \"https://company.com/about\"처럼 절대 경로로 변환해야 합니다.\n",
    "우리는 One-shot 프롬프트 기법을 사용할 것이며, 프롬프트에 모델이 어떻게 응답해야 하는지 예시를 함께 제공합니다.\n",
    "\n",
    "이 작업은 LLM의 훌륭한 활용 사례입니다. 왜냐하면 미묘한 맥락 이해가 필요하기 때문입니다. LLM 없이 단순히 코드를 작성해 웹페이지를 파싱하고 분석하려고 하면, 매우 어려운 작업이 될 것입니다.\n",
    "\n",
    "참고: 더 고급 기법으로 Structured Outputs가 있습니다. 이 방법은 모델이 특정 스펙에 맞춰 응답하도록 요구합니다. 이 기법은 8주차 자율형 Agentic AI 프로젝트에서 다룰 예정입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6957b079-0d96-45f7-a26a-3487510e9b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "link_system_prompt = \"You are provided with a list of links found on a webpage. \\\n",
    "You are able to decide which of the links would be most relevant to include in a brochure about the company, \\\n",
    "such as links to an About page, or a Company page, or Careers/Jobs pages.\\n\"\n",
    "link_system_prompt += \"You should respond in JSON as in this example:\"\n",
    "link_system_prompt += \"\"\"\n",
    "{\n",
    "    \"links\": [\n",
    "        {\"type\": \"about page\", \"url\": \"https://full.url/goes/here/about\"},\n",
    "        {\"type\": \"careers page\": \"url\": \"https://another.full.url/careers\"}\n",
    "    ]\n",
    "} \n",
    "\"\"\"\n",
    "###원샷 프롬프트 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "304d8595-6f1c-4966-a73c-791f0e31ab93",
   "metadata": {},
   "outputs": [],
   "source": [
    "##멀티샷 프롬프트\n",
    "link_system_prompt = \"\"\"You are provided with a list of links found on a webpage.\n",
    "Choose links relevant for a company brochure (About, Company, Careers/Jobs, Press).\n",
    "Exclude Terms, Privacy, email links, login, and ads. Always return absolute https URLs.\n",
    "Respond ONLY in JSON like:\n",
    "{ \"links\": [ { \"type\": \"<about|careers|...>\", \"url\": \"https://...\" } ] }\n",
    "\n",
    "# Example 1\n",
    "Input (base: https://companyA.com):\n",
    "/about\n",
    "/contact\n",
    "/privacy\n",
    "/terms\n",
    "mailto:hello@companyA.com\n",
    "/careers\n",
    "\n",
    "Output:\n",
    "{\n",
    "  \"links\": [\n",
    "    {\"type\": \"about page\", \"url\": \"https://companyA.com/about\"},\n",
    "    {\"type\": \"careers page\", \"url\": \"https://companyA.com/careers\"}\n",
    "  ]\n",
    "}\n",
    "\n",
    "# Example 2\n",
    "Input (base: https://www.startup.io):\n",
    "https://www.startup.io/company\n",
    "/login\n",
    "/products\n",
    "/newsroom\n",
    "/privacy-policy\n",
    "/jobs\n",
    "\n",
    "Output:\n",
    "{\n",
    "  \"links\": [\n",
    "    {\"type\": \"company page\", \"url\": \"https://www.startup.io/company\"},\n",
    "    {\"type\": \"careers page\", \"url\": \"https://www.startup.io/jobs\"},\n",
    "    {\"type\": \"press/newsroom page\", \"url\": \"https://www.startup.io/newsroom\"}\n",
    "  ]\n",
    "}\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b97e4068-97ed-4120-beae-c42105e4d59a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are provided with a list of links found on a webpage. You are able to decide which of the links would be most relevant to include in a brochure about the company, such as links to an About page, or a Company page, or Careers/Jobs pages.\n",
      "You should respond in JSON as in this example:\n",
      "{\n",
      "    \"links\": [\n",
      "        {\"type\": \"about page\", \"url\": \"https://full.url/goes/here/about\"},\n",
      "        {\"type\": \"careers page\": \"url\": \"https://another.full.url/careers\"}\n",
      "    ]\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(link_system_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e1f601b-2eaf-499d-b6b8-c99050c9d6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_links_user_prompt(website):\n",
    "    user_prompt = f\"Here is the list of links on the website of {website.url} - \"\n",
    "    user_prompt += \"please decide which of these are relevant web links for a brochure about the company, respond with the full https URL in JSON format. \\\n",
    "Do not include Terms of Service, Privacy, email links.\\n\"\n",
    "    user_prompt += \"Links (some might be relative links):\\n\"\n",
    "    user_prompt += \"\\n\".join(website.links)\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d90630-5d19-43ea-94fc-ac77c2d5343c",
   "metadata": {},
   "outputs": [],
   "source": [
    "이 코드는 웹사이트의 링크 목록을 GPT 같은 모델에 보낼 프롬프트(질문문)를 만드는 함수예요.\n",
    "단계별로 풀면 이렇게 됩니다.\n",
    "\n",
    "1. 함수 정의\n",
    "python\n",
    "코드 복사\n",
    "def get_links_user_prompt(website):\n",
    "website는 앞서 만든 Website 클래스 같은 객체일 가능성이 큽니다.\n",
    "\n",
    "즉, website.url → 해당 웹사이트 주소\n",
    "\n",
    "website.links → 그 사이트에서 수집한 링크 목록\n",
    "\n",
    "2. 기본 프롬프트 시작\n",
    "python\n",
    "코드 복사\n",
    "user_prompt = f\"Here is the list of links on the website of {website.url} - \"\n",
    "프롬프트 첫 부분에 \"이 사이트({website.url})의 링크 목록입니다\"라는 문장을 작성.\n",
    "\n",
    "3. 요청 내용 추가\n",
    "python\n",
    "코드 복사\n",
    "user_prompt += \"please decide which of these are relevant web links for a brochure about the company, respond with the full https URL in JSON format. \\\n",
    "Do not include Terms of Service, Privacy, email links.\\n\"\n",
    "모델에게 지시:\n",
    "\n",
    "회사 브로셔에 쓸만한 관련 있는 링크만 고르기\n",
    "\n",
    "전체 HTTPS URL로 JSON 형식으로 응답하기\n",
    "\n",
    "이용 약관, 개인정보 처리방침, 이메일 링크는 제외하기\n",
    "\n",
    "4. 링크 목록 안내 문구\n",
    "python\n",
    "코드 복사\n",
    "user_prompt += \"Links (some might be relative links):\\n\"\n",
    "다음에 나올 링크들이 일부는 /about처럼 상대 경로일 수 있다는 걸 알려줌.\n",
    "\n",
    "5. 실제 링크들 추가\n",
    "python\n",
    "코드 복사\n",
    "user_prompt += \"\\n\".join(website.links)\n",
    "website.links 리스트의 모든 링크를 줄바꿈으로 이어붙임.\n",
    "\n",
    "6. 완성된 프롬프트 반환\n",
    "python\n",
    "코드 복사\n",
    "return user_prompt\n",
    "완성된 GPT 요청용 문자열을 돌려줌.\n",
    "\n",
    "💡 쉽게 말하면\n",
    "이 함수는\n",
    "\n",
    "“이 사이트 링크 목록을 줄 테니, 브로셔에 필요한 링크만 골라서 JSON으로 줘”\n",
    "라는 요청문을 자동으로 만들어주는 프롬프트 생성기입니다.\n",
    "\n",
    "원하면 제가 이 함수를 실행했을 때 실제로 만들어지는 프롬프트 예시를 하나 보여드릴 수 있습니다.\n",
    "그렇게 해드릴까요?\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "나의 말:\n",
    "응 예시도 보여줘\n",
    "\n",
    "\n",
    "ChatGPT의 말:\n",
    "좋아요 👍\n",
    "예를 들어, Website 객체가 이렇게 생겼다고 가정해볼게요.\n",
    "\n",
    "python\n",
    "코드 복사\n",
    "website = Website(\"https://company.com\")\n",
    "website.links = [\n",
    "    \"/about\",\n",
    "    \"/products\",\n",
    "    \"/contact\",\n",
    "    \"/privacy-policy\",\n",
    "    \"https://company.com/blog\",\n",
    "    \"mailto:info@company.com\"\n",
    "]\n",
    "이 상태에서 함수를 실행하면:\n",
    "\n",
    "python\n",
    "코드 복사\n",
    "print(get_links_user_prompt(website))\n",
    "실제 결과 예시\n",
    "swift\n",
    "코드 복사\n",
    "Here is the list of links on the website of https://company.com - please decide which of these are relevant web links for a brochure about the company, respond with the full https URL in JSON format. Do not include Terms of Service, Privacy, email links.\n",
    "Links (some might be relative links):\n",
    "/about\n",
    "/products\n",
    "/contact\n",
    "/privacy-policy\n",
    "https://company.com/blog\n",
    "mailto:info@company.com\n",
    "📌 이 프롬프트를 GPT에 보내면 모델은 이런 식으로 응답할 수 있어요:\n",
    "\n",
    "json\n",
    "코드 복사\n",
    "[\n",
    "  \"https://company.com/about\",\n",
    "  \"https://company.com/products\",\n",
    "  \"https://company.com/contact\",\n",
    "  \"https://company.com/blog\"\n",
    "]\n",
    "→ privacy-policy나 mailto: 같은 건 제외하고, 상대 경로는 절대 경로로 변환해서 줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6bcbfa78-6395-4685-b92c-22d592050fd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the list of links on the website of https://edwarddonner.com - please decide which of these are relevant web links for a brochure about the company, respond with the full https URL in JSON format. Do not include Terms of Service, Privacy, email links.\n",
      "Links (some might be relative links):\n",
      "https://edwarddonner.com/\n",
      "https://edwarddonner.com/connect-four/\n",
      "https://edwarddonner.com/outsmart/\n",
      "https://edwarddonner.com/about-me-and-about-nebula/\n",
      "https://edwarddonner.com/posts/\n",
      "https://edwarddonner.com/\n",
      "https://news.ycombinator.com\n",
      "https://nebula.io/?utm_source=ed&utm_medium=referral\n",
      "https://www.prnewswire.com/news-releases/wynden-stark-group-acquires-nyc-venture-backed-tech-startup-untapt-301269512.html\n",
      "https://patents.google.com/patent/US20210049536A1/\n",
      "https://www.linkedin.com/in/eddonner/\n",
      "https://edwarddonner.com/2025/05/28/connecting-my-courses-become-an-llm-expert-and-leader/\n",
      "https://edwarddonner.com/2025/05/28/connecting-my-courses-become-an-llm-expert-and-leader/\n",
      "https://edwarddonner.com/2025/05/18/2025-ai-executive-briefing/\n",
      "https://edwarddonner.com/2025/05/18/2025-ai-executive-briefing/\n",
      "https://edwarddonner.com/2025/04/21/the-complete-agentic-ai-engineering-course/\n",
      "https://edwarddonner.com/2025/04/21/the-complete-agentic-ai-engineering-course/\n",
      "https://edwarddonner.com/2025/01/23/llm-workshop-hands-on-with-agents-resources/\n",
      "https://edwarddonner.com/2025/01/23/llm-workshop-hands-on-with-agents-resources/\n",
      "https://edwarddonner.com/\n",
      "https://edwarddonner.com/connect-four/\n",
      "https://edwarddonner.com/outsmart/\n",
      "https://edwarddonner.com/about-me-and-about-nebula/\n",
      "https://edwarddonner.com/posts/\n",
      "mailto:hello@mygroovydomain.com\n",
      "https://www.linkedin.com/in/eddonner/\n",
      "https://twitter.com/edwarddonner\n",
      "https://www.facebook.com/edward.donner.52\n"
     ]
    }
   ],
   "source": [
    "print(get_links_user_prompt(ed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a29aca19-ca13-471c-a4b4-5abbfa813f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_links(url):\n",
    "    website = Website(url)\n",
    "    response = openai.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": link_system_prompt},\n",
    "            {\"role\": \"user\", \"content\": get_links_user_prompt(website)}\n",
    "      ],\n",
    "        response_format={\"type\": \"json_object\"}    ###RESPONSE 포맷 설정 가능, 프롬프트에도 명시해야 동작\n",
    "    )\n",
    "    result = response.choices[0].message.content\n",
    "    return json.loads(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef93ca0e-fe51-4711-87bf-c219e258469c",
   "metadata": {},
   "outputs": [],
   "source": [
    "좋아요! 이 한 줄이 하는 일을 쪼개서 아주 쉽게 설명해볼게요.\n",
    "\n",
    "핵심 요약\n",
    "response 안에는 모델의 여러 후보 답변(choices) 이 들어 있습니다.\n",
    "\n",
    "choices[0]는 그중 첫 번째 답변이고, .message.content가 그 답변의 순수 텍스트 내용입니다.\n",
    "\n",
    "그래서 result는 모델이 출력한 텍스트 문자열이 됩니다.\n",
    "\n",
    "쉬운 비유\n",
    "모델이 답안을 여러 장 제출할 수도 있어요(시험지 여러 버전). choices는 그 답안 묶음이고, choices[0]는 1번 답안지, 그 안의 message.content는 실제 적힌 글이에요. 우리는 “첫 번째 답안지의 글”을 꺼내 result에 담는 셈이죠.\n",
    "\n",
    "구조로 보기 (응답 객체의 전형적인 형태)\n",
    "scss\n",
    "코드 복사\n",
    "response\n",
    "└─ choices  ← 리스트(여러 개일 수 있음)\n",
    "   ├─ [0]\n",
    "   │   ├─ index\n",
    "   │   ├─ message\n",
    "   │   │   ├─ role (\"assistant\")\n",
    "   │   │   └─ content  ← 모델이 만든 텍스트\n",
    "   │   └─ finish_reason\n",
    "   └─ [1], [2], ...\n",
    "코드 한 줄 해석\n",
    "python\n",
    "코드 복사\n",
    "result = response.choices[0].message.content\n",
    "response.choices : 모델 답변 후보들의 리스트\n",
    "\n",
    "[0] : 첫 번째 후보 선택\n",
    "\n",
    ".message : 그 후보의 메시지 객체\n",
    "\n",
    ".content : 그 메시지의 텍스트(스트링)\n",
    "\n",
    "실전 팁 & 주의사항\n",
    "여러 후보를 요청한 경우\n",
    "n=3 같은 옵션으로 여러 답변을 받았다면, [1], [2]에서도 message.content를 꺼낼 수 있어요.\n",
    "\n",
    "함수/툴 호출 응답\n",
    "일부 호출(예: tool/function call)에서는 content가 비어 있고 tool_calls만 있을 수 있어요. 그땐 아래처럼 안전하게 처리하세요.\n",
    "\n",
    "python\n",
    "코드 복사\n",
    "msg = response.choices[0].message\n",
    "text = msg.content or \"\"\n",
    "if getattr(msg, \"tool_calls\", None):\n",
    "    # 여기서 툴 호출 정보를 처리\n",
    "    pass\n",
    "스트리밍 모드(stream=True)\n",
    "스트리밍이면 response가 이벤트 스트림 형태라 이 한 줄로는 못 꺼냅니다. 청크를 모아 이어붙여야 해요.\n",
    "\n",
    "다른 API와 혼동 주의\n",
    "예전 Completions API는 choices[0].text였고, Chat Completions은 choices[0].message.content입니다. 헷갈리면 문서를 확인하세요.\n",
    "\n",
    "원하면 지금 쓰고 있는 호출 코드에 맞춘 견고한 추출 함수(단일/다중 후보, 툴콜/스트리밍 대비)도 만들어 드릴게요.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ChatGPT에게 묻기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "74a827a0-2782-4ae5-b210-4a242a8b4cc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/',\n",
       " '/models',\n",
       " '/datasets',\n",
       " '/spaces',\n",
       " '/docs',\n",
       " '/enterprise',\n",
       " '/pricing',\n",
       " '/login',\n",
       " '/join',\n",
       " '/spaces',\n",
       " '/models',\n",
       " '/openai/gpt-oss-120b',\n",
       " '/openai/gpt-oss-20b',\n",
       " '/Qwen/Qwen-Image',\n",
       " '/tencent/Hunyuan-1.8B-Instruct',\n",
       " '/rednote-hilab/dots.ocr',\n",
       " '/models',\n",
       " '/spaces/Qwen/Qwen-Image',\n",
       " '/spaces/enzostvs/deepsite',\n",
       " '/spaces/black-forest-labs/FLUX.1-Krea-dev',\n",
       " '/spaces/Wan-AI/Wan-2.2-5B',\n",
       " '/spaces/alexnasa/OmniAvatar',\n",
       " '/spaces',\n",
       " '/datasets/fka/awesome-chatgpt-prompts',\n",
       " '/datasets/jxm/gpt-oss20b-samples',\n",
       " '/datasets/HuggingFaceH4/Multilingual-Thinking',\n",
       " '/datasets/openai/BrowseCompLongContext',\n",
       " '/datasets/nvidia/Nemotron-Post-Training-Dataset-v1',\n",
       " '/datasets',\n",
       " '/join',\n",
       " '/pricing#endpoints',\n",
       " '/pricing#spaces',\n",
       " '/pricing',\n",
       " '/enterprise',\n",
       " '/enterprise',\n",
       " '/enterprise',\n",
       " '/enterprise',\n",
       " '/enterprise',\n",
       " '/enterprise',\n",
       " '/enterprise',\n",
       " '/allenai',\n",
       " '/facebook',\n",
       " '/amazon',\n",
       " '/google',\n",
       " '/Intel',\n",
       " '/microsoft',\n",
       " '/grammarly',\n",
       " '/Writer',\n",
       " '/docs/transformers',\n",
       " '/docs/diffusers',\n",
       " '/docs/safetensors',\n",
       " '/docs/huggingface_hub',\n",
       " '/docs/tokenizers',\n",
       " '/docs/trl',\n",
       " '/docs/transformers.js',\n",
       " '/docs/smolagents',\n",
       " '/docs/peft',\n",
       " '/docs/datasets',\n",
       " '/docs/text-generation-inference',\n",
       " '/docs/accelerate',\n",
       " '/models',\n",
       " '/datasets',\n",
       " '/spaces',\n",
       " '/changelog',\n",
       " 'https://endpoints.huggingface.co',\n",
       " '/chat',\n",
       " '/huggingface',\n",
       " '/brand',\n",
       " '/terms-of-service',\n",
       " '/privacy',\n",
       " 'https://apply.workable.com/huggingface/',\n",
       " 'mailto:press@huggingface.co',\n",
       " '/learn',\n",
       " '/docs',\n",
       " '/blog',\n",
       " 'https://discuss.huggingface.co',\n",
       " 'https://status.huggingface.co/',\n",
       " 'https://github.com/huggingface',\n",
       " 'https://twitter.com/huggingface',\n",
       " 'https://www.linkedin.com/company/huggingface/',\n",
       " '/join/discord']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Anthropic has made their site harder to scrape, so I'm using HuggingFace..\n",
    "\n",
    "huggingface = Website(\"https://huggingface.co\")\n",
    "huggingface.links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3d583e2-dcc4-40cc-9b28-1e8dbf402924",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'links': [{'type': 'about page', 'url': 'https://huggingface.co/'},\n",
       "  {'type': 'enterprise page', 'url': 'https://huggingface.co/enterprise'},\n",
       "  {'type': 'pricing page', 'url': 'https://huggingface.co/pricing'},\n",
       "  {'type': 'careers page', 'url': 'https://apply.workable.com/huggingface/'},\n",
       "  {'type': 'blog page', 'url': 'https://huggingface.co/blog'},\n",
       "  {'type': 'company page',\n",
       "   'url': 'https://www.linkedin.com/company/huggingface/'}]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_links(\"https://huggingface.co\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d74128e-dfb6-47ec-9549-288b621c838c",
   "metadata": {},
   "source": [
    "## Second step: make the brochure!\n",
    "\n",
    "Assemble all the details into another prompt to GPT4-o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "85a5b6e2-e7ef-44a9-bc7f-59ede71037b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_details(url):\n",
    "    result = \"Landing page:\\n\"\n",
    "    result += Website(url).get_contents()  #해당 URL의 본문\n",
    "    links = get_links(url)  ## 모델 써서 관련있는 링크들 불러와\n",
    "    print(\"Found links:\", links) # 그거 프린트\n",
    "    for link in links[\"links\"]:\n",
    "        result += f\"\\n\\n{link['type']}\\n\"\n",
    "        result += Website(link[\"url\"]).get_contents()  #각 링크에 대한 컨텐츠 리절트에 추가\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef2bf63-87c8-49c7-8bde-c52dcd43d224",
   "metadata": {},
   "outputs": [],
   "source": [
    "좋아요 👍\n",
    "이 함수는 웹사이트 메인 페이지와, 그 안에서 뽑아낸 관련 링크들의 페이지 내용을 한 번에 모아주는 함수예요.\n",
    "단계별로 설명해 드릴게요.\n",
    "\n",
    "1. 함수 정의\n",
    "python\n",
    "코드 복사\n",
    "def get_all_details(url):\n",
    "url : 조사할 웹사이트 주소 (예: \"https://company.com\").\n",
    "\n",
    "2. 결과 문자열 초기화\n",
    "python\n",
    "코드 복사\n",
    "result = \"Landing page:\\n\"\n",
    "result라는 문자열을 만들고, 맨 앞에 \"Landing page:\\n\"를 넣어둡니다.\n",
    "\n",
    "나중에 여기에 각 페이지의 내용을 계속 덧붙일 거예요.\n",
    "\n",
    "3. 메인 페이지 내용 가져오기\n",
    "python\n",
    "코드 복사\n",
    "result += Website(url).get_contents()\n",
    "Website(url) → 앞에서 만든 Website 클래스로 해당 URL 페이지를 불러옴.\n",
    "\n",
    ".get_contents() → 그 페이지의 제목과 본문 텍스트를 문자열로 가져옴.\n",
    "\n",
    "이걸 result에 이어붙임.\n",
    "\n",
    "4. 관련 링크 가져오기\n",
    "python\n",
    "코드 복사\n",
    "links = get_links(url)\n",
    "get_links(url) : GPT 같은 모델을 써서 메인 페이지에서 회사 브로셔에 쓸만한 관련 링크들만 뽑아주는 함수.\n",
    "\n",
    "반환값 예시:\n",
    "\n",
    "python\n",
    "코드 복사\n",
    "{\n",
    "    \"links\": [\n",
    "        {\"type\": \"About\", \"url\": \"https://company.com/about\"},\n",
    "        {\"type\": \"Products\", \"url\": \"https://company.com/products\"}\n",
    "    ]\n",
    "}\n",
    "5. 찾은 링크 출력\n",
    "python\n",
    "코드 복사\n",
    "print(\"Found links:\", links)\n",
    "콘솔에 어떤 링크를 찾았는지 확인용으로 출력.\n",
    "\n",
    "6. 각 링크 페이지 내용 추가\n",
    "python\n",
    "코드 복사\n",
    "for link in links[\"links\"]:\n",
    "    result += f\"\\n\\n{link['type']}\\n\"\n",
    "    result += Website(link[\"url\"]).get_contents()\n",
    "links[\"links\"] 안에 있는 링크들을 하나씩 꺼내서:\n",
    "\n",
    "link['type'] : 페이지 유형(About, Products 등) 제목을 result에 추가\n",
    "\n",
    "Website(link[\"url\"]).get_contents() : 그 페이지의 제목과 본문 텍스트를 가져와서 result에 이어붙임.\n",
    "\n",
    "7. 최종 결과 반환\n",
    "python\n",
    "코드 복사\n",
    "return result\n",
    "메인 페이지 + 관련 링크 페이지들의 내용을 한 덩어리로 합친 문자열을 돌려줍니다.\n",
    "\n",
    "💡 쉽게 비유\n",
    "이건 **“홈페이지랑, 중요한 다른 페이지들까지 한 번에 스크랩해서 한 문서로 모아주는 수집기”**예요.\n",
    "\n",
    "1단계 : 메인 페이지 내용 수집\n",
    "\n",
    "2단계 : AI가 중요한 링크 추천\n",
    "\n",
    "3단계 : 그 링크 페이지들 내용 수집\n",
    "\n",
    "4단계 : 전부 합쳐서 하나의 결과물로 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5dd885-e5b1-4587-b372-568e35e658b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "그럼 get_all_details()가 실행됐을 때 나올 법한 예시를 만들어드릴게요.\n",
    "\n",
    "가정\n",
    "URL: \"https://company.com\"\n",
    "\n",
    "get_links(url)이 반환하는 값:\n",
    "\n",
    "python\n",
    "코드 복사\n",
    "{\n",
    "    \"links\": [\n",
    "        {\"type\": \"About\", \"url\": \"https://company.com/about\"},\n",
    "        {\"type\": \"Products\", \"url\": \"https://company.com/products\"}\n",
    "    ]\n",
    "}\n",
    "각 페이지에는 간단한 제목과 본문이 있다고 가정.\n",
    "\n",
    "실행 코드\n",
    "python\n",
    "코드 복사\n",
    "output = get_all_details(\"https://company.com\")\n",
    "print(output)\n",
    "결과 예시\n",
    "yaml\n",
    "코드 복사\n",
    "Landing page:\n",
    "Webpage Title:\n",
    "Company - Welcome\n",
    "Webpage Contents:\n",
    "Welcome to our company website.\n",
    "We offer a range of products and services to suit your needs.\n",
    "\n",
    "Found links: {\n",
    "    \"links\": [\n",
    "        {\"type\": \"About\", \"url\": \"https://company.com/about\"},\n",
    "        {\"type\": \"Products\", \"url\": \"https://company.com/products\"}\n",
    "    ]\n",
    "}\n",
    "\n",
    "About\n",
    "Webpage Title:\n",
    "About Us - Company\n",
    "Webpage Contents:\n",
    "Our company was founded in 2010 with the mission to deliver high-quality products worldwide.\n",
    "We value innovation, customer satisfaction, and sustainability.\n",
    "\n",
    "Products\n",
    "Webpage Title:\n",
    "Our Products - Company\n",
    "Webpage Contents:\n",
    "We offer electronics, home appliances, and software solutions.\n",
    "Visit our online store to learn more about each category.\n",
    "📌 흐름 정리\n",
    "\n",
    "\"Landing page:\" → 메인 페이지 제목과 본문\n",
    "\n",
    "\"Found links: ...\" → AI가 고른 관련 링크 출력\n",
    "\n",
    "각 링크의 type과 그 페이지의 제목·본문을 순서대로 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5099bd14-076d-4745-baf3-dac08d8e5ab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found links: {'links': [{'type': 'about page', 'url': 'https://huggingface.co'}, {'type': 'careers page', 'url': 'https://apply.workable.com/huggingface/'}, {'type': 'blog page', 'url': 'https://huggingface.co/blog'}, {'type': 'company page', 'url': 'https://www.linkedin.com/company/huggingface/'}, {'type': 'support page', 'url': 'https://discuss.huggingface.co'}, {'type': 'status page', 'url': 'https://status.huggingface.co'}]}\n",
      "Landing page:\n",
      "Webpage Title:\n",
      "Hugging Face – The AI community building the future.\n",
      "Webpage Contents:\n",
      "Hugging Face\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Community\n",
      "Docs\n",
      "Enterprise\n",
      "Pricing\n",
      "Log In\n",
      "Sign Up\n",
      "The AI community building the future.\n",
      "The platform where the machine learning community collaborates on models, datasets, and applications.\n",
      "Explore AI Apps\n",
      "or\n",
      "Browse 1M+ models\n",
      "Trending on\n",
      "this week\n",
      "Models\n",
      "openai/gpt-oss-120b\n",
      "Updated\n",
      "3 days ago\n",
      "•\n",
      "429k\n",
      "•\n",
      "3.16k\n",
      "openai/gpt-oss-20b\n",
      "Updated\n",
      "3 days ago\n",
      "•\n",
      "2M\n",
      "•\n",
      "2.73k\n",
      "Qwen/Qwen-Image\n",
      "Updated\n",
      "5 days ago\n",
      "•\n",
      "62.8k\n",
      "•\n",
      "1.42k\n",
      "tencent/Hunyuan-1.8B-Instruct\n",
      "Updated\n",
      "5 days ago\n",
      "•\n",
      "3.1k\n",
      "•\n",
      "573\n",
      "rednote-hilab/dots.ocr\n",
      "Updated\n",
      "4 days ago\n",
      "•\n",
      "16.2k\n",
      "•\n",
      "563\n",
      "Browse 1M+ models\n",
      "Spaces\n",
      "Running\n",
      "on\n",
      "Zero\n",
      "415\n",
      "415\n",
      "Qwen Image\n",
      "🖼\n",
      "Generate images from text prompts\n",
      "Running\n",
      "11.7k\n",
      "11.7k\n",
      "DeepSite v2\n",
      "🐳\n",
      "Generate any application with DeepSeek\n",
      "Running\n",
      "on\n",
      "Zero\n",
      "264\n",
      "264\n",
      "FLUX.1 Krea Dev\n",
      "📚\n",
      "Generate images from text prompts\n",
      "Running\n",
      "on\n",
      "Zero\n",
      "MCP\n",
      "282\n",
      "282\n",
      "Wan 2.2 5B\n",
      "🚀\n",
      "Generate high-quality videos from text prompts and images\n",
      "Running\n",
      "on\n",
      "Zero\n",
      "120\n",
      "120\n",
      "OmniAvatar\n",
      "🐨\n",
      "Generate podcast and tiktok style video avatars\n",
      "Browse 400k+ applications\n",
      "Datasets\n",
      "fka/awesome-chatgpt-prompts\n",
      "Updated\n",
      "Jan 6\n",
      "•\n",
      "32.4k\n",
      "•\n",
      "8.65k\n",
      "jxm/gpt-oss20b-samples\n",
      "Updated\n",
      "3 days ago\n",
      "•\n",
      "1.03k\n",
      "•\n",
      "55\n",
      "HuggingFaceH4/Multilingual-Thinking\n",
      "Updated\n",
      "4 days ago\n",
      "•\n",
      "6.15k\n",
      "•\n",
      "44\n",
      "openai/BrowseCompLongContext\n",
      "Updated\n",
      "2 days ago\n",
      "•\n",
      "568\n",
      "•\n",
      "30\n",
      "nvidia/Nemotron-Post-Training-Dataset-v1\n",
      "Updated\n",
      "10 days ago\n",
      "•\n",
      "15.9k\n",
      "•\n",
      "103\n",
      "Browse 250k+ datasets\n",
      "The Home of Machine Learning\n",
      "Create, discover and collaborate on ML better.\n",
      "The collaboration platform\n",
      "Host and collaborate on unlimited public models, datasets and applications.\n",
      "Move faster\n",
      "With the HF Open source stack.\n",
      "Explore all modalities\n",
      "Text, image, video, audio or even 3D.\n",
      "Build your portfolio\n",
      "Share your work with the world and build your ML profile.\n",
      "Sign Up\n",
      "Accelerate your ML\n",
      "We provide paid Compute and Enterprise solutions.\n",
      "Compute\n",
      "Deploy on optimized\n",
      "Inference Endpoints\n",
      "or update your\n",
      "Spaces applications\n",
      "to a GPU in a few clicks.\n",
      "View pricing\n",
      "Starting at $0.60/hour for GPU\n",
      "Team & Enterprise\n",
      "Give your team the most advanced platform to build AI with enterprise-grade security, access controls and\n",
      "\t\t\tdedicated support.\n",
      "Getting started\n",
      "Starting at $20/user/month\n",
      "Single Sign-On\n",
      "Regions\n",
      "Priority Support\n",
      "Audit Logs\n",
      "Resource Groups\n",
      "Private Datasets Viewer\n",
      "More than 50,000 organizations are using Hugging Face\n",
      "Ai2\n",
      "Enterprise\n",
      "non-profit\n",
      "•\n",
      "776 models\n",
      "•\n",
      "3.78k followers\n",
      "AI at Meta\n",
      "Enterprise\n",
      "company\n",
      "•\n",
      "2.2k models\n",
      "•\n",
      "7.11k followers\n",
      "Amazon\n",
      "company\n",
      "•\n",
      "20 models\n",
      "•\n",
      "3.35k followers\n",
      "Google\n",
      "Enterprise\n",
      "company\n",
      "•\n",
      "1.04k models\n",
      "•\n",
      "23.9k followers\n",
      "Intel\n",
      "company\n",
      "•\n",
      "239 models\n",
      "•\n",
      "2.86k followers\n",
      "Microsoft\n",
      "company\n",
      "•\n",
      "419 models\n",
      "•\n",
      "14.1k followers\n",
      "Grammarly\n",
      "Team\n",
      "company\n",
      "•\n",
      "10 models\n",
      "•\n",
      "171 followers\n",
      "Writer\n",
      "Enterprise\n",
      "company\n",
      "•\n",
      "21 models\n",
      "•\n",
      "318 followers\n",
      "Our Open Source\n",
      "We are building the foundation of ML tooling with the community.\n",
      "Transformers\n",
      "148,174\n",
      "State-of-the-art AI models for PyTorch\n",
      "Diffusers\n",
      "30,205\n",
      "State-of-the-art Diffusion models in PyTorch\n",
      "Safetensors\n",
      "3,392\n",
      "Safe way to store/distribute neural network weights\n",
      "Hub Python Library\n",
      "2,831\n",
      "Python client to interact with the Hugging Face Hub\n",
      "Tokenizers\n",
      "9,978\n",
      "Fast tokenizers optimized for research & production\n",
      "TRL\n",
      "15,028\n",
      "Train transformers LMs with reinforcement learning\n",
      "Transformers.js\n",
      "14,316\n",
      "State-of-the-art ML running directly in your browser\n",
      "smolagents\n",
      "21,995\n",
      "Smol library to build great agents in Python\n",
      "PEFT\n",
      "19,281\n",
      "Parameter-efficient finetuning for large language models\n",
      "Datasets\n",
      "20,484\n",
      "Access & share datasets for any ML tasks\n",
      "Text Generation Inference\n",
      "10,412\n",
      "Serve language models with TGI optimized toolkit\n",
      "Accelerate\n",
      "9,021\n",
      "Train PyTorch models with multi-GPU, TPU, mixed precision\n",
      "System theme\n",
      "Website\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Changelog\n",
      "Inference Endpoints\n",
      "HuggingChat\n",
      "Company\n",
      "About\n",
      "Brand assets\n",
      "Terms of service\n",
      "Privacy\n",
      "Jobs\n",
      "Press\n",
      "Resources\n",
      "Learn\n",
      "Documentation\n",
      "Blog\n",
      "Forum\n",
      "Service Status\n",
      "Social\n",
      "GitHub\n",
      "Twitter\n",
      "LinkedIn\n",
      "Discord\n",
      "\n",
      "\n",
      "\n",
      "about page\n",
      "Webpage Title:\n",
      "Hugging Face – The AI community building the future.\n",
      "Webpage Contents:\n",
      "Hugging Face\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Community\n",
      "Docs\n",
      "Enterprise\n",
      "Pricing\n",
      "Log In\n",
      "Sign Up\n",
      "The AI community building the future.\n",
      "The platform where the machine learning community collaborates on models, datasets, and applications.\n",
      "Explore AI Apps\n",
      "or\n",
      "Browse 1M+ models\n",
      "Trending on\n",
      "this week\n",
      "Models\n",
      "openai/gpt-oss-120b\n",
      "Updated\n",
      "3 days ago\n",
      "•\n",
      "429k\n",
      "•\n",
      "3.16k\n",
      "openai/gpt-oss-20b\n",
      "Updated\n",
      "3 days ago\n",
      "•\n",
      "2M\n",
      "•\n",
      "2.73k\n",
      "Qwen/Qwen-Image\n",
      "Updated\n",
      "5 days ago\n",
      "•\n",
      "62.8k\n",
      "•\n",
      "1.42k\n",
      "tencent/Hunyuan-1.8B-Instruct\n",
      "Updated\n",
      "5 days ago\n",
      "•\n",
      "3.1k\n",
      "•\n",
      "573\n",
      "rednote-hilab/dots.ocr\n",
      "Updated\n",
      "4 days ago\n",
      "•\n",
      "16.2k\n",
      "•\n",
      "563\n",
      "Browse 1M+ models\n",
      "Spaces\n",
      "Running\n",
      "on\n",
      "Zero\n",
      "415\n",
      "415\n",
      "Qwen Image\n",
      "🖼\n",
      "Generate images from text prompts\n",
      "Running\n",
      "11.7k\n",
      "11.7k\n",
      "DeepSite v2\n",
      "🐳\n",
      "Generate any application with DeepSeek\n",
      "Running\n",
      "on\n",
      "Zero\n",
      "264\n",
      "264\n",
      "FLUX.1 Krea Dev\n",
      "📚\n",
      "Generate images from text prompts\n",
      "Running\n",
      "on\n",
      "Zero\n",
      "MCP\n",
      "282\n",
      "282\n",
      "Wan 2.2 5B\n",
      "🚀\n",
      "Generate high-quality videos from text prompts and images\n",
      "Running\n",
      "on\n",
      "Zero\n",
      "120\n",
      "120\n",
      "OmniAvatar\n",
      "🐨\n",
      "Generate podcast and tiktok style video avatars\n",
      "Browse 400k+ applications\n",
      "Datasets\n",
      "fka/awesome-chatgpt-prompts\n",
      "Updated\n",
      "Jan 6\n",
      "•\n",
      "32.4k\n",
      "•\n",
      "8.65k\n",
      "jxm/gpt-oss20b-samples\n",
      "Updated\n",
      "3 days ago\n",
      "•\n",
      "1.03k\n",
      "•\n",
      "55\n",
      "HuggingFaceH4/Multilingual-Thinking\n",
      "Updated\n",
      "4 days ago\n",
      "•\n",
      "6.15k\n",
      "•\n",
      "44\n",
      "openai/BrowseCompLongContext\n",
      "Updated\n",
      "2 days ago\n",
      "•\n",
      "568\n",
      "•\n",
      "30\n",
      "nvidia/Nemotron-Post-Training-Dataset-v1\n",
      "Updated\n",
      "10 days ago\n",
      "•\n",
      "15.9k\n",
      "•\n",
      "103\n",
      "Browse 250k+ datasets\n",
      "The Home of Machine Learning\n",
      "Create, discover and collaborate on ML better.\n",
      "The collaboration platform\n",
      "Host and collaborate on unlimited public models, datasets and applications.\n",
      "Move faster\n",
      "With the HF Open source stack.\n",
      "Explore all modalities\n",
      "Text, image, video, audio or even 3D.\n",
      "Build your portfolio\n",
      "Share your work with the world and build your ML profile.\n",
      "Sign Up\n",
      "Accelerate your ML\n",
      "We provide paid Compute and Enterprise solutions.\n",
      "Compute\n",
      "Deploy on optimized\n",
      "Inference Endpoints\n",
      "or update your\n",
      "Spaces applications\n",
      "to a GPU in a few clicks.\n",
      "View pricing\n",
      "Starting at $0.60/hour for GPU\n",
      "Team & Enterprise\n",
      "Give your team the most advanced platform to build AI with enterprise-grade security, access controls and\n",
      "\t\t\tdedicated support.\n",
      "Getting started\n",
      "Starting at $20/user/month\n",
      "Single Sign-On\n",
      "Regions\n",
      "Priority Support\n",
      "Audit Logs\n",
      "Resource Groups\n",
      "Private Datasets Viewer\n",
      "More than 50,000 organizations are using Hugging Face\n",
      "Ai2\n",
      "Enterprise\n",
      "non-profit\n",
      "•\n",
      "776 models\n",
      "•\n",
      "3.78k followers\n",
      "AI at Meta\n",
      "Enterprise\n",
      "company\n",
      "•\n",
      "2.2k models\n",
      "•\n",
      "7.11k followers\n",
      "Amazon\n",
      "company\n",
      "•\n",
      "20 models\n",
      "•\n",
      "3.35k followers\n",
      "Google\n",
      "Enterprise\n",
      "company\n",
      "•\n",
      "1.04k models\n",
      "•\n",
      "23.9k followers\n",
      "Intel\n",
      "company\n",
      "•\n",
      "239 models\n",
      "•\n",
      "2.86k followers\n",
      "Microsoft\n",
      "company\n",
      "•\n",
      "419 models\n",
      "•\n",
      "14.1k followers\n",
      "Grammarly\n",
      "Team\n",
      "company\n",
      "•\n",
      "10 models\n",
      "•\n",
      "171 followers\n",
      "Writer\n",
      "Enterprise\n",
      "company\n",
      "•\n",
      "21 models\n",
      "•\n",
      "318 followers\n",
      "Our Open Source\n",
      "We are building the foundation of ML tooling with the community.\n",
      "Transformers\n",
      "148,174\n",
      "State-of-the-art AI models for PyTorch\n",
      "Diffusers\n",
      "30,205\n",
      "State-of-the-art Diffusion models in PyTorch\n",
      "Safetensors\n",
      "3,392\n",
      "Safe way to store/distribute neural network weights\n",
      "Hub Python Library\n",
      "2,831\n",
      "Python client to interact with the Hugging Face Hub\n",
      "Tokenizers\n",
      "9,978\n",
      "Fast tokenizers optimized for research & production\n",
      "TRL\n",
      "15,028\n",
      "Train transformers LMs with reinforcement learning\n",
      "Transformers.js\n",
      "14,316\n",
      "State-of-the-art ML running directly in your browser\n",
      "smolagents\n",
      "21,995\n",
      "Smol library to build great agents in Python\n",
      "PEFT\n",
      "19,281\n",
      "Parameter-efficient finetuning for large language models\n",
      "Datasets\n",
      "20,484\n",
      "Access & share datasets for any ML tasks\n",
      "Text Generation Inference\n",
      "10,412\n",
      "Serve language models with TGI optimized toolkit\n",
      "Accelerate\n",
      "9,021\n",
      "Train PyTorch models with multi-GPU, TPU, mixed precision\n",
      "System theme\n",
      "Website\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Changelog\n",
      "Inference Endpoints\n",
      "HuggingChat\n",
      "Company\n",
      "About\n",
      "Brand assets\n",
      "Terms of service\n",
      "Privacy\n",
      "Jobs\n",
      "Press\n",
      "Resources\n",
      "Learn\n",
      "Documentation\n",
      "Blog\n",
      "Forum\n",
      "Service Status\n",
      "Social\n",
      "GitHub\n",
      "Twitter\n",
      "LinkedIn\n",
      "Discord\n",
      "Zhihu\n",
      "WeChat\n",
      "\n",
      "\n",
      "\n",
      "careers page\n",
      "Webpage Title:\n",
      "Hugging Face - Current Openings\n",
      "Webpage Contents:\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "blog page\n",
      "Webpage Title:\n",
      "Hugging Face – Blog\n",
      "Webpage Contents:\n",
      "Hugging Face\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Community\n",
      "Docs\n",
      "Enterprise\n",
      "Pricing\n",
      "Log In\n",
      "Sign Up\n",
      "Blog, Articles, and discussions\n",
      "New Article\n",
      "Everything\n",
      "community\n",
      "guide\n",
      "open source collab\n",
      "partnerships\n",
      "research\n",
      "NLP\n",
      "Audio\n",
      "CV\n",
      "RL\n",
      "ethics\n",
      "Diffusion\n",
      "Game Development\n",
      "RLHF\n",
      "Leaderboard\n",
      "Case Studies\n",
      "LeRobot\n",
      "Inference Providers\n",
      "Introducing AI Sheets: a tool to work with datasets using open AI models!\n",
      "By\n",
      "dvilasuero\n",
      "August 8, 2025\n",
      "•\n",
      "26\n",
      "Community Articles\n",
      "view all\n",
      "What Open-Source Developers Need to Know about the EU AI Act's Rules for GPAI Models\n",
      "By\n",
      "yjernite\n",
      "and 5 others\n",
      "•\n",
      "7 days ago\n",
      "•\n",
      "23\n",
      "AWorld Multi-Agent System Hits #1 on GAIA Leaderboard\n",
      "By\n",
      "chengle\n",
      "•\n",
      "4 days ago\n",
      "•\n",
      "18\n",
      "Towards Open Evolutionary Agents\n",
      "By\n",
      "driaforall\n",
      "and 1 other\n",
      "•\n",
      "7 days ago\n",
      "•\n",
      "12\n",
      "The GPT-OSS models are here… and they’re energy-efficient!\n",
      "By\n",
      "sasha\n",
      "•\n",
      "4 days ago\n",
      "•\n",
      "12\n",
      "Code a simple RAG from scratch\n",
      "By\n",
      "ngxson\n",
      "•\n",
      "Oct 29, 2024\n",
      "•\n",
      "147\n",
      "Uncensor any LLM with abliteration\n",
      "By\n",
      "mlabonne\n",
      "•\n",
      "Jun 13, 2024\n",
      "•\n",
      "647\n",
      "LLM agent experiment with a purpose-built RPG and tool calls. (Work in progress)\n",
      "By\n",
      "neph1\n",
      "•\n",
      "6 days ago\n",
      "•\n",
      "7\n",
      "DeepSeek-R1 Dissection: Understanding PPO & GRPO Without Any Prior Reinforcement Learning Knowledge\n",
      "By\n",
      "NormalUhr\n",
      "•\n",
      "Feb 7\n",
      "•\n",
      "201\n",
      "Building Enterprise-Ready Text Classifiers in Minutes with Adaptive Learning\n",
      "By\n",
      "codelion\n",
      "•\n",
      "2 days ago\n",
      "•\n",
      "6\n",
      "ChatML vs Harmony: Understanding the new Format from OpenAI 🔍\n",
      "By\n",
      "kuotient\n",
      "•\n",
      "2 days ago\n",
      "•\n",
      "6\n",
      "Introducing ColQwen-Omni: Retrieve in every modality\n",
      "By\n",
      "manu\n",
      "and 4 others\n",
      "•\n",
      "25 days ago\n",
      "•\n",
      "64\n",
      "What I Learned Upscaling a Long-distance Midjourney Photo w/ Stable Diffusion PLUS unboxing Qwen Image & Wan 2.2\n",
      "By\n",
      "jasonhargrove\n",
      "•\n",
      "3 days ago\n",
      "•\n",
      "5\n",
      "Luth: Efficient French Specialization for Small Language Models\n",
      "By\n",
      "MaxLSB\n",
      "and 1 other\n",
      "•\n",
      "about 4 hours ago\n",
      "•\n",
      "5\n",
      "RynnVLA-001: Using Human Demonstrations to Improve Robot Manipulation\n",
      "By\n",
      "Alibaba-DAMO-Academy\n",
      "and 9 others\n",
      "•\n",
      "about 3 hours ago\n",
      "•\n",
      "5\n",
      "makeMoE: Implement a Sparse Mixture of Experts Language Model from Scratch\n",
      "By\n",
      "AviSoori1x\n",
      "•\n",
      "May 7, 2024\n",
      "•\n",
      "93\n",
      "G2P Shrinks Speech Models\n",
      "By\n",
      "hexgrad\n",
      "•\n",
      "Feb 5\n",
      "•\n",
      "66\n",
      "Measuring Open-Source Llama Nemotron Models on DeepResearch Bench\n",
      "By\n",
      "nvidia\n",
      "•\n",
      "7 days ago\n",
      "•\n",
      "4\n",
      "From GRPO to DAPO and GSPO: What, Why, and How\n",
      "By\n",
      "NormalUhr\n",
      "•\n",
      "2 days ago\n",
      "•\n",
      "4\n",
      "OpenAI just dropped two massive open-weight models — *but how do we separate the reality from the hype?*\n",
      "By\n",
      "stefanwebb\n",
      "and 2 others\n",
      "•\n",
      "1 day ago\n",
      "•\n",
      "4\n",
      "ColPali: Efficient Document Retrieval with Vision Language Models 👀\n",
      "By\n",
      "manu\n",
      "•\n",
      "Jul 5, 2024\n",
      "•\n",
      "286\n",
      "Accelerate ND-Parallel: A Guide to Efficient Multi-GPU Training\n",
      "By\n",
      "siro1\n",
      "August 8, 2025\n",
      "•\n",
      "32\n",
      "Vision Language Model Alignment in TRL ⚡️\n",
      "By\n",
      "sergiopaniego\n",
      "August 7, 2025\n",
      "•\n",
      "37\n",
      "Welcome GPT OSS, the new open-source model family from OpenAI!\n",
      "By\n",
      "reach-vb\n",
      "August 5, 2025\n",
      "•\n",
      "434\n",
      "Build an AI Shopping Assistant with Gradio MCP Servers\n",
      "By\n",
      "freddyaboulton\n",
      "July 31, 2025\n",
      "•\n",
      "35\n",
      "Introducing Trackio: A Lightweight Experiment Tracking Library from Hugging Face\n",
      "By\n",
      "abidlabs\n",
      "July 29, 2025\n",
      "•\n",
      "144\n",
      "Say hello to `hf`: a faster, friendlier Hugging Face CLI ✨\n",
      "By\n",
      "Wauplin\n",
      "July 25, 2025\n",
      "•\n",
      "70\n",
      "Parquet Content-Defined Chunking\n",
      "By\n",
      "kszucs\n",
      "July 25, 2025\n",
      "•\n",
      "54\n",
      "TimeScope: How Long Can Your Video Large Multimodal Model Go?\n",
      "By\n",
      "orrzohar\n",
      "July 23, 2025\n",
      "•\n",
      "34\n",
      "Fast LoRA inference for Flux with Diffusers and PEFT\n",
      "By\n",
      "sayakpaul\n",
      "July 23, 2025\n",
      "•\n",
      "42\n",
      "Arc Virtual Cell Challenge: A Primer\n",
      "By\n",
      "FL33TW00D-HF\n",
      "July 18, 2025\n",
      "•\n",
      "50\n",
      "Consilium: When Multiple LLMs Collaborate\n",
      "By\n",
      "azettl\n",
      "July 17, 2025\n",
      "guest\n",
      "•\n",
      "21\n",
      "Back to The Future: Evaluating AI Agents on Predicting Future Events\n",
      "By\n",
      "vinid\n",
      "July 17, 2025\n",
      "guest\n",
      "•\n",
      "31\n",
      "Five Big Improvements to Gradio MCP Servers\n",
      "By\n",
      "freddyaboulton\n",
      "July 17, 2025\n",
      "•\n",
      "20\n",
      "Seq vs Seq: the Ettin Suite of Paired Encoders and Decoders\n",
      "By\n",
      "orionweller\n",
      "July 16, 2025\n",
      "•\n",
      "57\n",
      "Previous\n",
      "1\n",
      "2\n",
      "3\n",
      "...\n",
      "44\n",
      "Next\n",
      "Community Articles\n",
      "Sort: \n",
      "\t\tTrending\n",
      "What Open-Source Developers Need to Know about the EU AI Act's Rules for GPAI Models\n",
      "By\n",
      "yjernite\n",
      "and 5 others\n",
      "•\n",
      "7 days ago\n",
      "•\n",
      "23\n",
      "AWorld Multi-Agent System Hits #1 on GAIA Leaderboard\n",
      "By\n",
      "chengle\n",
      "•\n",
      "4 days ago\n",
      "•\n",
      "18\n",
      "Towards Open Evolutionary Agents\n",
      "By\n",
      "driaforall\n",
      "and 1 other\n",
      "•\n",
      "7 days ago\n",
      "•\n",
      "12\n",
      "The GPT-OSS models are here… and they’re energy-efficient!\n",
      "By\n",
      "sasha\n",
      "•\n",
      "4 days ago\n",
      "•\n",
      "12\n",
      "Code a simple RAG from scratch\n",
      "By\n",
      "ngxson\n",
      "•\n",
      "Oct 29, 2024\n",
      "•\n",
      "147\n",
      "Uncensor any LLM with abliteration\n",
      "By\n",
      "mlabonne\n",
      "•\n",
      "Jun 13, 2024\n",
      "•\n",
      "647\n",
      "LLM agent experiment with a purpose-built RPG and tool calls. (Work in progress)\n",
      "By\n",
      "neph1\n",
      "•\n",
      "6 days ago\n",
      "•\n",
      "7\n",
      "DeepSeek-R1 Dissection: Understanding PPO & GRPO Without Any Prior Reinforcement Learning Knowledge\n",
      "By\n",
      "NormalUhr\n",
      "•\n",
      "Feb 7\n",
      "•\n",
      "201\n",
      "Building Enterprise-Ready Text Classifiers in Minutes with Adaptive Learning\n",
      "By\n",
      "codelion\n",
      "•\n",
      "2 days ago\n",
      "•\n",
      "6\n",
      "ChatML vs Harmony: Understanding the new Format from OpenAI 🔍\n",
      "By\n",
      "kuotient\n",
      "•\n",
      "2 days ago\n",
      "•\n",
      "6\n",
      "Introducing ColQwen-Omni: Retrieve in every modality\n",
      "By\n",
      "manu\n",
      "and 4 others\n",
      "•\n",
      "25 days ago\n",
      "•\n",
      "64\n",
      "What I Learned Upscaling a Long-distance Midjourney Photo w/ Stable Diffusion PLUS unboxing Qwen Image & Wan 2.2\n",
      "By\n",
      "jasonhargrove\n",
      "•\n",
      "3 days ago\n",
      "•\n",
      "5\n",
      "Luth: Efficient French Specialization for Small Language Models\n",
      "By\n",
      "MaxLSB\n",
      "and 1 other\n",
      "•\n",
      "about 4 hours ago\n",
      "•\n",
      "5\n",
      "RynnVLA-001: Using Human Demonstrations to Improve Robot Manipulation\n",
      "By\n",
      "Alibaba-DAMO-Academy\n",
      "and 9 others\n",
      "•\n",
      "about 3 hours ago\n",
      "•\n",
      "5\n",
      "makeMoE: Implement a Sparse Mixture of Experts Language Model from Scratch\n",
      "By\n",
      "AviSoori1x\n",
      "•\n",
      "May 7, 2024\n",
      "•\n",
      "93\n",
      "G2P Shrinks Speech Models\n",
      "By\n",
      "hexgrad\n",
      "•\n",
      "Feb 5\n",
      "•\n",
      "66\n",
      "Measuring Open-Source Llama Nemotron Models on DeepResearch Bench\n",
      "By\n",
      "nvidia\n",
      "•\n",
      "7 days ago\n",
      "•\n",
      "4\n",
      "From GRPO to DAPO and GSPO: What, Why, and How\n",
      "By\n",
      "NormalUhr\n",
      "•\n",
      "2 days ago\n",
      "•\n",
      "4\n",
      "OpenAI just dropped two massive open-weight models — *but how do we separate the reality from the hype?*\n",
      "By\n",
      "stefanwebb\n",
      "and 2 others\n",
      "•\n",
      "1 day ago\n",
      "•\n",
      "4\n",
      "ColPali: Efficient Document Retrieval with Vision Language Models 👀\n",
      "By\n",
      "manu\n",
      "•\n",
      "Jul 5, 2024\n",
      "•\n",
      "286\n",
      "View all\n",
      "System theme\n",
      "Company\n",
      "TOS\n",
      "Privacy\n",
      "About\n",
      "Jobs\n",
      "Website\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Pricing\n",
      "Docs\n",
      "\n",
      "\n",
      "\n",
      "company page\n",
      "Webpage Title:\n",
      "Hugging Face | LinkedIn\n",
      "Webpage Contents:\n",
      "Skip to main content\n",
      "LinkedIn\n",
      "Top Content\n",
      "People\n",
      "Learning\n",
      "Jobs\n",
      "Games\n",
      "Get the app\n",
      "Join now\n",
      "Sign in\n",
      "Hugging Face\n",
      "Software Development\n",
      "The AI community building the future.\n",
      "See jobs\n",
      "Follow\n",
      "Discover all 602 employees\n",
      "Report this company\n",
      "About us\n",
      "The AI community building the future.\n",
      "Website\n",
      "https://huggingface.co\n",
      "External link for Hugging Face\n",
      "Industry\n",
      "Software Development\n",
      "Company size\n",
      "51-200 employees\n",
      "Type\n",
      "Privately Held\n",
      "Founded\n",
      "2016\n",
      "Specialties\n",
      "machine learning, natural language processing, and deep learning\n",
      "Products\n",
      "Hugging Face\n",
      "Hugging Face\n",
      "Natural Language Processing (NLP) Software\n",
      "We’re on a journey to solve and democratize artificial intelligence through natural language.\n",
      "Locations\n",
      "Primary\n",
      "Get directions\n",
      "Paris, FR\n",
      "Get directions\n",
      "Employees at Hugging Face\n",
      "Ludovic Huraux\n",
      "Rajat Arya\n",
      "Tech Lead & Software Engineer @ HF | prev: co-founder XetHub, Apple, Turi, AWS, Microsoft\n",
      "Jeff Boudier\n",
      "Product + Growth at Hugging Face\n",
      "Terrence Rohan\n",
      "Seed Investor\n",
      "See all employees\n",
      "Updates\n",
      "Hugging Face\n",
      "reposted this\n",
      "Gradio\n",
      "68,519 followers\n",
      "3h\n",
      "Edited\n",
      "Report this post\n",
      "LIA-X, the Portrait Animator! 🔥 Animate your portraits, or 🆕 Edit your talking head in videos -- neck, mouth, cheek, and eyes region.\n",
      "\n",
      "Gradio app released on\n",
      "Hugging Face\n",
      ":\n",
      "https://lnkd.in/gkzKsTfv\n",
      "…more\n",
      "20\n",
      "1 Comment\n",
      "Like\n",
      "Comment\n",
      "Share\n",
      "Hugging Face\n",
      "1,033,968 followers\n",
      "2d\n",
      "Report this post\n",
      "🦾🦾🦾\n",
      "Clem Delangue 🤗\n",
      "Clem Delangue 🤗 is an Influencer\n",
      "Co-founder & CEO at Hugging Face\n",
      "2d\n",
      "So excited to announce that\n",
      "Hugging Face\n",
      "LeRobot can now be installed with a simple pip install and just crossed 15,000\n",
      "GitHub\n",
      "stars!\n",
      "\n",
      "It's already integrated into hundreds of robots, ranging from simple hand grippers like the SO-100/101 all the way to some of the most complex humanoid robots like\n",
      "Pollen Robotics\n",
      "Reachy 2.\n",
      "\n",
      "Thanks to all contributors of policies, models & datasets (like\n",
      "NVIDIA\n",
      ",\n",
      "Physical Intelligence\n",
      ",\n",
      "Microsoft\n",
      ", SmolVLA,...) who already shared over 1,500 models & 15,000 datasets, it's becoming the standard to bridge hardware and software in AI robotics.\n",
      "\n",
      "Let's go open AI robotics 🦾🦾🦾\n",
      "226\n",
      "6 Comments\n",
      "Like\n",
      "Comment\n",
      "Share\n",
      "Hugging Face\n",
      "reposted this\n",
      "Daniel Vila Suero\n",
      "Building data tools @ Hugging Face 🤗\n",
      "2d\n",
      "Report this post\n",
      "Tired of just reading about how good or bad the latest AI models are? Introducing\n",
      "Hugging Face\n",
      "AI Sheets, the open-source tool for getting data work done 👇 \n",
      "\n",
      "\n",
      "I'm super excited to release this open-source tool for the community.\n",
      "\n",
      "It lets you experiment with thousands of models on data you care about! \n",
      "\n",
      "You can run it on the Hub or locally (yes, it works with local models too).\n",
      "\n",
      "Let's go open source AI!\n",
      "\n",
      "Repo:\n",
      "https://lnkd.in/gdKeV-zW\n",
      "Blog post in the first comment.\n",
      "141\n",
      "10 Comments\n",
      "Like\n",
      "Comment\n",
      "Share\n",
      "Hugging Face\n",
      "reposted this\n",
      "Gradio\n",
      "68,519 followers\n",
      "3d\n",
      "Report this post\n",
      "Introducing\n",
      "https://gpt.gradio.app/\n",
      ", now you can chat with\n",
      "OpenAI\n",
      "'s latest gpt-oss models and use thousands of\n",
      "Hugging Face\n",
      "Spaces as MCP servers.\n",
      "…more\n",
      "124\n",
      "5 Comments\n",
      "Like\n",
      "Comment\n",
      "Share\n",
      "Hugging Face\n",
      "reposted this\n",
      "Daniel van Strien\n",
      "Machine Learning Librarian at Hugging Face 🤗 | Making AI work for libraries, archives, and their communities\n",
      "3d\n",
      "Report this post\n",
      "What if OCR models could show you their thought process?\n",
      "\n",
      "NuMarkdown-8B-Thinking from\n",
      "NuMind (YC S22)\n",
      "doesn't just extract text - it reasons through documents first, showing you exactly HOW it analyses structure before converting to markdown.\n",
      "\n",
      "Could this be particularly useful for challenging historical documents? \n",
      " \n",
      "- Complex multi-column layouts? It thinks through the reading order\n",
      "- Nested tables with merged cells? It maps the structure first\n",
      "- Mixed fonts and decorative elements? It identifies what's content vs decoration\n",
      "\n",
      "Here's it analysing a 1878 medical report from Calcutta (from the\n",
      "National Library of Scotland\n",
      ") - you can literally see it thinking through the layout step-by-step before extraction.\n",
      "\n",
      "You can try the model easily yourself thanks to\n",
      "Hugging Face\n",
      "Jobs and\n",
      "Astral\n",
      "uv\n",
      "\n",
      "hf jobs uv run --flavor l4x4 \\\n",
      "[\n",
      "script-url.html\n",
      "] \\\n",
      "your-dataset \\\n",
      "output-dataset \\\n",
      "--include-thinking\n",
      "\n",
      "My UV Scripts OCR collection now has 3 VLM based OCR models:\n",
      " 🚀 RolmOCR - one of the OG of the recent OCR VLMs from\n",
      "Reducto\n",
      "📐 Nanonets - LaTeX & complex tables\n",
      " 🧠 NuMarkdown - Reasoning-based (NEW!) from\n",
      "NuMind (YC S22)\n",
      "All can be run easily against an existing\n",
      "Hugging Face\n",
      "dataset with no setup! \n",
      "\n",
      "You can view the results on OCR Time Capsule:\n",
      "https://lnkd.in/eyX4zJhK\n",
      ".\n",
      "\n",
      "Full collection of OCR scripts:\n",
      "https://lnkd.in/eDmzb5Hv\n",
      "#DigitalHumanities\n",
      "#OCR\n",
      "#GLAM\n",
      "#MachineLearning\n",
      "#AI\n",
      "652\n",
      "23 Comments\n",
      "Like\n",
      "Comment\n",
      "Share\n",
      "Hugging Face\n",
      "reposted this\n",
      "Merve Noyan\n",
      "open-sourceress at 🤗\n",
      "3d\n",
      "Report this post\n",
      "new TRL comes with GRPO & MPO support for vision language models 💥\n",
      "\n",
      "we also dropped an explainer on them & how to train with one-liner CLI commands 🫡 \n",
      "find it in comments 💬\n",
      "204\n",
      "3 Comments\n",
      "Like\n",
      "Comment\n",
      "Share\n",
      "Hugging Face\n",
      "reposted this\n",
      "Gradio\n",
      "68,519 followers\n",
      "4d\n",
      "Report this post\n",
      "ChatGPT, but with access to 2700+ MCP Servers 🤯 \n",
      "\n",
      "Much before 10 am PT 😉 Stay tuned!\n",
      "…more\n",
      "86\n",
      "3 Comments\n",
      "Like\n",
      "Comment\n",
      "Share\n",
      "Hugging Face\n",
      "reposted this\n",
      "Daniel van Strien\n",
      "Machine Learning Librarian at Hugging Face 🤗 | Making AI work for libraries, archives, and their communities\n",
      "5d\n",
      "Report this post\n",
      "Generate synthetic data using\n",
      "OpenAI\n",
      "'s GPT OSS models on\n",
      "Hugging Face\n",
      "Jobs!\n",
      "\n",
      "I just shipped a simple script that runs with one command - no local setup needed (powered by\n",
      "Astral\n",
      "'s uv under the hood!) \n",
      "\n",
      " hf jobs uv run --flavor l4x4  SCRIPT_URL  --input-dataset your/dataset  --output-dataset your/output\n",
      "\n",
      " - Works on L4 GPUs\n",
      " - Captures reasoning traces\n",
      " - Auto-handles dataset upload\n",
      "\n",
      "I already used it to generate some low reasoning effort haiku! \n",
      "\n",
      "Check it out:\n",
      "https://lnkd.in/eQbc2484\n",
      "#AI\n",
      "#MachineLearning\n",
      "#OpenSource\n",
      "#SyntheticData\n",
      "198\n",
      "5 Comments\n",
      "Like\n",
      "Comment\n",
      "Share\n",
      "Hugging Face\n",
      "1,033,968 followers\n",
      "5d\n",
      "Report this post\n",
      "Welcome to\n",
      "OpenAI\n",
      "on\n",
      "Hugging Face\n",
      "!\n",
      "613\n",
      "17 Comments\n",
      "Like\n",
      "Comment\n",
      "Share\n",
      "Join now to see what you are missing\n",
      "Find people you know at Hugging Face\n",
      "Browse recommended jobs for you\n",
      "View all updates, news, and articles\n",
      "Join now\n",
      "Similar pages\n",
      "Anthropic\n",
      "Research Services\n",
      "Perplexity\n",
      "Software Development\n",
      "San Francisco, California\n",
      "Mistral AI\n",
      "Technology, Information and Internet\n",
      "Paris, France\n",
      "OpenAI\n",
      "Research Services\n",
      "San Francisco, CA\n",
      "LangChain\n",
      "Technology, Information and Internet\n",
      "Generative AI\n",
      "Technology, Information and Internet\n",
      "Google DeepMind\n",
      "Research Services\n",
      "London, London\n",
      "DeepLearning.AI\n",
      "Software Development\n",
      "Palo Alto, California\n",
      "Cohere\n",
      "Software Development\n",
      "Toronto, Ontario\n",
      "LlamaIndex\n",
      "Technology, Information and Internet\n",
      "San Francisco, California\n",
      "Show more similar pages\n",
      "Show fewer similar pages\n",
      "Browse jobs\n",
      "Engineer jobs\n",
      "555,845 open jobs\n",
      "Machine Learning Engineer jobs\n",
      "148,937 open jobs\n",
      "Scientist jobs\n",
      "48,969 open jobs\n",
      "Software Engineer jobs\n",
      "300,699 open jobs\n",
      "Analyst jobs\n",
      "694,057 open jobs\n",
      "Intern jobs\n",
      "71,196 open jobs\n",
      "Developer jobs\n",
      "258,935 open jobs\n",
      "Manager jobs\n",
      "1,880,925 open jobs\n",
      "Product Manager jobs\n",
      "199,941 open jobs\n",
      "Director jobs\n",
      "1,220,357 open jobs\n",
      "Python Developer jobs\n",
      "46,642 open jobs\n",
      "Data Scientist jobs\n",
      "264,158 open jobs\n",
      "Data Analyst jobs\n",
      "329,009 open jobs\n",
      "Senior Software Engineer jobs\n",
      "78,145 open jobs\n",
      "Project Manager jobs\n",
      "253,048 open jobs\n",
      "Researcher jobs\n",
      "195,654 open jobs\n",
      "Associate jobs\n",
      "1,091,945 open jobs\n",
      "Data Engineer jobs\n",
      "192,126 open jobs\n",
      "Vice President jobs\n",
      "235,270 open jobs\n",
      "Specialist jobs\n",
      "768,666 open jobs\n",
      "Show more jobs like this\n",
      "Show fewer jobs like this\n",
      "Funding\n",
      "Hugging Face\n",
      "8 total rounds\n",
      "Last Round\n",
      "Series unknown\n",
      "Sep 1, 2024\n",
      "External Crunchbase Link for last round of funding\n",
      "See more info on\n",
      "crunchbase\n",
      "More searches\n",
      "More searches\n",
      "Engineer jobs\n",
      "Scientist jobs\n",
      "Machine Learning Engineer jobs\n",
      "Software Engineer jobs\n",
      "Intern jobs\n",
      "Developer jobs\n",
      "Analyst jobs\n",
      "Manager jobs\n",
      "Senior Software Engineer jobs\n",
      "Data Scientist jobs\n",
      "Researcher jobs\n",
      "Product Manager jobs\n",
      "Director jobs\n",
      "Associate jobs\n",
      "Intelligence Specialist jobs\n",
      "Data Analyst jobs\n",
      "Data Science Specialist jobs\n",
      "Python Developer jobs\n",
      "Quantitative Analyst jobs\n",
      "Project Manager jobs\n",
      "Account Executive jobs\n",
      "Specialist jobs\n",
      "Data Engineer jobs\n",
      "Designer jobs\n",
      "Quantitative Researcher jobs\n",
      "Consultant jobs\n",
      "Solutions Architect jobs\n",
      "Vice President jobs\n",
      "User Experience Designer jobs\n",
      "Head jobs\n",
      "Full Stack Engineer jobs\n",
      "Engineering Manager jobs\n",
      "Software Engineer Intern jobs\n",
      "Junior Software Engineer jobs\n",
      "Software Intern jobs\n",
      "Product Designer jobs\n",
      "Solutions Engineer jobs\n",
      "Staff Software Engineer jobs\n",
      "Program Manager jobs\n",
      "Senior Scientist jobs\n",
      "Writer jobs\n",
      "Research Intern jobs\n",
      "Senior Product Manager jobs\n",
      "Summer Intern jobs\n",
      "Account Manager jobs\n",
      "Recruiter jobs\n",
      "Lead jobs\n",
      "Research Engineer jobs\n",
      "Computer Science Intern jobs\n",
      "Platform Engineer jobs\n",
      "Junior Developer jobs\n",
      "Android Developer jobs\n",
      "User Experience Researcher jobs\n",
      "Java Software Engineer jobs\n",
      "Site Reliability Engineer jobs\n",
      "Graduate jobs\n",
      "Software Engineering Manager jobs\n",
      "Representative jobs\n",
      "Business Development Specialist jobs\n",
      "Computer Engineer jobs\n",
      "LinkedIn\n",
      "© 2025\n",
      "About\n",
      "Accessibility\n",
      "User Agreement\n",
      "Privacy Policy\n",
      "Cookie Policy\n",
      "Copyright Policy\n",
      "Brand Policy\n",
      "Guest Controls\n",
      "Community Guidelines\n",
      "العربية (Arabic)\n",
      "বাংলা (Bangla)\n",
      "Čeština (Czech)\n",
      "Dansk (Danish)\n",
      "Deutsch (German)\n",
      "Ελληνικά (Greek)\n",
      "English (English)\n",
      "Español (Spanish)\n",
      "فارسی (Persian)\n",
      "Suomi (Finnish)\n",
      "Français (French)\n",
      "हिंदी (Hindi)\n",
      "Magyar (Hungarian)\n",
      "Bahasa Indonesia (Indonesian)\n",
      "Italiano (Italian)\n",
      "עברית (Hebrew)\n",
      "日本語 (Japanese)\n",
      "한국어 (Korean)\n",
      "मराठी (Marathi)\n",
      "Bahasa Malaysia (Malay)\n",
      "Nederlands (Dutch)\n",
      "Norsk (Norwegian)\n",
      "ਪੰਜਾਬੀ (Punjabi)\n",
      "Polski (Polish)\n",
      "Português (Portuguese)\n",
      "Română (Romanian)\n",
      "Русский (Russian)\n",
      "Svenska (Swedish)\n",
      "తెలుగు (Telugu)\n",
      "ภาษาไทย (Thai)\n",
      "Tagalog (Tagalog)\n",
      "Türkçe (Turkish)\n",
      "Українська (Ukrainian)\n",
      "Tiếng Việt (Vietnamese)\n",
      "简体中文 (Chinese (Simplified))\n",
      "正體中文 (Chinese (Traditional))\n",
      "Language\n",
      "Agree & Join LinkedIn\n",
      "By clicking Continue to join or sign in, you agree to LinkedIn’s\n",
      "User Agreement\n",
      ",\n",
      "Privacy Policy\n",
      ", and\n",
      "Cookie Policy\n",
      ".\n",
      "Sign in to see who you already know at Hugging Face\n",
      "Sign in\n",
      "Welcome back\n",
      "Email or phone\n",
      "Password\n",
      "Show\n",
      "Forgot password?\n",
      "Sign in\n",
      "or\n",
      "By clicking Continue to join or sign in, you agree to LinkedIn’s\n",
      "User Agreement\n",
      ",\n",
      "Privacy Policy\n",
      ", and\n",
      "Cookie Policy\n",
      ".\n",
      "New to LinkedIn?\n",
      "Join now\n",
      "or\n",
      "New to LinkedIn?\n",
      "Join now\n",
      "By clicking Continue to join or sign in, you agree to LinkedIn’s\n",
      "User Agreement\n",
      ",\n",
      "Privacy Policy\n",
      ", and\n",
      "Cookie Policy\n",
      ".\n",
      "LinkedIn\n",
      "LinkedIn is better on the app\n",
      "Don’t have the app? Get it in the Microsoft Store.\n",
      "Open the app\n",
      "\n",
      "\n",
      "\n",
      "support page\n",
      "Webpage Title:\n",
      "Hugging Face Forums - Hugging Face Community Discussion\n",
      "Webpage Contents:\n",
      "Hugging Face Forums\n",
      "Topic\n",
      "Replies\n",
      "Views\n",
      "Activity\n",
      "Local LLM and ML platform with RTX 5090 GPU\n",
      "Show and Tell\n",
      "2\n",
      "6\n",
      "August 11, 2025\n",
      "How to fine-tune an LLM model with an entire document in a format such as *.txt/docx/pdf ect\n",
      "🤗AutoTrain\n",
      "7\n",
      "7320\n",
      "August 11, 2025\n",
      "Struggling to Build an AI That Can Detect “Not Good” vs “Good” Environment Photos\n",
      "Beginners\n",
      "0\n",
      "7\n",
      "August 11, 2025\n",
      "Privacy question\n",
      "Spaces\n",
      "2\n",
      "12\n",
      "August 11, 2025\n",
      "Organization Verification Stuck on ‘Pending’\n",
      "Beginners\n",
      "1\n",
      "7\n",
      "August 11, 2025\n",
      "Zero GPU Worker Error\n",
      "Spaces\n",
      "30\n",
      "267\n",
      "August 11, 2025\n",
      "Latest llama.cpp won't build in Spaces\n",
      "Spaces\n",
      "1\n",
      "8\n",
      "August 11, 2025\n",
      "Can't get my uzu model.... got the token but still gated?\n",
      "Models\n",
      "0\n",
      "6\n",
      "August 11, 2025\n",
      "Under 500 MB in storage, but indicates 1 GB\n",
      "Site Feedback\n",
      "1\n",
      "8\n",
      "August 10, 2025\n",
      "Getting this error while trying to access Mistral model using Streamlit\n",
      "Models\n",
      "1\n",
      "9\n",
      "August 11, 2025\n",
      "[Runtime Error] Using Undistro (Wolfi OS) in HF Docker Spaces\n",
      "Spaces\n",
      "1\n",
      "11\n",
      "August 10, 2025\n",
      "ChatGPT 5 An Initial Review\n",
      "Research\n",
      "11\n",
      "169\n",
      "August 10, 2025\n",
      "How to run validation on multiple evaluation datasets simultaneously during Qwen2.5-VL-7B-Instruct fine-tuning?\n",
      "🤗Transformers\n",
      "2\n",
      "15\n",
      "August 10, 2025\n",
      "Error with Doc-Builder in smolagents documentation NotFound[Error]\n",
      "Beginners\n",
      "3\n",
      "16\n",
      "August 10, 2025\n",
      "Looking for Datasets for Session Understanding by LLMs\n",
      "Research\n",
      "1\n",
      "20\n",
      "August 9, 2025\n",
      "Defaulting to the same model - Smolagents\n",
      "Beginners\n",
      "2\n",
      "15\n",
      "August 9, 2025\n",
      "Reward Hacking Solutions\n",
      "Research\n",
      "0\n",
      "18\n",
      "August 9, 2025\n",
      "Need Help in creating ai chatbot for my app\n",
      "Intermediate\n",
      "22\n",
      "119\n",
      "August 8, 2025\n",
      "Feedback on LLM-as-a-Judge design for open-source library\n",
      "Show and Tell\n",
      "0\n",
      "11\n",
      "August 9, 2025\n",
      "Ai conscious base\n",
      "Research\n",
      "20\n",
      "154\n",
      "August 11, 2025\n",
      "Error while initializing ZeroGPU\n",
      "Models\n",
      "13\n",
      "198\n",
      "August 10, 2025\n",
      "LLM Recommendation for unstructured text to json file converrsion?\n",
      "Beginners\n",
      "1\n",
      "29\n",
      "August 8, 2025\n",
      "Process of High Quality Chat Dataset Synthesis\n",
      "Intermediate\n",
      "4\n",
      "25\n",
      "August 8, 2025\n",
      "Could Qwen Be the Best Alternative to Claude Code?\n",
      "Beginners\n",
      "4\n",
      "442\n",
      "August 5, 2025\n",
      "Storage Usage never update?\n",
      "Beginners\n",
      "3\n",
      "11\n",
      "August 9, 2025\n",
      "Can you use PAYG for an entreprise without a Team/Entreprise plan?\n",
      "Beginners\n",
      "6\n",
      "21\n",
      "August 7, 2025\n",
      "ValueError: Image path is None/Invalid Imagedata dictionary\n",
      "Spaces\n",
      "2\n",
      "60\n",
      "August 10, 2025\n",
      "Help Needed: LLM Model for Summarization\n",
      "Beginners\n",
      "2\n",
      "51\n",
      "August 6, 2025\n",
      "Extend codellama\n",
      "Models\n",
      "2\n",
      "14\n",
      "August 9, 2025\n",
      "Rethinking How We Do Research in the Age of AI\n",
      "Intermediate\n",
      "4\n",
      "65\n",
      "August 8, 2025\n",
      "next page →\n",
      "Home\n",
      "Categories\n",
      "Guidelines\n",
      "Terms of Service\n",
      "Privacy Policy\n",
      "Powered by\n",
      "Discourse\n",
      ", best viewed with JavaScript enabled\n",
      "\n",
      "\n",
      "\n",
      "status page\n",
      "Webpage Title:\n",
      "\n",
      "Hugging Face status\n",
      "\n",
      "Webpage Contents:\n",
      "Status\n",
      "Maintenance\n",
      "Previous incidents\n",
      "Get updates\n",
      "Get status updates\n",
      "E-mail\n",
      "RSS\n",
      "JSON\n",
      "Webhook\n",
      "Get e-mail notifications whenever Hugging Face creates, updates or resolves an incident.\n",
      "Subscribe to specific components\n",
      "Current status by service\n",
      "Huggingface Hub\n",
      "Git Hosting and Serving\n",
      "Inference Endpoints\n",
      "Inference Endpoints UI\n",
      "Inference Endpoints API\n",
      "Spaces\n",
      "Spaces Proxy\n",
      "Subscribe\n",
      "Get the RSS feed\n",
      "Get the entire status page as JSON\n",
      "Get a request to your URL whenever Hugging Face creates, updates or resolves an incident.\n",
      "We'll email you with confirmation and when there's an issue with your URL\n",
      "Subscribe to specific components\n",
      "Current status by service\n",
      "Huggingface Hub\n",
      "Git Hosting and Serving\n",
      "Inference Endpoints\n",
      "Inference Endpoints UI\n",
      "Inference Endpoints API\n",
      "Spaces\n",
      "Spaces Proxy\n",
      "Subscribe\n",
      "All services are online\n",
      "Last updated on Aug 11 at 07:53am EDT\n",
      "Current status by service\n",
      "Operational\n",
      "Huggingface Hub\n",
      "99.960% uptime\n",
      "Operational\n",
      "May 14, 2025\n",
      "Operational\n",
      "May 15, 2025\n",
      "Operational\n",
      "May 16, 2025\n",
      "Operational\n",
      "May 17, 2025\n",
      "Operational\n",
      "May 18, 2025\n",
      "Operational\n",
      "May 19, 2025\n",
      "Operational\n",
      "May 20, 2025\n",
      "Operational\n",
      "May 21, 2025\n",
      "Operational\n",
      "May 22, 2025\n",
      "Operational\n",
      "May 23, 2025\n",
      "Operational\n",
      "May 24, 2025\n",
      "Operational\n",
      "May 25, 2025\n",
      "Operational\n",
      "May 26, 2025\n",
      "Operational\n",
      "May 27, 2025\n",
      "Operational\n",
      "May 28, 2025\n",
      "Operational\n",
      "May 29, 2025\n",
      "Operational\n",
      "May 30, 2025\n",
      "Operational\n",
      "May 31, 2025\n",
      "Operational\n",
      "Jun 01, 2025\n",
      "Operational\n",
      "Jun 02, 2025\n",
      "Operational\n",
      "Jun 03, 2025\n",
      "Operational\n",
      "Jun 04, 2025\n",
      "Operational\n",
      "Jun 05, 2025\n",
      "Operational\n",
      "Jun 06, 2025\n",
      "Operational\n",
      "Jun 07, 2025\n",
      "Downtime\n",
      "Down for 4 minutes\n",
      "Jun 08, 2025\n",
      "Operational\n",
      "Jun 09, 2025\n",
      "Operational\n",
      "Jun 10, 2025\n",
      "Operational\n",
      "Jun 11, 2025\n",
      "Operational\n",
      "Jun 12, 2025\n",
      "Operational\n",
      "Jun 13, 2025\n",
      "Downtime\n",
      "Down for 33 minutes\n",
      "Jun 14, 2025\n",
      "Operational\n",
      "Jun 15, 2025\n",
      "Downtime\n",
      "Down for 5 minutes\n",
      "Jun 16, 2025\n",
      "Operational\n",
      "Jun 17, 2025\n",
      "Operational\n",
      "Jun 18, 2025\n",
      "Downtime\n",
      "Down for 4 minutes\n",
      "Jun 19, 2025\n",
      "Operational\n",
      "Jun 20, 2025\n",
      "Operational\n",
      "Jun 21, 2025\n",
      "Operational\n",
      "Jun 22, 2025\n",
      "Operational\n",
      "Jun 23, 2025\n",
      "Downtime\n",
      "Down for 4 minutes\n",
      "Jun 24, 2025\n",
      "Operational\n",
      "Jun 25, 2025\n",
      "Operational\n",
      "Jun 26, 2025\n",
      "Operational\n",
      "Jun 27, 2025\n",
      "Operational\n",
      "Jun 28, 2025\n",
      "Operational\n",
      "Jun 29, 2025\n",
      "Operational\n",
      "Jun 30, 2025\n",
      "Operational\n",
      "Jul 01, 2025\n",
      "Operational\n",
      "Jul 02, 2025\n",
      "Operational\n",
      "Jul 03, 2025\n",
      "Operational\n",
      "Jul 04, 2025\n",
      "Operational\n",
      "Jul 05, 2025\n",
      "Operational\n",
      "Jul 06, 2025\n",
      "Operational\n",
      "Jul 07, 2025\n",
      "Operational\n",
      "Jul 08, 2025\n",
      "Operational\n",
      "Jul 09, 2025\n",
      "Operational\n",
      "Jul 10, 2025\n",
      "Operational\n",
      "Jul 11, 2025\n",
      "Operational\n",
      "Jul 12, 2025\n",
      "Operational\n",
      "Jul 13, 2025\n",
      "Operational\n",
      "Jul 14, 2025\n",
      "Operational\n",
      "Jul 15, 2025\n",
      "Operational\n",
      "Jul 16, 2025\n",
      "Operational\n",
      "Jul 17, 2025\n",
      "Operational\n",
      "Jul 18, 2025\n",
      "Operational\n",
      "Jul 19, 2025\n",
      "Operational\n",
      "Jul 20, 2025\n",
      "Operational\n",
      "Jul 21, 2025\n",
      "Operational\n",
      "Jul 22, 2025\n",
      "Operational\n",
      "Jul 23, 2025\n",
      "Operational\n",
      "Jul 24, 2025\n",
      "Operational\n",
      "Jul 25, 2025\n",
      "Operational\n",
      "Jul 26, 2025\n",
      "Operational\n",
      "Jul 27, 2025\n",
      "Operational\n",
      "Jul 28, 2025\n",
      "Operational\n",
      "Jul 29, 2025\n",
      "Operational\n",
      "Jul 30, 2025\n",
      "Operational\n",
      "Jul 31, 2025\n",
      "Operational\n",
      "Aug 01, 2025\n",
      "Operational\n",
      "Aug 02, 2025\n",
      "Operational\n",
      "Aug 03, 2025\n",
      "Operational\n",
      "Aug 04, 2025\n",
      "Operational\n",
      "Aug 05, 2025\n",
      "Operational\n",
      "Aug 06, 2025\n",
      "Operational\n",
      "Aug 07, 2025\n",
      "Operational\n",
      "Aug 08, 2025\n",
      "Operational\n",
      "Aug 09, 2025\n",
      "Operational\n",
      "Aug 10, 2025\n",
      "Operational\n",
      "Aug 11, 2025\n",
      "30 days ago\n",
      "60 days ago\n",
      "90 days ago\n",
      "Today\n",
      "Git Hosting and Serving\n",
      "99.928% uptime\n",
      "Operational\n",
      "May 14, 2025\n",
      "Operational\n",
      "May 15, 2025\n",
      "Operational\n",
      "May 16, 2025\n",
      "Operational\n",
      "May 17, 2025\n",
      "Operational\n",
      "May 18, 2025\n",
      "Operational\n",
      "May 19, 2025\n",
      "Operational\n",
      "May 20, 2025\n",
      "Operational\n",
      "May 21, 2025\n",
      "Operational\n",
      "May 22, 2025\n",
      "Operational\n",
      "May 23, 2025\n",
      "Operational\n",
      "May 24, 2025\n",
      "Operational\n",
      "May 25, 2025\n",
      "Operational\n",
      "May 26, 2025\n",
      "Operational\n",
      "May 27, 2025\n",
      "Operational\n",
      "May 28, 2025\n",
      "Operational\n",
      "May 29, 2025\n",
      "Operational\n",
      "May 30, 2025\n",
      "Operational\n",
      "May 31, 2025\n",
      "Operational\n",
      "Jun 01, 2025\n",
      "Operational\n",
      "Jun 02, 2025\n",
      "Operational\n",
      "Jun 03, 2025\n",
      "Operational\n",
      "Jun 04, 2025\n",
      "Operational\n",
      "Jun 05, 2025\n",
      "Downtime\n",
      "Down for 6 minutes\n",
      "Jun 06, 2025\n",
      "Operational\n",
      "Jun 07, 2025\n",
      "Downtime\n",
      "Down for 33 minutes\n",
      "Jun 08, 2025\n",
      "Operational\n",
      "Jun 09, 2025\n",
      "Operational\n",
      "Jun 10, 2025\n",
      "Operational\n",
      "Jun 11, 2025\n",
      "Operational\n",
      "Jun 12, 2025\n",
      "Operational\n",
      "Jun 13, 2025\n",
      "Downtime\n",
      "Down for 33 minutes\n",
      "Jun 14, 2025\n",
      "Operational\n",
      "Jun 15, 2025\n",
      "Operational\n",
      "Jun 16, 2025\n",
      "Operational\n",
      "Jun 17, 2025\n",
      "Downtime\n",
      "Down for 4 minutes\n",
      "Jun 18, 2025\n",
      "Operational\n",
      "Jun 19, 2025\n",
      "Operational\n",
      "Jun 20, 2025\n",
      "Operational\n",
      "Jun 21, 2025\n",
      "Operational\n",
      "Jun 22, 2025\n",
      "Operational\n",
      "Jun 23, 2025\n",
      "Downtime\n",
      "Down for 10 minutes\n",
      "Jun 24, 2025\n",
      "Operational\n",
      "Jun 25, 2025\n",
      "Downtime\n",
      "Down for 4 minutes\n",
      "Jun 26, 2025\n",
      "Operational\n",
      "Jun 27, 2025\n",
      "Operational\n",
      "Jun 28, 2025\n",
      "Operational\n",
      "Jun 29, 2025\n",
      "Operational\n",
      "Jun 30, 2025\n",
      "Operational\n",
      "Jul 01, 2025\n",
      "Operational\n",
      "Jul 02, 2025\n",
      "Operational\n",
      "Jul 03, 2025\n",
      "Operational\n",
      "Jul 04, 2025\n",
      "Operational\n",
      "Jul 05, 2025\n",
      "Operational\n",
      "Jul 06, 2025\n",
      "Operational\n",
      "Jul 07, 2025\n",
      "Operational\n",
      "Jul 08, 2025\n",
      "Operational\n",
      "Jul 09, 2025\n",
      "Operational\n",
      "Jul 10, 2025\n",
      "Operational\n",
      "Jul 11, 2025\n",
      "Operational\n",
      "Jul 12, 2025\n",
      "Operational\n",
      "Jul 13, 2025\n",
      "Operational\n",
      "Jul 14, 2025\n",
      "Operational\n",
      "Jul 15, 2025\n",
      "Operational\n",
      "Jul 16, 2025\n",
      "Operational\n",
      "Jul 17, 2025\n",
      "Operational\n",
      "Jul 18, 2025\n",
      "Operational\n",
      "Jul 19, 2025\n",
      "Operational\n",
      "Jul 20, 2025\n",
      "Operational\n",
      "Jul 21, 2025\n",
      "Operational\n",
      "Jul 22, 2025\n",
      "Operational\n",
      "Jul 23, 2025\n",
      "Operational\n",
      "Jul 24, 2025\n",
      "Operational\n",
      "Jul 25, 2025\n",
      "Operational\n",
      "Jul 26, 2025\n",
      "Operational\n",
      "Jul 27, 2025\n",
      "Operational\n",
      "Jul 28, 2025\n",
      "Operational\n",
      "Jul 29, 2025\n",
      "Operational\n",
      "Jul 30, 2025\n",
      "Operational\n",
      "Jul 31, 2025\n",
      "Operational\n",
      "Aug 01, 2025\n",
      "Operational\n",
      "Aug 02, 2025\n",
      "Operational\n",
      "Aug 03, 2025\n",
      "Operational\n",
      "Aug 04, 2025\n",
      "Operational\n",
      "Aug 05, 2025\n",
      "Operational\n",
      "Aug 06, 2025\n",
      "Operational\n",
      "Aug 07, 2025\n",
      "Operational\n",
      "Aug 08, 2025\n",
      "Operational\n",
      "Aug 09, 2025\n",
      "Operational\n",
      "Aug 10, 2025\n",
      "Operational\n",
      "Aug 11, 2025\n",
      "30 days ago\n",
      "60 days ago\n",
      "90 days ago\n",
      "Today\n",
      "Inference Endpoints\n",
      "Operational\n",
      "Inference Endpoints UI\n",
      "99.969% uptime\n",
      "Operational\n",
      "May 14, 2025\n",
      "Operational\n",
      "May 15, 2025\n",
      "Operational\n",
      "May 16, 2025\n",
      "Operational\n",
      "May 17, 2025\n",
      "Operational\n",
      "May 18, 2025\n",
      "Operational\n",
      "May 19, 2025\n",
      "Operational\n",
      "May 20, 2025\n",
      "Operational\n",
      "May 21, 2025\n",
      "Operational\n",
      "May 22, 2025\n",
      "Operational\n",
      "May 23, 2025\n",
      "Operational\n",
      "May 24, 2025\n",
      "Operational\n",
      "May 25, 2025\n",
      "Operational\n",
      "May 26, 2025\n",
      "Operational\n",
      "May 27, 2025\n",
      "Operational\n",
      "May 28, 2025\n",
      "Operational\n",
      "May 29, 2025\n",
      "Operational\n",
      "May 30, 2025\n",
      "Operational\n",
      "May 31, 2025\n",
      "Operational\n",
      "Jun 01, 2025\n",
      "Operational\n",
      "Jun 02, 2025\n",
      "Operational\n",
      "Jun 03, 2025\n",
      "Operational\n",
      "Jun 04, 2025\n",
      "Operational\n",
      "Jun 05, 2025\n",
      "Operational\n",
      "Jun 06, 2025\n",
      "Operational\n",
      "Jun 07, 2025\n",
      "Operational\n",
      "Jun 08, 2025\n",
      "Operational\n",
      "Jun 09, 2025\n",
      "Operational\n",
      "Jun 10, 2025\n",
      "Operational\n",
      "Jun 11, 2025\n",
      "Downtime\n",
      "Down for 19 minutes\n",
      "Jun 12, 2025\n",
      "Operational\n",
      "Jun 13, 2025\n",
      "Operational\n",
      "Jun 14, 2025\n",
      "Operational\n",
      "Jun 15, 2025\n",
      "Operational\n",
      "Jun 16, 2025\n",
      "Operational\n",
      "Jun 17, 2025\n",
      "Operational\n",
      "Jun 18, 2025\n",
      "Operational\n",
      "Jun 19, 2025\n",
      "Downtime\n",
      "Down for 20 minutes\n",
      "Jun 20, 2025\n",
      "Operational\n",
      "Jun 21, 2025\n",
      "Operational\n",
      "Jun 22, 2025\n",
      "Operational\n",
      "Jun 23, 2025\n",
      "Operational\n",
      "Jun 24, 2025\n",
      "Operational\n",
      "Jun 25, 2025\n",
      "Operational\n",
      "Jun 26, 2025\n",
      "Operational\n",
      "Jun 27, 2025\n",
      "Operational\n",
      "Jun 28, 2025\n",
      "Operational\n",
      "Jun 29, 2025\n",
      "Operational\n",
      "Jun 30, 2025\n",
      "Operational\n",
      "Jul 01, 2025\n",
      "Operational\n",
      "Jul 02, 2025\n",
      "Operational\n",
      "Jul 03, 2025\n",
      "Operational\n",
      "Jul 04, 2025\n",
      "Operational\n",
      "Jul 05, 2025\n",
      "Operational\n",
      "Jul 06, 2025\n",
      "Operational\n",
      "Jul 07, 2025\n",
      "Operational\n",
      "Jul 08, 2025\n",
      "Operational\n",
      "Jul 09, 2025\n",
      "Operational\n",
      "Jul 10, 2025\n",
      "Operational\n",
      "Jul 11, 2025\n",
      "Operational\n",
      "Jul 12, 2025\n",
      "Operational\n",
      "Jul 13, 2025\n",
      "Operational\n",
      "Jul 14, 2025\n",
      "Operational\n",
      "Jul 15, 2025\n",
      "Operational\n",
      "Jul 16, 2025\n",
      "Operational\n",
      "Jul 17, 2025\n",
      "Operational\n",
      "Jul 18, 2025\n",
      "Operational\n",
      "Jul 19, 2025\n",
      "Operational\n",
      "Jul 20, 2025\n",
      "Operational\n",
      "Jul 21, 2025\n",
      "Operational\n",
      "Jul 22, 2025\n",
      "Operational\n",
      "Jul 23, 2025\n",
      "Operational\n",
      "Jul 24, 2025\n",
      "Operational\n",
      "Jul 25, 2025\n",
      "Operational\n",
      "Jul 26, 2025\n",
      "Operational\n",
      "Jul 27, 2025\n",
      "Operational\n",
      "Jul 28, 2025\n",
      "Operational\n",
      "Jul 29, 2025\n",
      "Operational\n",
      "Jul 30, 2025\n",
      "Operational\n",
      "Jul 31, 2025\n",
      "Operational\n",
      "Aug 01, 2025\n",
      "Operational\n",
      "Aug 02, 2025\n",
      "Operational\n",
      "Aug 03, 2025\n",
      "Operational\n",
      "Aug 04, 2025\n",
      "Operational\n",
      "Aug 05, 2025\n",
      "Operational\n",
      "Aug 06, 2025\n",
      "Operational\n",
      "Aug 07, 2025\n",
      "Operational\n",
      "Aug 08, 2025\n",
      "Operational\n",
      "Aug 09, 2025\n",
      "Operational\n",
      "Aug 10, 2025\n",
      "Operational\n",
      "Aug 11, 2025\n",
      "30 days ago\n",
      "60 days ago\n",
      "90 days ago\n",
      "Today\n",
      "Inference Endpoints API\n",
      "100.000% uptime\n",
      "Operational\n",
      "May 14, 2025\n",
      "Operational\n",
      "May 15, 2025\n",
      "Operational\n",
      "May 16, 2025\n",
      "Operational\n",
      "May 17, 2025\n",
      "Operational\n",
      "May 18, 2025\n",
      "Operational\n",
      "May 19, 2025\n",
      "Operational\n",
      "May 20, 2025\n",
      "Operational\n",
      "May 21, 2025\n",
      "Operational\n",
      "May 22, 2025\n",
      "Operational\n",
      "May 23, 2025\n",
      "Operational\n",
      "May 24, 2025\n",
      "Operational\n",
      "May 25, 2025\n",
      "Operational\n",
      "May 26, 2025\n",
      "Operational\n",
      "May 27, 2025\n",
      "Operational\n",
      "May 28, 2025\n",
      "Operational\n",
      "May 29, 2025\n",
      "Operational\n",
      "May 30, 2025\n",
      "Operational\n",
      "May 31, 2025\n",
      "Operational\n",
      "Jun 01, 2025\n",
      "Operational\n",
      "Jun 02, 2025\n",
      "Operational\n",
      "Jun 03, 2025\n",
      "Operational\n",
      "Jun 04, 2025\n",
      "Operational\n",
      "Jun 05, 2025\n",
      "Operational\n",
      "Jun 06, 2025\n",
      "Operational\n",
      "Jun 07, 2025\n",
      "Operational\n",
      "Jun 08, 2025\n",
      "Operational\n",
      "Jun 09, 2025\n",
      "Operational\n",
      "Jun 10, 2025\n",
      "Operational\n",
      "Jun 11, 2025\n",
      "Operational\n",
      "Jun 12, 2025\n",
      "Operational\n",
      "Jun 13, 2025\n",
      "Operational\n",
      "Jun 14, 2025\n",
      "Operational\n",
      "Jun 15, 2025\n",
      "Operational\n",
      "Jun 16, 2025\n",
      "Operational\n",
      "Jun 17, 2025\n",
      "Operational\n",
      "Jun 18, 2025\n",
      "Operational\n",
      "Jun 19, 2025\n",
      "Operational\n",
      "Jun 20, 2025\n",
      "Operational\n",
      "Jun 21, 2025\n",
      "Operational\n",
      "Jun 22, 2025\n",
      "Operational\n",
      "Jun 23, 2025\n",
      "Operational\n",
      "Jun 24, 2025\n",
      "Operational\n",
      "Jun 25, 2025\n",
      "Operational\n",
      "Jun 26, 2025\n",
      "Operational\n",
      "Jun 27, 2025\n",
      "Operational\n",
      "Jun 28, 2025\n",
      "Operational\n",
      "Jun 29, 2025\n",
      "Operational\n",
      "Jun 30, 2025\n",
      "Operational\n",
      "Jul 01, 2025\n",
      "Operational\n",
      "Jul 02, 2025\n",
      "Operational\n",
      "Jul 03, 2025\n",
      "Operational\n",
      "Jul 04, 2025\n",
      "Operational\n",
      "Jul 05, 2025\n",
      "Operational\n",
      "Jul 06, 2025\n",
      "Operational\n",
      "Jul 07, 2025\n",
      "Operational\n",
      "Jul 08, 2025\n",
      "Operational\n",
      "Jul 09, 2025\n",
      "Operational\n",
      "Jul 10, 2025\n",
      "Operational\n",
      "Jul 11, 2025\n",
      "Operational\n",
      "Jul 12, 2025\n",
      "Operational\n",
      "Jul 13, 2025\n",
      "Operational\n",
      "Jul 14, 2025\n",
      "Operational\n",
      "Jul 15, 2025\n",
      "Operational\n",
      "Jul 16, 2025\n",
      "Operational\n",
      "Jul 17, 2025\n",
      "Operational\n",
      "Jul 18, 2025\n",
      "Operational\n",
      "Jul 19, 2025\n",
      "Operational\n",
      "Jul 20, 2025\n",
      "Operational\n",
      "Jul 21, 2025\n",
      "Operational\n",
      "Jul 22, 2025\n",
      "Operational\n",
      "Jul 23, 2025\n",
      "Operational\n",
      "Jul 24, 2025\n",
      "Operational\n",
      "Jul 25, 2025\n",
      "Operational\n",
      "Jul 26, 2025\n",
      "Operational\n",
      "Jul 27, 2025\n",
      "Operational\n",
      "Jul 28, 2025\n",
      "Operational\n",
      "Jul 29, 2025\n",
      "Operational\n",
      "Jul 30, 2025\n",
      "Operational\n",
      "Jul 31, 2025\n",
      "Operational\n",
      "Aug 01, 2025\n",
      "Operational\n",
      "Aug 02, 2025\n",
      "Operational\n",
      "Aug 03, 2025\n",
      "Operational\n",
      "Aug 04, 2025\n",
      "Operational\n",
      "Aug 05, 2025\n",
      "Operational\n",
      "Aug 06, 2025\n",
      "Operational\n",
      "Aug 07, 2025\n",
      "Operational\n",
      "Aug 08, 2025\n",
      "Operational\n",
      "Aug 09, 2025\n",
      "Operational\n",
      "Aug 10, 2025\n",
      "Operational\n",
      "Aug 11, 2025\n",
      "30 days ago\n",
      "60 days ago\n",
      "90 days ago\n",
      "Today\n",
      "Spaces\n",
      "Operational\n",
      "Spaces Proxy\n",
      "100.000% uptime\n",
      "Operational\n",
      "May 14, 2025\n",
      "Operational\n",
      "May 15, 2025\n",
      "Operational\n",
      "May 16, 2025\n",
      "Operational\n",
      "May 17, 2025\n",
      "Operational\n",
      "May 18, 2025\n",
      "Operational\n",
      "May 19, 2025\n",
      "Operational\n",
      "May 20, 2025\n",
      "Operational\n",
      "May 21, 2025\n",
      "Operational\n",
      "May 22, 2025\n",
      "Operational\n",
      "May 23, 2025\n",
      "Operational\n",
      "May 24, 2025\n",
      "Operational\n",
      "May 25, 2025\n",
      "Operational\n",
      "May 26, 2025\n",
      "Operational\n",
      "May 27, 2025\n",
      "Operational\n",
      "May 28, 2025\n",
      "Operational\n",
      "May 29, 2025\n",
      "Operational\n",
      "May 30, 2025\n",
      "Operational\n",
      "May 31, 2025\n",
      "Operational\n",
      "Jun 01, 2025\n",
      "Operational\n",
      "Jun 02, 2025\n",
      "Operational\n",
      "Jun 03, 2025\n",
      "Operational\n",
      "Jun 04, 2025\n",
      "Operational\n",
      "Jun 05, 2025\n",
      "Operational\n",
      "Jun 06, 2025\n",
      "Operational\n",
      "Jun 07, 2025\n",
      "Operational\n",
      "Jun 08, 2025\n",
      "Operational\n",
      "Jun 09, 2025\n",
      "Operational\n",
      "Jun 10, 2025\n",
      "Operational\n",
      "Jun 11, 2025\n",
      "Operational\n",
      "Jun 12, 2025\n",
      "Operational\n",
      "Jun 13, 2025\n",
      "Operational\n",
      "Jun 14, 2025\n",
      "Operational\n",
      "Jun 15, 2025\n",
      "Operational\n",
      "Jun 16, 2025\n",
      "Operational\n",
      "Jun 17, 2025\n",
      "Operational\n",
      "Jun 18, 2025\n",
      "Operational\n",
      "Jun 19, 2025\n",
      "Operational\n",
      "Jun 20, 2025\n",
      "Operational\n",
      "Jun 21, 2025\n",
      "Operational\n",
      "Jun 22, 2025\n",
      "Operational\n",
      "Jun 23, 2025\n",
      "Operational\n",
      "Jun 24, 2025\n",
      "Operational\n",
      "Jun 25, 2025\n",
      "Operational\n",
      "Jun 26, 2025\n",
      "Operational\n",
      "Jun 27, 2025\n",
      "Operational\n",
      "Jun 28, 2025\n",
      "Operational\n",
      "Jun 29, 2025\n",
      "Operational\n",
      "Jun 30, 2025\n",
      "Operational\n",
      "Jul 01, 2025\n",
      "Operational\n",
      "Jul 02, 2025\n",
      "Operational\n",
      "Jul 03, 2025\n",
      "Operational\n",
      "Jul 04, 2025\n",
      "Operational\n",
      "Jul 05, 2025\n",
      "Operational\n",
      "Jul 06, 2025\n",
      "Operational\n",
      "Jul 07, 2025\n",
      "Operational\n",
      "Jul 08, 2025\n",
      "Operational\n",
      "Jul 09, 2025\n",
      "Operational\n",
      "Jul 10, 2025\n",
      "Operational\n",
      "Jul 11, 2025\n",
      "Operational\n",
      "Jul 12, 2025\n",
      "Operational\n",
      "Jul 13, 2025\n",
      "Operational\n",
      "Jul 14, 2025\n",
      "Operational\n",
      "Jul 15, 2025\n",
      "Operational\n",
      "Jul 16, 2025\n",
      "Operational\n",
      "Jul 17, 2025\n",
      "Operational\n",
      "Jul 18, 2025\n",
      "Operational\n",
      "Jul 19, 2025\n",
      "Operational\n",
      "Jul 20, 2025\n",
      "Operational\n",
      "Jul 21, 2025\n",
      "Operational\n",
      "Jul 22, 2025\n",
      "Operational\n",
      "Jul 23, 2025\n",
      "Operational\n",
      "Jul 24, 2025\n",
      "Operational\n",
      "Jul 25, 2025\n",
      "Operational\n",
      "Jul 26, 2025\n",
      "Operational\n",
      "Jul 27, 2025\n",
      "Operational\n",
      "Jul 28, 2025\n",
      "Operational\n",
      "Jul 29, 2025\n",
      "Operational\n",
      "Jul 30, 2025\n",
      "Operational\n",
      "Jul 31, 2025\n",
      "Operational\n",
      "Aug 01, 2025\n",
      "Operational\n",
      "Aug 02, 2025\n",
      "Operational\n",
      "Aug 03, 2025\n",
      "Operational\n",
      "Aug 04, 2025\n",
      "Operational\n",
      "Aug 05, 2025\n",
      "Operational\n",
      "Aug 06, 2025\n",
      "Operational\n",
      "Aug 07, 2025\n",
      "Operational\n",
      "Aug 08, 2025\n",
      "Operational\n",
      "Aug 09, 2025\n",
      "Operational\n",
      "Aug 10, 2025\n",
      "Operational\n",
      "Aug 11, 2025\n",
      "30 days ago\n",
      "60 days ago\n",
      "90 days ago\n",
      "Today\n",
      "Powered by\n",
      "Better Stack\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(get_all_details(\"https://huggingface.co\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9b863a55-f86c-4e3f-8a79-94e24c1a8cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# system_prompt = \"You are an assistant that analyzes the contents of several relevant pages from a company website \\\n",
    "# and creates a short brochure about the company for prospective customers, investors and recruits. Respond in markdown.\\\n",
    "# Include details of company culture, customers and careers/jobs if you have the information.\"\n",
    "\n",
    "system_prompt = \"You are an assistant that analyzes the contents of several relevant pages from a company website \\\n",
    "and creates a short brochure about the company for prospective customers, investors and recruits. You are recruiting Korean workers, so \\\n",
    "you have to make brochure which are written by Korean. Respond in markdown.\\\n",
    "Include details of company culture, customers and careers/jobs if you have the information.\"\n",
    "\n",
    "# 한국어 브로셔로 변경한 프롬프트\n",
    "\n",
    "# Or uncomment the lines below for a more humorous brochure - this demonstrates how easy it is to incorporate 'tone':\n",
    "\n",
    "# system_prompt = \"You are an assistant that analyzes the contents of several relevant pages from a company website \\\n",
    "# and creates a short humorous, entertaining, jokey brochure about the company for prospective customers, investors and recruits. Respond in markdown.\\\n",
    "# Include details of company culture, customers and careers/jobs if you have the information.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6ab83d92-d36b-4ce0-8bcc-5bb4c2f8ff23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_brochure_user_prompt(company_name, url):\n",
    "    user_prompt = f\"You are looking at a company called: {company_name}\\n\"\n",
    "    user_prompt += f\"Here are the contents of its landing page and other relevant pages; use this information to build a short brochure of the company in markdown.\\n\"\n",
    "    user_prompt += get_all_details(url)  # 메인페이지+ 관련 페이지까지 다 1개로 합친 거 \n",
    "    user_prompt = user_prompt[:5_000] # Truncate if more than 5,000 characters\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cd909e0b-1312-4ce2-a553-821e795d7572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found links: {'links': [{'type': 'about page', 'url': 'https://huggingface.co/about'}, {'type': 'careers page', 'url': 'https://apply.workable.com/huggingface/'}, {'type': 'company page', 'url': 'https://huggingface.co/enterprise'}, {'type': 'blog', 'url': 'https://huggingface.co/blog'}, {'type': 'docs page', 'url': 'https://huggingface.co/docs'}, {'type': 'community page', 'url': 'https://discuss.huggingface.co'}, {'type': 'Github', 'url': 'https://github.com/huggingface'}, {'type': 'LinkedIn', 'url': 'https://www.linkedin.com/company/huggingface/'}, {'type': 'Twitter', 'url': 'https://twitter.com/huggingface'}]}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"You are looking at a company called: HuggingFace\\nHere are the contents of its landing page and other relevant pages; use this information to build a short brochure of the company in markdown.\\nLanding page:\\nWebpage Title:\\nHugging Face – The AI community building the future.\\nWebpage Contents:\\nHugging Face\\nModels\\nDatasets\\nSpaces\\nCommunity\\nDocs\\nEnterprise\\nPricing\\nLog In\\nSign Up\\nThe AI community building the future.\\nThe platform where the machine learning community collaborates on models, datasets, and applications.\\nExplore AI Apps\\nor\\nBrowse 1M+ models\\nTrending on\\nthis week\\nModels\\nopenai/gpt-oss-120b\\nUpdated\\n3 days ago\\n•\\n429k\\n•\\n3.16k\\nopenai/gpt-oss-20b\\nUpdated\\n3 days ago\\n•\\n2M\\n•\\n2.73k\\nQwen/Qwen-Image\\nUpdated\\n5 days ago\\n•\\n62.8k\\n•\\n1.43k\\ntencent/Hunyuan-1.8B-Instruct\\nUpdated\\n5 days ago\\n•\\n3.1k\\n•\\n573\\nrednote-hilab/dots.ocr\\nUpdated\\n4 days ago\\n•\\n16.2k\\n•\\n563\\nBrowse 1M+ models\\nSpaces\\nRunning\\non\\nZero\\n415\\n415\\nQwen Image\\n🖼\\nGenerate images from text prompts\\nRunning\\n11.7k\\n11.7k\\nDeepSite v2\\n🐳\\nGenerate any application with DeepSeek\\nRunning\\non\\nZero\\n264\\n264\\nFLUX.1 Krea Dev\\n📚\\nGenerate images from text prompts\\nRunning\\non\\nZero\\nMCP\\n282\\n282\\nWan 2.2 5B\\n🚀\\nGenerate high-quality videos from text prompts and images\\nRunning\\non\\nZero\\n120\\n120\\nOmniAvatar\\n🐨\\nGenerate podcast and tiktok style video avatars\\nBrowse 400k+ applications\\nDatasets\\nfka/awesome-chatgpt-prompts\\nUpdated\\nJan 6\\n•\\n32.4k\\n•\\n8.65k\\njxm/gpt-oss20b-samples\\nUpdated\\n3 days ago\\n•\\n1.03k\\n•\\n55\\nHuggingFaceH4/Multilingual-Thinking\\nUpdated\\n4 days ago\\n•\\n6.15k\\n•\\n44\\nopenai/BrowseCompLongContext\\nUpdated\\n2 days ago\\n•\\n568\\n•\\n30\\nnvidia/Nemotron-Post-Training-Dataset-v1\\nUpdated\\n10 days ago\\n•\\n15.9k\\n•\\n103\\nBrowse 250k+ datasets\\nThe Home of Machine Learning\\nCreate, discover and collaborate on ML better.\\nThe collaboration platform\\nHost and collaborate on unlimited public models, datasets and applications.\\nMove faster\\nWith the HF Open source stack.\\nExplore all modalities\\nText, image, video, audio or even 3D.\\nBuild your portfolio\\nShare your work with the world and build your ML profile.\\nSign Up\\nAccelerate your ML\\nWe provide paid Compute and Enterprise solutions.\\nCompute\\nDeploy on optimized\\nInference Endpoints\\nor update your\\nSpaces applications\\nto a GPU in a few clicks.\\nView pricing\\nStarting at $0.60/hour for GPU\\nTeam & Enterprise\\nGive your team the most advanced platform to build AI with enterprise-grade security, access controls and\\n\\t\\t\\tdedicated support.\\nGetting started\\nStarting at $20/user/month\\nSingle Sign-On\\nRegions\\nPriority Support\\nAudit Logs\\nResource Groups\\nPrivate Datasets Viewer\\nMore than 50,000 organizations are using Hugging Face\\nAi2\\nEnterprise\\nnon-profit\\n•\\n776 models\\n•\\n3.78k followers\\nAI at Meta\\nEnterprise\\ncompany\\n•\\n2.2k models\\n•\\n7.11k followers\\nAmazon\\ncompany\\n•\\n20 models\\n•\\n3.35k followers\\nGoogle\\nEnterprise\\ncompany\\n•\\n1.04k models\\n•\\n23.9k followers\\nIntel\\ncompany\\n•\\n239 models\\n•\\n2.86k followers\\nMicrosoft\\ncompany\\n•\\n419 models\\n•\\n14.1k followers\\nGrammarly\\nTeam\\ncompany\\n•\\n10 models\\n•\\n171 followers\\nWriter\\nEnterprise\\ncompany\\n•\\n21 models\\n•\\n318 followers\\nOur Open Source\\nWe are building the foundation of ML tooling with the community.\\nTransformers\\n148,174\\nState-of-the-art AI models for PyTorch\\nDiffusers\\n30,205\\nState-of-the-art Diffusion models in PyTorch\\nSafetensors\\n3,392\\nSafe way to store/distribute neural network weights\\nHub Python Library\\n2,831\\nPython client to interact with the Hugging Face Hub\\nTokenizers\\n9,978\\nFast tokenizers optimized for research & production\\nTRL\\n15,028\\nTrain transformers LMs with reinforcement learning\\nTransformers.js\\n14,316\\nState-of-the-art ML running directly in your browser\\nsmolagents\\n21,995\\nSmol library to build great agents in Python\\nPEFT\\n19,281\\nParameter-efficient finetuning for large language models\\nDatasets\\n20,484\\nAccess & share datasets for any ML tasks\\nText Generation Inference\\n10,412\\nServe language models with TGI optimized toolkit\\nAccelerate\\n9,021\\nTrain PyTorch models with multi-GPU, TPU, mixed precision\\nSystem theme\\nWebsite\\nModels\\nDatasets\\nSpaces\\nChangelog\\nInference Endpoints\\nHuggingChat\\nCompany\\nAbout\\nBrand assets\\nTerms of service\\nPrivacy\\nJobs\\nPress\\nResources\\nLearn\\nDocumentation\\nBlog\\nForum\\nService Status\\nSocial\\nGitHub\\nTwitter\\nLinkedIn\\nDiscord\\n\\n\\n\\nabout page\\nWebpage Title:\\nabout (Sergei)\\nWebpage Contents:\\nHugging Face\\nModels\\nDatasets\\nSpaces\\nCommunity\\nDocs\\nEnterprise\\nPricing\\nLog In\\nSign Up\\nSergei\\nabout\\nFollow\\njondelamothe's profile picture\\nRenumathi's profile picture\\nKalaipriya's profile picture\\n5\\n\\t\\t\\t\\t\\tfollowers\\n·\\n0 following\\nAI & ML interests\\nNone yet\\nOrganizations\\nNone yet\\nmodels\\n0\\nNone public yet\\ndatasets\\n0\\nNone public yet\\nSystem theme\\nCompany\\nTOS\\nPrivacy\\nAbout\\nJobs\\nWebsite\\nModels\\nDatasets\\nSpaces\\nPricing\\nDocs\\n\\n\\n\\ncareers page\\nWebpage Title:\\nHugging Face - Current Openings\\nWebpage Contents:\\n\\n\\n\\n\\ncompany page\\nWebpage Title:\\nEnterprise Hub - Hugging Face\\nWebpage Contents:\\nHugging Face\\nModels\\nDatasets\\nSpaces\\nCommunity\\nDocs\\nEnterprise\\nPricing\\nLog In\\nSign Up\\nTeam & Enterprise Hub\\nScale your organization with the world’s leading AI platform\\nSubscribe to\\nTeam\\nstarting at $20/user/mon\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_brochure_user_prompt(\"HuggingFace\", \"https://huggingface.co\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e44de579-4a1a-4e6a-a510-20ea3e4b8d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_brochure(company_name, url):\n",
    "    response = openai.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": get_brochure_user_prompt(company_name, url)}\n",
    "          ],\n",
    "    )\n",
    "    result = response.choices[0].message.content\n",
    "    display(Markdown(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e093444a-9407-42ae-924a-145730591a39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found links: {'links': [{'type': 'about page', 'url': 'https://huggingface.co/huggingface'}, {'type': 'careers page', 'url': 'https://apply.workable.com/huggingface/'}, {'type': 'blog', 'url': 'https://huggingface.co/blog'}, {'type': 'company page', 'url': 'https://huggingface.co/enterprise'}, {'type': 'pricing page', 'url': 'https://huggingface.co/pricing'}, {'type': 'community page', 'url': 'https://discuss.huggingface.co'}, {'type': 'GitHub page', 'url': 'https://github.com/huggingface'}, {'type': 'Twitter page', 'url': 'https://twitter.com/huggingface'}, {'type': 'LinkedIn page', 'url': 'https://www.linkedin.com/company/huggingface/'}]}\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "```markdown\n",
       "# Hugging Face: The AI Community Building the Future\n",
       "\n",
       "Welcome to Hugging Face, a pioneering platform that empowers the machine learning community through collaboration, innovation, and shared resources. Our mission is to accelerate the development of AI technologies and democratize access to machine learning tools for everyone.\n",
       "\n",
       "## What We Offer\n",
       "\n",
       "- **Models**: Access over 1 million machine learning models, including cutting-edge architectures like GPT, diffusion models, and more.\n",
       "  \n",
       "- **Datasets**: Explore a vast library of over 250,000 datasets tailored for various machine learning tasks.\n",
       "\n",
       "- **Spaces**: Utilize our user-friendly interface to create and share applications, allowing for seamless collaboration and innovation.\n",
       "\n",
       "- **Enterprise Solutions**: We provide tailored enterprise-grade services, ensuring security, access control, and dedicated support for organizations looking to harness the power of AI.\n",
       "\n",
       "## Our Community\n",
       "\n",
       "Hugging Face is not just a platform, but a vibrant community of over 50,000 organizations and many active users. Major companies like Google, Amazon, Microsoft, and Grammarly utilize our tools and models, demonstrating our commitment to serving both individual developers and large enterprises.\n",
       "\n",
       "### Collaboration at Our Core\n",
       "\n",
       "We believe in the power of community and open-source. Our projects like Transformer models, Diffusers, and Tokenizers are designed for collaborative building and sharing, creating a robust ecosystem for machine learning developers.\n",
       "\n",
       "## Company Culture\n",
       "\n",
       "At Hugging Face, we foster a culture of inclusivity, innovation, and continuous improvement. We encourage our team members to explore new ideas, collaborate across functions, and contribute to an open-source community that thrives on shared knowledge.\n",
       "\n",
       "- **Team Size**: Currently featuring over 211 dedicated professionals passionate about AI and machine learning.\n",
       "  \n",
       "- **Work Environment**: We promote flexibility, creativity, and a consultancy-like atmosphere where every team member's input is valued.\n",
       "\n",
       "## Careers at Hugging Face\n",
       "\n",
       "Join a team that is shaping the future of AI! We are always on the lookout for talented individuals who are excited about contributing to impactful projects. \n",
       "\n",
       "### Positions Available:\n",
       "- Machine Learning Engineers\n",
       "- Data Scientists\n",
       "- Software Developers\n",
       "- Community Managers\n",
       "- Product Designers\n",
       "\n",
       "Explore opportunities on our [Careers Page](https://huggingface.co/jobs) and find out how you can become part of the Hugging Face family.\n",
       "\n",
       "## Getting Started\n",
       "\n",
       "Whether you’re an AI enthusiast, developer, or someone looking for robust machine learning solutions, Hugging Face is the place to be. \n",
       "\n",
       "- **Explore AI Apps**: Dive deep into our extensive application ecosystem.\n",
       "- **Sign Up**: Create an account to start building or collaborating on models and datasets.\n",
       "\n",
       "**Hugging Face** - Building the AI community of the future, together.\n",
       "\n",
       "🔗 [Visit Our Website](https://huggingface.co)  \n",
       "🔗 [Join Us on GitHub](https://github.com/huggingface)  \n",
       "🔗 [Follow Us on Twitter](https://twitter.com/huggingface)  \n",
       "🔗 [Connect with Us on LinkedIn](https://linkedin.com/company/huggingface/)  \n",
       "```\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "create_brochure(\"HuggingFace\", \"https://huggingface.co\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61eaaab7-0b47-4b29-82d4-75d474ad8d18",
   "metadata": {},
   "source": [
    "## Finally - a minor improvement\n",
    "\n",
    "With a small adjustment, we can change this so that the results stream back from OpenAI,\n",
    "with the familiar typewriter animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "51db0e49-f261-4137-aabe-92dd601f7725",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_brochure(company_name, url):\n",
    "    stream = openai.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": get_brochure_user_prompt(company_name, url)}\n",
    "          ],\n",
    "        stream=True\n",
    "    )\n",
    "    \n",
    "    response = \"\"\n",
    "    display_handle = display(Markdown(\"\"), display_id=True)\n",
    "    for chunk in stream:\n",
    "        response += chunk.choices[0].delta.content or ''\n",
    "        response = response.replace(\"```\",\"\").replace(\"markdown\", \"\")\n",
    "        update_display(Markdown(response), display_id=display_handle.display_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e2b31b-a6bb-48d4-a171-e92da43d9018",
   "metadata": {},
   "outputs": [],
   "source": [
    "이 함수 stream_brochure()는 OpenAI API의 스트리밍 모드를 사용해서, 회사 브로셔 내용을 실시간으로 화면에 출력하는 기능이에요.\n",
    "단계별로 풀어보면 이렇게 됩니다.\n",
    "\n",
    "1. 함수 정의\n",
    "python\n",
    "코드 복사\n",
    "def stream_brochure(company_name, url):\n",
    "매개변수\n",
    "\n",
    "company_name: 회사 이름 (예: \"OpenAI\")\n",
    "\n",
    "url: 해당 회사 웹사이트 주소 (예: \"https://openai.com\")\n",
    "\n",
    "2. GPT 호출 준비 (스트리밍 모드)\n",
    "python\n",
    "코드 복사\n",
    "stream = openai.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": get_brochure_user_prompt(company_name, url)}\n",
    "      ],\n",
    "    stream=True\n",
    ")\n",
    "model=MODEL : 사용할 모델 이름(예: \"gpt-4o-mini\").\n",
    "\n",
    "messages : 챗봇 대화 맥락\n",
    "\n",
    "첫 번째 메시지 (system) → 전체적인 역할·규칙을 설명하는 시스템 프롬프트\n",
    "\n",
    "두 번째 메시지 (user) → get_brochure_user_prompt()로 만든 사용자 요청(브로셔 작성 지시문)\n",
    "\n",
    "stream=True : 모델이 한 번에 전부 응답하는 게 아니라 조각(chunk) 단위로 실시간 전송하도록 함.\n",
    "\n",
    "3. 초기 화면 출력 준비\n",
    "python\n",
    "코드 복사\n",
    "response = \"\"\n",
    "display_handle = display(Markdown(\"\"), display_id=True)\n",
    "response : 지금까지 받은 텍스트를 누적할 변수.\n",
    "\n",
    "display_handle : 화면에 마크다운 형태로 표시할 수 있는 영역을 생성(예: Jupyter Notebook 환경).\n",
    "\n",
    "4. 스트리밍 응답 처리\n",
    "python\n",
    "코드 복사\n",
    "for chunk in stream:\n",
    "    response += chunk.choices[0].delta.content or ''\n",
    "    response = response.replace(\"```\",\"\").replace(\"markdown\", \"\")\n",
    "    update_display(Markdown(response), display_id=display_handle.display_id)\n",
    "for chunk in stream → GPT가 보내주는 **조각(chunk)**을 하나씩 받음.\n",
    "\n",
    "chunk.choices[0].delta.content → 이 조각의 새로 생성된 텍스트 부분\n",
    "(or ''는 None 방지)\n",
    "\n",
    "response += ... → 전체 응답에 새 텍스트 누적.\n",
    "\n",
    ".replace(\"```\",\"\").replace(\"markdown\", \"\") → 마크다운 코드 블록 표식 제거.\n",
    "\n",
    "update_display(...) → 화면을 실시간으로 갱신해서, 지금까지 받은 내용 보여줌.\n",
    "\n",
    "💡 쉽게 말하면\n",
    "\n",
    "stream=True 덕분에 GPT가 “답변 다 썼습니다” 하고 기다리는 게 아니라,\n",
    "쓰자마자 바로바로 화면에 반영할 수 있는 거예요.\n",
    "\n",
    "마치 실시간 자막처럼 브로셔 내용을 타이핑하듯 표시하는 거죠.\n",
    "\n",
    "📌 흐름 요약\n",
    "\n",
    "GPT 모델에 “이 회사에 대한 브로셔 써줘” 요청 보냄 (스트리밍 모드)\n",
    "\n",
    "모델이 한 문장씩 보내주면 즉시 누적\n",
    "\n",
    "화면을 계속 갱신해서 실시간으로 내용 표시\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92cbba82-2088-4884-a1d2-900d8352019d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "56bf0ae3-ee9d-4a72-9cd6-edcac67ceb6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found links: {'links': [{'type': 'about page', 'url': 'https://huggingface.co/about'}, {'type': 'careers page', 'url': 'https://apply.workable.com/huggingface/'}, {'type': 'company page', 'url': 'https://huggingface.co/enterprise'}, {'type': 'press page', 'url': 'https://huggingface.co/blog'}]}\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "# Hugging Face 소개 브로셔\n",
       "\n",
       "## 회사 개요\n",
       "Hugging Face는 인공지능(AI) 커뮤니티가 미래를 함께 구축하는 플랫폼입니다. 우리는 기계 학습(ML) 커뮤니티가 모델, 데이터 세트 및 애플리케이션에 협업할 수 있도록 도와줍니다. Hugging Face는 전 세계 5만 개 이상의 조직에서 사용되고 있으며, 기업급 보안과 전용 지원을 통해 ML 솔루션을 제공하고 있습니다.\n",
       "\n",
       "## 회사 문화\n",
       "Hugging Face는 협력과 혁신을 중시하는 문화가 특징입니다. 우리는 오픈 소스 정신을 통해 커뮤니티와 함께 발전하며, 누구나 쉽게 기여할 수 있는 환경을 만듭니다. 다양성과 포용성을 강조하여, 소외되지 않는 AI 생태계를 조성하는 데 힘쓰고 있습니다.\n",
       "\n",
       "## 고객\n",
       "우리는 **Meta**, **Amazon**, **Google**, **Microsoft** 등 여러 글로벌 기업과 협력하고 있습니다. 또한, 다양한 비영리 기관 및 스타트업과 함께 일하며, 그들의 AI 프로젝트를 지원합니다.\n",
       "\n",
       "## 경력 기회\n",
       "Hugging Face에서는 다음과 같은 다양한 직무를 제공합니다:\n",
       "- 기계 학습 엔지니어\n",
       "- 데이터 과학자\n",
       "- 소프트웨어 개발자\n",
       "- 고객 지원 전문인\n",
       "\n",
       "우리는 모든 기술 수준과 경험을 가진 지원자를 환영합니다! 함께 AI의 미래를 만들어갈 인재를 찾고 있습니다.\n",
       "\n",
       "## 우리가 제공하는 것\n",
       "- **모델 및 데이터 세트의 광범위한 라이브러리**: 100만 개 이상의 모델과 25만 개 이상의 데이터 세트에 접근할 수 있습니다.\n",
       "- **ML 포트폴리오 구축**: 여러분의 작업을 세계와 공유하세요.\n",
       "- **전문 지원 및 독점 도구**: 팀과 기업을 위한 고급 플랫폼을 제공하며, 안전하고 효율적인 AI 개발을 지원합니다.\n",
       "\n",
       "저희와 함께 AI의 미래를 창조해 보세요! 더 자세한 사항은 [Hugging Face 웹사이트](https://huggingface.co) 를 방문해 주시기 바랍니다.\n",
       "\n",
       "## 연락처\n",
       "Hugging Face에 대한 더 많은 정보와 경력에 대한 문의는 아래의 링크를 통해 가능합니다.\n",
       "- [채용 정보](https://huggingface.co/jobs)\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stream_brochure(\"HuggingFace\", \"https://huggingface.co\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fdb3f8d8-a3eb-41c8-b1aa-9f60686a653b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found links: {'links': [{'type': 'about page', 'url': 'https://huggingface.co'}, {'type': 'enterprise page', 'url': 'https://huggingface.co/enterprise'}, {'type': 'pricing page', 'url': 'https://huggingface.co/pricing'}, {'type': 'careers page', 'url': 'https://apply.workable.com/huggingface/'}, {'type': 'blog page', 'url': 'https://huggingface.co/blog'}, {'type': 'discussion forum', 'url': 'https://discuss.huggingface.co'}, {'type': 'GitHub page', 'url': 'https://github.com/huggingface'}, {'type': 'Twitter page', 'url': 'https://twitter.com/huggingface'}, {'type': 'LinkedIn page', 'url': 'https://www.linkedin.com/company/huggingface/'}]}\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "# Hugging Face 브로셔\n",
       "\n",
       "## AI 커뮤니티의 미래를 함께합니다.\n",
       "\n",
       "Hugging Face는 기계 학습 커뮤니티를 위한 플랫폼으로, 모델, 데이터셋, 응용 프로그램을 협력하여 개발하는 공간입니다. 우리는 누구나 AI 기술에 기여하고 공유할 수 있는 열린 환경을 제공합니다.\n",
       "\n",
       "## 우리의 자랑스러운 제공안\n",
       "\n",
       "- **모델**: 100만 개 이상의 최신 AI 모델에 접근하고 탐색하세요.\n",
       "- **데이터셋**: 25만 개 이상의 공공 데이터셋으로 기계 학습 작업을 지원합니다.\n",
       "- **Spaces**: AI 애플리케이션을 생성하고 공유하는데 최적화된 공간입니다.\n",
       "\n",
       "## 고객과의 협력\n",
       "\n",
       "Hugging Face는 Amazon, Google, Microsoft 등 50,000개 이상의 조직과 협력하고 있으며, 비영리 기업들도 우리 플랫폼을 통해 혁신을 이루고 있습니다. 우리의 성공적인 고객들은 다양한 산업에 걸쳐 있으며, 그들의 필요에 맞춘 AI 솔루션을 제공합니다.\n",
       "\n",
       "## 포괄적인 회사 문화\n",
       "\n",
       "Hugging Face에서의 근무는 굉장히 협력적이고 혁신적입니다. 우리는 여러 백그라운드를 가진 인재들이 자유롭게 의견을 교환하고, 아이디어를 실현할 수 있는 환경을 조성합니다. 각 팀원은 자신의 의견이 존중받고, 혁신적인 프로젝트에 참여할 기회를 가집니다.\n",
       "\n",
       "## 경력 및 채용 정보\n",
       "\n",
       "우리는 지속적인 성장을 위해 새로운 인재를 찾고 있습니다. 다양한 직무가 있으며, 모두가 AI의 미래를 함께 만들어가는 여정에 동참할 수 있습니다. 특히 한국어를 구사하는 인재를 우대하며, 다국적 팀에서 경험을 쌓을 수 있는 기회를 제공합니다.\n",
       "\n",
       "## 함께 미래를 만들어 갑니다\n",
       "\n",
       "Hugging Face는 현대 AI 기술의 최전선에서 활동하고 있으며, 여러분의 참여를 통해 더 나은 AI 생태계를 만들고자 합니다. 관심이 있으신 분들은 [신청하기](https://huggingface.co/join) 버튼을 통해 지원해 주시기 바랍니다!\n",
       "\n",
       "---\n",
       "\n",
       "**연락처 정보**  \n",
       "- 웹사이트: [Hugging Face](https://huggingface.co)  \n",
       "- 이메일: info@huggingface.co  \n",
       "- 소셜 미디어: [Twitter](https://twitter.com/huggingface) | [LinkedIn](https://linkedin.com/company/huggingface)\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Try changing the system prompt to the humorous version when you make the Brochure for Hugging Face:\n",
    "\n",
    "stream_brochure(\"HuggingFace\", \"https://huggingface.co\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27bf9e0-665f-4645-b66b-9725e2a959b5",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../business.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#181;\">Business applications</h2>\n",
    "            <span style=\"color:#181;\">In this exercise we extended the Day 1 code to make multiple LLM calls, and generate a document.\n",
    "\n",
    "This is perhaps the first example of Agentic AI design patterns, as we combined multiple calls to LLMs. This will feature more in Week 2, and then we will return to Agentic AI in a big way in Week 8 when we build a fully autonomous Agent solution.\n",
    "\n",
    "Generating content in this way is one of the very most common Use Cases. As with summarization, this can be applied to any business vertical. Write marketing content, generate a product tutorial from a spec, create personalized email content, and so much more. Explore how you can apply content generation to your business, and try making yourself a proof-of-concept prototype. See what other students have done in the community-contributions folder -- so many valuable projects -- it's wild!</span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b2454b-8ef8-4b5c-b928-053a15e0d553",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../important.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#900;\">Before you move to Week 2 (which is tons of fun)</h2>\n",
    "            <span style=\"color:#900;\">Please see the week1 EXERCISE notebook for your challenge for the end of week 1. This will give you some essential practice working with Frontier APIs, and prepare you well for Week 2.</span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b64f0f-7d33-4493-985a-033d06e8db08",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../resources.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#f71;\">A reminder on 3 useful resources</h2>\n",
    "            <span style=\"color:#f71;\">1. The resources for the course are available <a href=\"https://edwarddonner.com/2024/11/13/llm-engineering-resources/\">here.</a><br/>\n",
    "            2. I'm on LinkedIn <a href=\"https://www.linkedin.com/in/eddonner/\">here</a> and I love connecting with people taking the course!<br/>\n",
    "            3. I'm trying out X/Twitter and I'm at <a href=\"https://x.com/edwarddonner\">@edwarddonner<a> and hoping people will teach me how it's done..  \n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f48e42e-fa7a-495f-a5d4-26bfc24d60b6",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../thankyou.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#090;\">Finally! I have a special request for you</h2>\n",
    "            <span style=\"color:#090;\">\n",
    "                My editor tells me that it makes a MASSIVE difference when students rate this course on Udemy - it's one of the main ways that Udemy decides whether to show it to others. If you're able to take a minute to rate this, I'd be so very grateful! And regardless - always please reach out to me at ed@edwarddonner.com if I can help at any point.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d3e1a1-ba54-4907-97c5-30f89a24775b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
