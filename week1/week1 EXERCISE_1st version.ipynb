{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe12c203-e6a6-452c-a655-afb8a03a4ff5",
   "metadata": {},
   "source": [
    "# End of week 1 exercise\n",
    "\n",
    "To demonstrate your familiarity with OpenAI API, and also Ollama, build a tool that takes a technical question,  \n",
    "and responds with an explanation. This is a tool that you will be able to use yourself during the course!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1070317-3ed9-4659-abe3-828943230e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "from typing import List\n",
    "from dotenv import load_dotenv\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display, update_display\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a456906-915a-4bfd-bb9d-57e505c5093f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "\n",
    "MODEL_GPT = 'gpt-4o-mini'\n",
    "MODEL_LLAMA = 'llama3.2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8d7923c-5f28-4c30-8556-342d7c8497c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key found and looks good so far!\n"
     ]
    }
   ],
   "source": [
    "# set up environment\n",
    "# Load environment variables in a file called .env\n",
    "\n",
    "load_dotenv(override=True)      # env 파일로드\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# Check the key\n",
    "\n",
    "if not api_key:\n",
    "    print(\"No API key was found - please head over to the troubleshooting notebook in this folder to identify & fix!\")\n",
    "elif not api_key.startswith(\"sk-proj-\"):\n",
    "    print(\"An API key was found, but it doesn't start sk-proj-; please check you're using the right key - see troubleshooting notebook\")\n",
    "elif api_key.strip() != api_key:\n",
    "    print(\"An API key was found, but it looks like it might have space or tab characters at the start or end - please remove them - see troubleshooting notebook\")\n",
    "else:\n",
    "    print(\"API key found and looks good so far!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e590c759-f56e-4c2c-85be-1e7db5989375",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai = OpenAI()   # 인스턴스 생성해서 넣기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac8404d8-ff72-4894-b45f-6b5bc58e537f",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"you are a assistant which specializes in coding. \\\n",
    "You have to explain code to south korea people.\\ try to explain code as korean and easy word \\\n",
    "to who are not major in computer science. Respond in markdown.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f0d0137-52b0-47a8-81a8-11a90a010798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here is the question; type over this to ask something new\n",
    "\n",
    "user_prompt = \"\"\"\n",
    "Please explain what this code does and why:\n",
    "yield from {book.get(\"author\") for book in books if book.get(\"author\")}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca3dbee-fc9b-4a3a-834c-fb7cad011d05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fab0dc13-cbb8-4e89-b14d-d945fba364d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ai_answer (system_prompt, user_prompt, MODEL):\n",
    "    if MODEL == MODEL_GPT:\n",
    "        stream = openai.chat.completions.create(\n",
    "            model=MODEL,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "              ],\n",
    "            stream=True\n",
    "        )\n",
    "    else:\n",
    "        ollama_via_openai = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')\n",
    "        stream = ollama_via_openai.chat.completions.create(\n",
    "            model=MODEL,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "              ],\n",
    "            stream=True\n",
    "        )\n",
    "    \n",
    "    response = \"\"\n",
    "    display_handle = display(Markdown(\"\"), display_id=True)\n",
    "    for chunk in stream:\n",
    "        response += chunk.choices[0].delta.content or ''\n",
    "        response = response.replace(\"```\",\"\").replace(\"markdown\", \"\")\n",
    "        update_display(Markdown(response), display_id=display_handle.display_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "60ce7000-a4a5-4cce-a261-e75ef45063b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "이 코드는 파이썬의 리스트 컴프리헨션과 제너레이터를 사용하여 특정 작업을 수행하는 코드입니다. 하나하나 쉽게 설명해 볼게요.\n",
       "\n",
       "### 코드 설명\n",
       "\n",
       "python\n",
       "yield from {book.get(\"author\") for book in books if book.get(\"author\")}\n",
       "\n",
       "\n",
       "1. **`books` 리스트**: 이 코드에서는 `books`라는 변수에 책들을 담고 있는 리스트가 있다고 가정합니다. 각 책은 딕셔너리 형태로 되어 있으며, 제목, 저자 등의 정보를 포함하고 있습니다.\n",
       "\n",
       "2. **리스트 컴프리헨션**: \n",
       "   - `{book.get(\"author\") for book in books if book.get(\"author\")}` 부분은 리스트 컴프리헨션을 사용하여 저자(author) 정보를 추출합니다.\n",
       "   - `book.get(\"author\")`는 각 책의 저자 이름을 가져오는 메소드입니다. \n",
       "   - `for book in books`는 `books` 리스트에 있는 모든 책에 대해 반복하면서, 각각의 책에 대해 저자 이름을 가져옵니다.\n",
       "   - `if book.get(\"author\")`는 저자 이름이 존재할 때만 가져오도록 조건을 설정합니다. 즉, 저자 정보가 없는 책은 무시하게 됩니다.\n",
       "\n",
       "3. **중괄호 `{}`**: \n",
       "   - 중괄호를 사용했기 때문에, 이 코드에서 생성되는 결과는 **집합(set)** 입니다. 집합은 중복된 값을 허용하지 않으므로, 동일한 저자가 여러 번 나타나더라도 한번만 나타나게 됩니다.\n",
       "\n",
       "4. **`yield from`**: \n",
       "   - 최종적으로 `yield from` 키워드를 사용해서 생성된 집합의 각 요소를 하나씩 반환합니다. 즉, 저자명을 하나씩 호출하는 것처럼 사용할 수 있습니다.\n",
       "\n",
       "### 요약\n",
       "- 이 코드는 주어진 `books` 리스트에서 저자(author) 정보를 추출하여 중복 없이 반환하는 역할을 합니다. \n",
       "- 중복된 저자 이름은 한 번만 반환되며, 저자 정보가 없는 책은 무시됩니다.\n",
       "\n",
       "이런 방식으로 코드를 사용하면, 더 깔끔하고 효율적으로 저자 정보를 다룰 수 있습니다!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ai_answer(system_prompt, user_prompt, MODEL_GPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8f7c8ea8-4082-4ad0-8751-3301adcf6538",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Hwae! (Hello!)**\n",
       "\n",
       "I'm here to help you understand some code, so let's break it down.\n",
       "\n",
       "**What is the code trying to do?**\n",
       "\n",
       "The code is trying to retrieve a list of authors from a collection of books (`books`). It's like gathering a list of authors who have written interesting books!\n",
       "\n",
       "**Let's look at the code line by line:**\n",
       "\n",
       "* **`yield from {book.get(\"author\") for book in books if book.get(\"author\")}`**\n",
       "\t1. `yield from`: This is a keyword that means \"pass something to the next part\" (like saying, \"Hey, take this information and make sense of it!\")\n",
       "\t2. `{...}`: This is a set comprehension, which allows us to create a new set by selecting items from an existing list or dictionary.\n",
       "\t3. `book.get(\"author\")`: We're asking each book object (`book`) for its \"author\" inner value.\n",
       "\t4. `for book in books if book.get(\"author\")`: This is a loop that only starts when we have a valid book (i.e., one with an author).\n",
       "\n",
       "**So, what happens inside the set comprehension?**\n",
       "\n",
       "* We iterate through each book (`book`) in the collection of books (`books`).\n",
       "* For each book:\n",
       "\t+ We check if it has an \"author\" value using `book.get(\"author\")`.\n",
       "\t+ If it does have an author (i.e., the value is not empty or None), we add its author to our set computation.\n",
       "* The result is a set of authors from all the books.\n",
       "\n",
       "**Why use this syntax?**\n",
       "\n",
       "By using this set comprehension, we can create a list of authors while iterating through the books. It's like saying: \"Take me a set of all the book authors and stop here!\"\n",
       "\n",
       "Think of it like gathering authors' names at a party (books). Each book is like an invitee with their name, author. We're collecting all these names into one place.\n",
       "\n",
       "Does that help you understand what this code does?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get Llama 3.2 to answer\n",
    "ai_answer(system_prompt, user_prompt, MODEL_LLAMA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b277d7c-a611-4cfe-90d4-12039c66dcc1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
