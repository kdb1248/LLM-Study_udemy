{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe12c203-e6a6-452c-a655-afb8a03a4ff5",
   "metadata": {},
   "source": [
    "# End of week 1 exercise\n",
    "\n",
    "To demonstrate your familiarity with OpenAI API, and also Ollama, build a tool that takes a technical question,  \n",
    "and responds with an explanation. This is a tool that you will be able to use yourself during the course!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1070317-3ed9-4659-abe3-828943230e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "from typing import List\n",
    "from dotenv import load_dotenv\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display, update_display\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a456906-915a-4bfd-bb9d-57e505c5093f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "\n",
    "MODEL_GPT = 'gpt-4o-mini'\n",
    "MODEL_LLAMA = 'llama3.2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8d7923c-5f28-4c30-8556-342d7c8497c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key found and looks good so far!\n"
     ]
    }
   ],
   "source": [
    "# set up environment\n",
    "# Load environment variables in a file called .env\n",
    "\n",
    "load_dotenv(override=True)      # env íŒŒì¼ë¡œë“œ\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# Check the key\n",
    "\n",
    "if not api_key:\n",
    "    print(\"No API key was found - please head over to the troubleshooting notebook in this folder to identify & fix!\")\n",
    "elif not api_key.startswith(\"sk-proj-\"):\n",
    "    print(\"An API key was found, but it doesn't start sk-proj-; please check you're using the right key - see troubleshooting notebook\")\n",
    "elif api_key.strip() != api_key:\n",
    "    print(\"An API key was found, but it looks like it might have space or tab characters at the start or end - please remove them - see troubleshooting notebook\")\n",
    "else:\n",
    "    print(\"API key found and looks good so far!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80a4bc14-9f04-4546-a66d-cc3d0eb28873",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"you are a assistant which specializes in coding. \\\n",
    "You have to explain code to south korea people.\\ try to explain code as korean and easy word \\\n",
    "to who are not major in computer science. Respond in markdown.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ca3dbee-fc9b-4a3a-834c-fb7cad011d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì½”ë“œ ë¦¬íŒ©í† ë§ \n",
    "\n",
    "def get_client(model: str) -> OpenAI:\n",
    "    if model == MODEL_GPT:\n",
    "        return OpenAI()\n",
    "    # ollama(OpenAI í˜¸í™˜) í´ë¼ì´ì–¸íŠ¸\n",
    "    return OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82b7563e-2934-4164-bbfc-3dfb3e60c44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ai_answer(system_prompt: str, user_prompt: str, model: str):\n",
    "    client = get_client(model)\n",
    "    stream = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[{\"role\":\"system\",\"content\":system_prompt},\n",
    "                  {\"role\":\"user\",\"content\":user_prompt}],\n",
    "        stream=True\n",
    "    )\n",
    "    response = \"\"\n",
    "    display_handle = display(Markdown(\"\"), display_id=True)\n",
    "    for chunk in stream:\n",
    "        delta = getattr(chunk.choices[0].delta, \"content\", None) or \"\"\n",
    "        response += delta\n",
    "        # Markdownì€ êµ³ì´ ì œê±°í•  í•„ìš” ì—†ìŒ (ì½”ë“œë¸”ë¡ í‘œì‹œì— í•„ìš”)\n",
    "        update_display(Markdown(response), display_id=display_handle.display_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0da350c8-d52b-4bda-b11a-6d00e78d4102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "í”„ë¡¬í”„íŠ¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”:  Please explain what this code does and why: yield from {book.get(\"author\") for book in books if book.get(\"author\")}\n"
     ]
    }
   ],
   "source": [
    "user_prompt = input(\"í”„ë¡¬í”„íŠ¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "60ce7000-a4a5-4cce-a261-e75ef45063b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "ì•ˆë…•í•˜ì„¸ìš”! ì´ ì½”ë“œì— ëŒ€í•´ ì‰½ê²Œ ì„¤ëª…í•´ë“œë¦´ê²Œìš”. \n",
       "\n",
       "ì½”ë“œëŠ” íŒŒì´ì¬ì—ì„œ ì‚¬ìš©ë˜ëŠ” ê²ƒìœ¼ë¡œ, ì£¼ë¡œ ë°ì´í„°ë¥¼ ì²˜ë¦¬í•  ë•Œ ë§ì´ ì‚¬ìš©ë©ë‹ˆë‹¤. ì´ ì½”ë“œë¥¼ ì—¬ëŸ¬ ë¶€ë¶„ìœ¼ë¡œ ë‚˜ëˆ„ì–´ ì„¤ëª…í•´ë³¼ê²Œìš”.\n",
       "\n",
       "### ì½”ë“œ ì„¤ëª…\n",
       "\n",
       "1. **ë¦¬ìŠ¤íŠ¸ ì»´í”„ë¦¬í—¨ì…˜**:\n",
       "   ```python\n",
       "   {book.get(\"author\") for book in books if book.get(\"author\")}\n",
       "   ```\n",
       "   - ì´ ë¶€ë¶„ì€ **ì§‘í•©(set)** ì»´í”„ë¦¬í—¨ì…˜ì…ë‹ˆë‹¤. `books`ë¼ëŠ” ë¦¬ìŠ¤íŠ¸ì— ìˆëŠ” ê°ê°ì˜ `book`ì— ëŒ€í•´, ê° ì±…ì˜ **ì €ì(author)**ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.\n",
       "   - `book.get(\"author\")`ëŠ” `book`ì—ì„œ ì €ìë¥¼ ì°¾ëŠ” ë°©ë²•ì…ë‹ˆë‹¤. ì €ìê°€ ì—†ë‹¤ë©´ `None`ì„ ë°˜í™˜í•˜ëŠ”ë°, ì´ëŸ° ê²½ìš°ëŠ” ë„˜ì–´ê°‘ë‹ˆë‹¤.\n",
       "   - `if book.get(\"author\")`ëŠ” ì €ìê°€ ìˆëŠ” ê²½ìš°ì—ë§Œ í•´ë‹¹ ì €ìë¥¼ í¬í•¨í•©ë‹ˆë‹¤.\n",
       "   - ê·¸ë˜ì„œ ì´ ë¶€ë¶„ì€ ì €ìê°€ ìˆëŠ” ì±…ë“¤ë¡œë¶€í„° ì €ìë“¤ì˜ ì§‘í•©ì„ ë§Œë“¤ì–´ì¤ë‹ˆë‹¤.\n",
       "\n",
       "2. **yield from**:\n",
       "   ```python\n",
       "   yield from ...\n",
       "   ```\n",
       "   - `yield from`ì€ **ì œë„ˆë ˆì´í„°(generator)**ë¥¼ ë§Œë“¤ ë•Œ ì‚¬ìš©ë˜ëŠ” êµ¬ë¬¸ì…ë‹ˆë‹¤. ì´ë ‡ê²Œ í•˜ë©´ ì €ìë“¤ì„ í•˜ë‚˜ì”© ë°˜í™˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
       "   - ì¦‰, ì €ìë“¤ì˜ ë¦¬ìŠ¤íŠ¸ë¥¼ ìƒì„±í•˜ê³ , ì´ë¥¼ í˜¸ì¶œí•œ ìª½ì—ì„œ í•˜ë‚˜ì”© ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤.\n",
       "\n",
       "### ì „ì²´ì  ì˜ë¯¸\n",
       "\n",
       "ê²°êµ­ ì´ ì½”ë“œëŠ” `books` ë¦¬ìŠ¤íŠ¸ì— ìˆëŠ” ì±…ë“¤ì˜ ì €ìë“¤ ì¤‘ì—ì„œ, ì €ìê°€ ìˆëŠ” ê²½ìš°ì— í•œí•´ ì €ìë“¤ì˜ ì§‘í•©ì„ ìƒì„±í•˜ê³ , ê·¸ ì§‘í•©ì˜ ì €ìë“¤ì„ í•˜ë‚˜ì”© ë°˜í™˜í•˜ëŠ” ì—­í• ì„ í•©ë‹ˆë‹¤.\n",
       "\n",
       "#### ìš”ì•½\n",
       "- ì£¼ì–´ì§„ `books`ë¼ëŠ” ë¦¬ìŠ¤íŠ¸ì—ì„œ ì €ìê°€ ìˆëŠ” ì±…ë“¤ì˜ ì €ìë¥¼ ëª¨ì•„ì„œ,\n",
       "- ê·¸ ì €ìë“¤ì„ í•˜ë‚˜ì”© ì œê³µí•´ì£¼ëŠ” ê¸°ëŠ¥ì„ í•˜ëŠ” ì½”ë“œì…ë‹ˆë‹¤.\n",
       "\n",
       "ì´í•´ê°€ ë˜ì…¨ë‚˜ìš”? ì¶”ê°€ë¡œ ê¶ê¸ˆí•œ ì ì´ ìˆìœ¼ë©´ ì–¸ì œë“ ì§€ ë¬¼ì–´ë³´ì„¸ìš”! ğŸ˜Š"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ai_answer(system_prompt, user_prompt, MODEL_GPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e45e7be3-3930-49b4-9191-6119ebfd0582",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Explanation of Code: \n",
       "\n",
       "`.yield from {...}``\n",
       "\n",
       "`.get()` is a method used to access the value of an item inside `Hashset` or dictionary.\n",
       "\n",
       "### what does `yield from {...}` do?\n",
       "\n",
       "`yield from {...}` is used when you want to call another `iterator` like function and put all values in a new one . It's called to **lazy evaluation** meaning that `yield()` will run until the end, then return.\n",
       "\n",
       "`.get(\"author\")` will get the book author\n",
       "\n",
       "**so what the whole expression does?**\n",
       "\n",
       "The entire expression is used when you have many books with `author` and don't want it to execute on each page. This saves  performance. Let's assume we are doing query in a library, like which ones were written by Lee Do Hyun \n",
       "\n",
       "So we call `getAuthor()` from each book and print the author but only for those where writer is `Lee Do Hyun`."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ai_answer(system_prompt, user_prompt, MODEL_LLAMA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b277d7c-a611-4cfe-90d4-12039c66dcc1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
